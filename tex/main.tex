\documentclass{report}

\usepackage{epigraph}
\usepackage{colortbl}
\usepackage{xspace}
\usepackage{listings}
\usepackage{relsize}

\input{darais-latex-imports}
\input{darais-latex-macros}

\newcommand{\lang}{Allyn\xspace}
\newcommand{\mpc}{\ensuremath{\lambda_{\mathrm{MPC}}}\xspace}
\newcommand{\obliv}{\ensuremath{\lambda_{\mathrm{Obliv}}}\xspace}

\newcommand{\ins}[1]{\textcolor{red}{Ian: #1}}

%%% Macros for MPC
\newcommand{\alice}{Bâ¸¨â€¹Aâ€ºBâ¸©\xspace}
\newcommand{\bob}{Câ¸¨â€¹Bâ€ºCâ¸©\xspace}

\newcommand{\alices}[1]{Bâ¸¨#1â¸¤Aâ¸¥Bâ¸©}
\newcommand{\bobs}[1]{Câ¸¨#1â¸¤Bâ¸¥Câ¸©}

\newcommand{\aliceSec}{\alices{s}\xspace}
\newcommand{\bobSec}{\bobs{s}\xspace}

\newcommand{\aliceSh}[1]{\alices{âŒŠ#1âŒ‹}}
\newcommand{\bobSh}[1]{\bobs{âŒŠ#1âŒ‹}}

\newcommand{\opaque}{Aâ¸¨â˜…Aâ¸©\xspace}
%%%

%%% Macros from Symphony Paper
\newcommand{\eset}{â¸¨âˆ…â¸©}
%%%

\definecolor{implColor}{HTML}{EA9999}
\definecolor{theoryColor}{HTML}{A4C2F4}

\begin{document}

\title{Programming Languages for Secure and Oblivious Computation}

\author{Ian Sweet \\
  \emph{University of Maryland, College Park} \\
  \emph{ins@cs.umd.edu}}

\date{}

\maketitle

\begin{abstract}

  \emph{Secure Multiparty Computation} (MPC) has emerged as a promising approach to mutually confidential computation.
  Traditionally, MPC programs do not allow secrets to be used as indexes to dynamically allocated memory.
  This precludes, for example, a secure binary search in which the element being accessed is considered secret.
  This restriction is relaxed by ensuring that the secure computation is (probabilistically) \emph{oblivious}.
  Unfortunately, existing languages for MPC do not support efficient, oblivious programming. We propose the design
  and implementation of an efficient, probabilistically oblivious language for MPC.
\end{abstract}

\tableofcontents

\chapter{Introduction}
\label{ch:intro}

\epigraph{It seems like everywhere I go \\
          The more I see, the less I know}{
            Michael Franti \& Spearhead \\
            \emph{Say Hey I Love You}}

If our adversaries were more like Michael Franti then we wouldn't need to concern ourselves with privacy.
Our programming languages have a duty of \emph{confidentiality}. They are responsible for protecting the
data that we designate as sensitive or private. Most computation today is \emph{mutual} --- computation
is performed over the private information of many parties --- which means that programming languages really
have a duty of \emph{mutual confidentiality}. What do languages that guarantee mutual confidentiality look
like? How can they be improved?

\section{Secure Multiparty Computation and Obliviousness}
\label{sec:intro}

% What is MPC, in a nutshell?
\emph{Secure Multiparty Computation} (MPC) is a subfield of cryptography
that allows mutually untrusting parties to compute arbitrary functions over their private inputs while revealing nothing
except the function output. That is, MPC allows parties to work together to run programs \emph{under encryption}.

% Problem: MPC programs are hard to write and read for novices.
% Solution: Abstract Sequentiality.
Approaches to MPC have improved significantly over the years. The first full implementation, FairPlay~\cite{todo}, could evaluate
only a few hundred Boolean gates per second. Modern implementations on custom setups evaluate \emph{billions} of Boolean gates per
second~\cite{todo}, and cryptographers continue to reduce the cost of MPC. Despite increasing efficiency and compelling applications
(secure auctions, secure databases, collaborative machine learning, and any other imaginable application with security concerns),
MPC has not been widely adopted. One significant barrier to adoption is a lack of appropriate infrastructure. Today, it is difficult
for non-experts to understand and work in the complex distributed model that MPC requires. To assuage this difficulty, some recent
MPC lanuages (e.g. SCVM, Wysteria, and Symphony) are \textbf{abstractly sequential}. An \textbf{abstractly sequential} language hides
the parallel deployment of the MPC program from the programmer. This proposal builds heavily on one such language, Symphony, which is
discussed formally in~\cref{sec:lam-mpc}.

% Problem: MPC programs are slow, linear ORAM is intractable.
% Solution: Uniform, random sampling => logarithmic ORAM.

In addition to a lack of infrastructure, MPC languages also fail to provide adequate support for RAM-model programming.
The standard means by which RAM-model computation is supported in MPC languages is using \emph{Oblivious RAM} (ORAM). To date, most MPC languages
simply do not provide any access to ORAM. In their 2019 SoK,~\citet{todo} observe that only a ``few frameworks have ORAM support, either
natively (ObliVM and SCALE-MAMBA) or via a library (Obliv-C).'' The three languages mentioned, ObliVM~\cite{todo}, SCALE-MAMBA~\cite{todo}, and
Obliv-C~\cite{todo}, are \textbf{probabilistic} MPC languages. According to~\citet{todo}, a language must have support for uniform, random sampling
to implement asymptotically optimal ORAM. Indeed, each of these languages provides a highly optimized implementation of
Circuit ORAM~\cite{todo}, which is known to be asymptotically optimal (i.e. $O(\log{n})$).

% Problem: MPC programs that use uniform, random sampling for efficiency are not guaranteed to be safe (confidential).
% Solution: High assurance programs via an oblivious or leak-free declassification which is checked for confidentiality.
It is common practice in probabilistic MPC languages to declassify values with the expectation that they
do not reveal any information. For example, consider the One-Time Pad (OTP) in~\cref{fig:otp-symphony}.

\begin{figure}[h]
Mâ…
\begin{array}{r@{â }lcl}
     Â«0:Â» & ğ‘šğ‘3l{ â¦‘parâ¦’[\alice,\bob] }
  \\ Â«1:Â» & â â¦‘letâ¦’â£k â§¼=â§½ â¦‘parâ¦’[\alice]â£ğ’°(â´0,1âµ)â£â¦‘inâ¦’
  \\ Â«2:Â» & â â¦‘letâ¦’â£s â§¼=â§½ â¦‘parâ¦’[\alice]â£â¦‘readâ¦’â£â¦‘inâ¦’
  \\ Â«3:Â» & â â¦‘letâ¦’â£e â§¼=â§½ â¦‘declassifyâ¦’[\alice â†’ \alice,\bob]â£â¦‘parâ¦’[\alice]â£k âŠ• sâ£â¦‘inâ¦’
  \\ Â«4:Â» & â â€¦
\end{array}
Mâ†
\caption{\mpc{} code for a One-Time Pad}
\label{fig:otp-symphony}
\end{figure}

This example is a computation between two parties, \alice and \bob. On line 1, \alice generates a local uniform, random bit which will serve
as her encryption key. On line 2, she reads a secret bit from local storage. Finally, on line 3, she encrypts her secret, â¸¨sâ¸©, by XORing it
with the key â¸¨kâ¸© and then declassifies the result to \bob. Does \bob learn any information about \alice's secret? He doesn't, because it has been encrypted
by the random bit â¸¨kâ¸© which he doesn't know. As long as â¸¨kâ¸© is never revealed to \bob, \alice's secret is safe.
However, in existing MPC languages, there is no way to specify that the declassification on line 3 reveals no information about â¸¨sâ¸©.
A \textbf{high assurance} language ensures that programs are probabilistically oblivious. They give programmers the ability to specify
that probabilistic values may be safely revealed to other parties. They gives novices the opportunity to experiment safely, and free experts from having to
manually audit their programs.

In summary, we would like the following properties from our MPC language.

\begin{enumerate}
\item \label{itm:sequential} \textbf{\underline{Abstractly Sequential} -- An abstractly sequential language, which hides the parallel deployment from the
  programmer, is necessary for lowering the barrier of entry to MPC languages.}
  Being able to program as though the program is being executed sequentially, without worrying about the parallel deployment
  of the program, significantly reduces the complexity of MPC programming.
\item \label{itm:probabilistic} \textbf{\underline{Probabilistic} -- A probabilistic language, which allows sampling from uniform, random distributions, is necessary
  for implementing asymptotically optimal ORAM, oblivious algorithms, and data structures.}
  When more efficient oblivious protocols are invented (which happens every year), cryptographers would like to be able to
  implement these protocols as libraries in MPC languages.
\item \label{itm:assurance} \textbf{\underline{High Assurance} -- A high assurance language, which guarantees that all programs are oblivious, is necessary
  for certifying that programs do not leak information through side channels.} Without certification of obliviousness, a domain expert
  would need to manually audit the declassifications in the program which are expected to reveal no information. Such declassifications
  are common in, for example, tree-based ORAM constructions.
\end{enumerate}

\paragraph{Problem.} No existing MPC language is \textbf{(all together) abstractly sequential, probabilistic, and high assurance.}

\section{Proposed Work}
\label{sec:intro-proposal}

\paragraph{Hypothesis.} It is possible to design and implement a language for MPC which is \textbf{abstractly sequential, probabilistic,
  and high assurance (as defined above).}

\paragraph{Contribution: \obliv is PMTO.} In prior work, we show that ObliVM's~\cite{todo} type system is not oblivious,
and show how to fix it in such a way that is satisfies \emph{Probabilistic Memory Trace Obliviousness} (PMTO).
We prove this property for \obliv, a non-MPC language for oblivious programming.

\paragraph{Contribution: \mpc is MTO\%.} In ongoing work, we show that Symphony's type system guarantees that MPC programs are
\emph{Memory Trace Oblivious Modulo Declassifications} (MTO\%). To our knowledge, this is the first time such a theorem has been
proved for an MPC language. The SCVM language has a proof of a related property based on crypto-style ``simulation.''

\paragraph{Contribution: Identifying PMTO\%.} We identify and define \emph{Probabilistic Memory Trace Oblivious Modulo Declassification}
(PMTO\%) as an appropriate definition of security for probabilistic MPC languages. We also investigate and explicate the connection between
this property and other common security properties involving declassifications (such as Gradual Release~\cite{todo}).

The contributions described above have already been accomplished. They are necessary but not sufficient to confirm our hypothesis.
To confirm our hypothesis, we propose the design and implementation of a new language for MPC, called \lang, which extends the
Symphony language with primitives for drawing uniform, random samples and declassifying them.

\paragraph{Contribution: \lang, an abstractly sequential, probabilistic, and high assurance MPC language.}
\lang will extend Symphony with uniform, random sampling. This will immediately satisfy
Property~\ref{itm:probabilistic} above. We will provide evidence that this property is useful by
implementing various ORAM protocols (Trivial ORAM, Circuit ORAM, and Recursive (Circuit) ORAM). We will show through
an empirical evaluation that these case studies have the expected asymptotic behavior. Next, we will prove that \lang satisfies
the type safety and simulation theorems by adapting the proofs of these properties for Symphony. This will establish
that \lang satisfies Property~\ref{itm:sequential}.
Finally, we will design the type system of \lang to enforce PMTO\% and confirm that the case studies (ORAM protocols) are well-typed.
This will establish that \lang satisfies Property~\ref{itm:assurance} while also admitting interesting protocols. Having
accomplished everything above, we will have confirmed our hypothesis.

We summarize the tasks involved in the last contribution above, and give a rough timeline for their completion. Tasks in
\colorbox{implColor}{red} require adding additional functionality to the existing Haskell implementation of Symphony.
Tasks in \colorbox{theoryColor}{blue} require adapting the formal metatheory of Symphony. \\

\ins{TODO: when proposal document is done, revisit this and update timeline.}

\begin{tabular}{|p{.30\textwidth}|p{.30\textwidth}|p{.30\textwidth}|}
  \hline
  \textbf{Task} & \textbf{Description} & \textbf{Estimated Time of Completion} \\
  \hline
  \rowcolor{implColor}
  Case Studies:
  \begin{itemize}
  \item Trivial ORAM
  \item Tree ORAM(s)
  \item Recursive ORAM
  \end{itemize}    & Implement case studies in \lang;
  show that they are functionally correct and typecheck & 10/07/2020 ($\sim$2 weeks)  \\ \hline
  \rowcolor{implColor}
  Type Checker     & Implement the type checker for \lang                  & 11/07/2020 ($\sim$1 month)  \\ \hline
  \rowcolor{implColor}
  MPC Interpreter  & Implement an EMP MPC backend for \lang                & 01/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  Static Semantics & \lang is \mpc + \obliv                                & 03/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  PMTO\%           & Prove \lang satisfies PMTO\%                          & 05/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  Type Soundness   & Prove \lang satisfies Type Soundness                  & 05/14/2021 ($\sim$1 week)   \\ \hline
  \rowcolor{theoryColor}
  Simulation       & Prove \lang satisfies Simulation                      & 05/21/2021 ($\sim$1 week)   \\ \hline
  Thesis           & Write the thesis and defend it                        & 10/21/2021 ($\sim$5 months) \\ \hline
\end{tabular}

\chapter{Background}
\label{ch:background}

\epigraph{Trust in me in all you do \\
          Have the faith I have in you \\
          Love will see us through \\
          If only you trust in me}{
            Etta James \\
            \emph{Trust in Me}}

We begin by introducing the Symphony language using the Millionaire's Problem. Having done so, we will expand on the MPC language
properties that we advocate for in Section~\ref{sec:background-properties}.
Readers unfamiliar with MPC are encouraged to read Appendix~\ref{ch:gmw}, which describes the GMW protocol.
Readers unfamiliar with ORAM are encouraged to read Appendix~\ref{ch:oram}, which describes the ORAM protocols relevant to this proposal.

\section{A Taste of \mpc}
\label{sec:background-symphony}

From here on, we instead refer to Symphony as \mpc to emphasize the similarities with \obliv which is presented in
Chapter~\ref{ch:lam-obliv}. As a means of gentle introduction, let's consider the Millionaire's Problem in which two wealthy parties,
\alice and \bob, would like to know who is wealthier.

\begin{figure}[h]
Mâ…
\begin{array}{r@{â }lcl}
   Â«0:Â» & ğ‘šğ‘3l{ â¦‘parâ¦’[\alice,\bob] }
\\ Â«1:Â» & â â¦‘letâ¦’â£x    â§¼=â§½ â¦‘parâ¦’[\alice]â£â¦‘readâ¦’â£â¦‘inâ¦’
\\ Â«2:Â» & â â¦‘letâ¦’â£y    â§¼=â§½ â¦‘parâ¦’[\bob]â£â¦‘readâ¦’â£â¦‘inâ¦’
\\ Â«3:Â» & â â¦‘letâ¦’â£sx   â§¼=â§½ â¦‘shareâ¦’[\alice â†’ \alice,\bob]â£xâ£â¦‘inâ¦’
\\ Â«4:Â» & â â¦‘letâ¦’â£sy   â§¼=â§½ â¦‘shareâ¦’[\bob â†’ \alice,\bob]â£yâ£â¦‘inâ¦’
\\ Â«5:Â» & â â¦‘letâ¦’â£r    â§¼=â§½ sx < syâ£â¦‘inâ¦’
\\ Â«6:Â» & â â¦‘letâ¦’â£z    â§¼=â§½ â¦‘revealâ¦’[\alice,\bob]â£râ£â¦‘inâ¦’
\\ Â«7:Â» & â â€¦
\end{array}
Mâ†
\caption{\mpc{} code for the Millionaire's Problem}
\label{fig:millionaires-symphony}
\end{figure}

The code in Figure~\ref{fig:millionaires-symphony} is written in the \mpc language. On line 0, the â¸¨â¦‘parâ¦’[\alice,\bob]â¸© block
indicates that both \alice and \bob will execute everything in the block's lexical scope. Any other parties will ignore the
contents of the block and generate an \emph{opaque value} denoted \opaque. On line 1, \alice â¸¨â¦‘readâ¦’â¸©s her own wealth,
â¸¨\alices{â‹–wealthâ‹—}â¸©, from local storage and binds it to â¸¨xâ¸©. \bob, however, evaluates the expression â¸¨â¦‘parâ¦’[\alice]â£â¦‘readâ¦’â¸© to
\opaque because he is not included in the â¸¨â¦‘parâ¦’[\alice]â¸© block. On line 2, the same thing happens except \bob reads his wealth,
â¸¨\bobs{â‹–wealthâ‹—}â¸©, and binds it to â¸¨yâ¸© while \alice binds \opaque to â¸¨yâ¸©. In summary, after line 2, the local environemnts are:

Mâ…
  AËcc
  Aâ… \alice & \bob
  Aâƒ âŸ¨x â†¦ \alices{â‹–wealthâ‹—},â£y â†¦ \opaqueâŸ©â  & â âŸ¨x â†¦ \opaque,â£y â†¦ \bobs{â‹–wealthâ‹—}âŸ©
  Aâ†
Mâ†

On line 3, \alice splits her â¸¨\alices{â‹–wealthâ‹—}â¸© into two shares. She keeps her share and sends \bob's share to him. We use the same
notation for shares which appears in Appendix~\ref{ch:gmw} to emphasize the connection between the explanation of GMW and the execution model
of \mpc. On line 4, \bob splits his â¸¨\bobs{â‹–wealthâ‹—}â¸© into two shares. He keeps his share and send's \alice's share to her. So, after
line 4 the local environments are:

Mâ…
  AËllll
  Aâ… ğ‘šğ‘2c{\alice} & ğ‘šğ‘2c{\bob}
    Aâƒ âŸ¨â€¦,&â£sx â†¦ \aliceSh{\alices{â‹–wealthâ‹—}}, & â âŸ¨â€¦,&â£sx â†¦ \bobSh{\alices{â‹–wealthâ‹—}},
    Aâƒ    &â£sy â†¦ \aliceSh{\bobs{â‹–wealthâ‹—}}âŸ©   &     &â£sy â†¦ \bobSh{\bobs{â‹–wealthâ‹—}}âŸ©
  Aâ†
Mâ†

On line 5, \alice and \bob compute over their shares to produce a share indicating who is wealthier. Here we assume that the language knows
how to compute â¸¨<â¸© over shares. For example, if the underlying MPC protocol were GMW then we would encode â¸¨<â¸© as a magnitude circuit made
up of XOR and AND gates.

Mâ…
  AËcc
  Aâ… \alice & \bob
  Aâƒ âŸ¨â€¦,â£r â†¦ \aliceSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©}âŸ© & â âŸ¨â€¦,â£r â†¦ \bobSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©}âŸ©
  Aâ†
Mâ†

Finally, on line 6, the shares of â¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}â¸© among \alice and \bob are combined and the
result is revealed to both parties. Note that we could have revealed the result only to \alice, for example,
in which case \bob would send his share to \alice but not vice versa. Then, \alice could recover the cleartext result but \bob could not.
In this case, however, they both send their shares to each other. The XOR operator, â¸¨âŠ•â¸©, is used to combine shares implicitly as part
of the â¸¨â¦‘revealâ¦’â¸©.

Mâ…
  AËllll
  Aâ… ğ‘šğ‘2c{\alice} & ğ‘šğ‘2c{\bob}
    Aâƒ âŸ¨â€¦,â£z &{} â†¦ \aliceSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©} & â âŸ¨â€¦,â£z &{} â†¦ \aliceSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©}
    Aâƒ       &{}â£âŠ• \bobSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©} & &{}â£âŠ• \bobSh{Aâ¸¨\alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}Aâ¸©}
    Aâƒ       &{}â£= \alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}âŸ© & &{}â£= \alices{â‹–wealthâ‹—} < \bobs{â‹–wealthâ‹—}âŸ©
  Aâ†
Mâ†

There are some interesting things to notice about this program (and \mpc more generally). First, the programmer can control which parties
evaluate which expressions by using â¸¨â¦‘parâ¦’â¸© blocks. Second, cleartext â¸¨â¦‘readâ¦’â¸© operations (lines 1,2) are mixed with ciphertext operations
(lines 3,4,5,6). Lastly, the language is \textbf{abstractly sequential}. In a deployment, this program would run
independently on \alice and \bob who would communicate to jointly compute the result. Our explanation of the execution of
Figure~\ref{fig:millionaires-symphony} highlights the intuition of abstract sequentiality.

\section{Desirable Properties of MPC}
\label{sec:background-properties}

In Section~\ref{sec:intro} we claimed that a MPC language ought to be \textbf{abstractly sequential}, \textbf{probabilistic},
and \textbf{high assurance}. But, what are these properties and why do we care about them?

\subsection{Abstractly Sequential MPC Languages}
\label{subsec:background-properties-centralized}

A language which is abstractly sequential liberates the programmer from managing a parallel computation. In the context of MPC,
the programmer does not need to perform commands conditioned on which party is executing. To see the difference, contrast the
Obliv-C implementation of the Millionaire's Problem in Figure~\ref{fig:millionaires-oblivc} with the \mpc implementation in
Figure~\ref{fig:millionaires-symphony}.

\begin{figure}[h]
\begin{lstlisting}[language=c,basicstyle=\footnotesize\ttfamily,numbers=left,stepnumber=1]
  // File: million.h
  typedef struct {
    int in;
    bool out;
  } ProtocolIO;

  void millionaire (void *args);

  // File: million.oc
  #include <million.h>
  #include <obliv.oh>

  void millionaire (void *args) {
    ProtocolIO *io = args;
    obliv int a, b;
    obliv bool res = false;
    a = feedOblivInt (io->in, 1);
    b = feedOblivInt (io->in, 2);
    obliv if (a < b) res = true;
    revealOblivBool(&io->out, res, 0);
  }

  // File: million.c
  #include <million.h>

  int main (int argc, char *argv[]) {
    ProtocolDesc pd;
    ProtocolIO io;
    int p = (argv[1] == '1' ? 1 : 2);
    sscanf(argv[2], "%d", &io.in);
    // ... set up TCP connections

    setCurrentParty(&pd, p);
    execYaoProtocol(&pd, millionaire, &io);
    printf ("%d\n", io.out);
    // ... cleanup
  }
\end{lstlisting}
\caption{Obliv-C code for the Millionaire's Problem}
\label{fig:millionaires-oblivc}
\end{figure}

We can see that many of the details of the parallel, MPC deployment have leaked into the application code. The
\lstinline[language=c,basicstyle=\ttfamily]{main} function is responsible for all sorts of scaffolding such as establishing TCP connections (line 31),
explicitly executing the protocol (line 34), and populating the \lstinline[language=c,basicstyle=\ttfamily]{io} variable with party inputs (line 30). As
a point of comparison, take a look back at Figure~\ref{fig:millionaires-symphony}. Notice that this code makes no mention of TCP connections,
explicit execution of any protocol, or eagerly reading and caching secret inputs.

In Chapter~\ref{ch:lam-mpc} we will formally define an \textbf{abstractly sequential} MPC language as one which satisfies two theorems:
forward simulation and type safety. Forward simulation guarantees that if the sequential interpretation of a program doesn't get stuck,
then neither does its parallel deployment. Type safety ensures that well-typed programs do not get stuck in the sequential interpretation.
These two theorems work together to guarantee that well-typed programs cannot encounter, for example, a liveness error in which one party
fails to send a message that another party is blocked on.

Although we will not make any formal claims regarding the usability of the language, we claim that an MPC language which hides the parallel
nature of MPC is desirable.

\subsection{Probabilistic MPC Languages}
\label{subsec:background-properties-probabilistic}

In our terminology, an MPC language is \textbf{probabilistic} if it supports a primitive for drawing uniform, random samples from a
discrete, finite set. For example, drawing a uniform, random sample from â¸¨ğ”¹â¸©, the booleans, corresponds to a fair coin toss. We
could also draw from â¸¨â„•â¸¤32â¸¥â¸©, natural numbers modulo â¸¨2^{32}â¸©. Why is such a primitive important in an MPC language?

As discussed in Chapter~\ref{sec:intro}, MPC languages rely on ORAM to support a RAM-model of computation. In their seminal paper,~\citet{}
showed that Trivial ORAM, which has an overhead of $O(n)$, is optimal if the oblivious scheme is deterministic. However, provided the ability
to perform uniform, random samples, it is possible to design more efficient ORAMs. For example, all tree-based ORAM schemes, including
(Recursive) Circuit ORAM, rely the position tags being uniform, random samples. Additionally, there are highly
optimized oblivious algorithms and data structures which do not rely on ORAM, but do rely on randomness to achieve greater efficiency~\cite{}.

To see how the use of random sampling is used to improve efficiency, consider the \mpc{} code in Figure~\ref{fig:mpc-2-oram}. The purpose of
this code is to allow \bob to choose one of two secrets belonging to \alice without \alice learning which one \bob chose. On lines 1-2,
\alice shares two secrets, â¸¨sâ¸¤A1â¸¥â¸© and â¸¨sâ¸¤A2â¸¥â¸©, with \bob. On line 3, \bob's choice, â¸¨sâ¸¤Bâ¸¥â¸©, is shared with \alice.
On line 4, \bob flips a coin, â¸¨uâ¸©, which he shares with \alice. On lines 5-6, the array, â¸¨aâ¸©, is populated
in-order if the coin â¸¨uâ¸© is heads, and out-of-order if the coin is tails. Finally, on line 7 the XOR of \bob's choice with the flipped
coin is revealed to both parties. Notice that if \bob's choice was â¸¨0â¸© (tails) then he always gets â¸¨sâ¸¤A1â¸¥â¸© and
likewise for â¸¨1â¸© (heads) and â¸¨sâ¸¤A2â¸¥â¸©.

This code illustrates the importance of random sampling for efficient RAM access. If the MPC program had instead stored the array â¸¨aâ¸© in
a Trivial ORAM then the lookup on line 8 would require 2 accesses (one for each element in the ORAM). This may not seem so bad, but consider
the overhead if \bob wanted to choose from an array of length â¸¨nâ¸©. In that case, the lookup on line 8 would incur an $O(n)$ overhead!

\begin{figure}[h]
Mâ…
\begin{array}{r@{â }lcl}
   Â«0:Â» & ğ‘šğ‘3l{ â¦‘parâ¦’[\alice,\bob] }
\\ Â«1:Â» & â â¦‘letâ¦’â£sâ¸¤A1â¸¥ â§¼=â§½ â¦‘shareâ¦’[\alice â†’ \alice,\bob]â£(â¦‘parâ¦’[\alice]â£â¦‘readâ¦’â£â„¤)â£â¦‘inâ¦’
\\ Â«2:Â» & â â¦‘letâ¦’â£sâ¸¤A2â¸¥ â§¼=â§½ â¦‘shareâ¦’[\alice â†’ \alice,\bob]â£(â¦‘parâ¦’[\alice]â£â¦‘readâ¦’â£â„¤)â£â¦‘inâ¦’
\\ Â«3:Â» & â â¦‘letâ¦’â£sâ¸¤Bâ¸¥  â§¼=â§½ â¦‘shareâ¦’[\bob â†’ \alice,\bob]â£â¦‘parâ¦’[\bob]â£â¦‘readâ¦’â£â¦‘inâ¦’
\\ Â«4:Â» & â â¦‘letâ¦’â£u     â§¼=â§½ â¦‘shareâ¦’[\bob â†’ \alice,\bob]â£â¦‘parâ¦’[\bob]â£ğ’°(â´0,1âµ)â£â¦‘inâ¦’
\\ Â«5:Â» & â â¦‘letâ¦’â£l,r   â§¼=â§½ â¦‘muxâ¦’â£uâ£â¦‘thenâ¦’â£sâ¸¤A1â¸¥,sâ¸¤A2â¸¥â£â¦‘elseâ¦’â£sâ¸¤A2â¸¥,sâ¸¤A1â¸¥â£â¦‘inâ¦’
\\ Â«6:Â» & â â¦‘letâ¦’â£a     â§¼=â§½ [l;â£r]â£â¦‘inâ¦’
\\ Â«7:Â» & â â¦‘letâ¦’â£idx   â§¼=â§½ â¦‘revealâ¦’[\alice,\bob]â£sâ¸¤Bâ¸¥ âŠ• uâ£â¦‘inâ¦’
\\ Â«8:Â» & â â¦‘letâ¦’â£r     â§¼=â§½ a[idx]â£â¦‘inâ¦’
\\ Â«9:Â» & â â€¦
\end{array}
Mâ†
\caption{Conceptual 2 element ORAM lookup in \mpc{}}
\label{fig:mpc-2-oram}
\end{figure}

\subsection{High Assurance MPC Languages}
\label{subsec:background-properties-assurance}

Finally, an MPC language is \textbf{high assurance} if it guarantees that programs are oblivious by construction.
Existing MPC languages with support for uniform, random sampling cannot be considered \textbf{high assurance} because
they do not allow developers to distinguish between \emph{declassification} and \emph{revelation}. A declassification
intends to leak some necessary information about secrets. The information leak is part of the specification.
A revelation intends not to leak any information about secrets. Freedom from information leaks is
part of the specification. For example, the Millionaire's Problem in Figure~\ref{fig:millionaires-symphony} features a declassification. The
developer expects that declassification of the comparison will leak some information about the net worth of the
participants. In contrast, the ``declassifications'' in the One-Time Pad and Mini-ORAM examples (Figures~\ref{fig:otp-symphony} and~\ref{fig:mpc-2-oram})
are really revelations. The developer expects that the ``declassifications'' will not leak any information about \alice's secrets.

Existing MPC languages provide only a mechanism for declassifications. These declassifications are trusted and any
information leaked is assumed to be intentional. Unfortunately, this means that revelations must also use the
declassification mechanism. As such, the leak-freedom of those revelations cannot be checked
by the language. For example, consider what happens if we change line 7 in the Mini-ORAM example to declassify â¸¨sâ¸¤Bâ¸¥â¸©.
In that case, the functional correctness of the program is unaffected but we have accidentally leaked \bob's secret to \alice!
This information leak could have been prevented by a language which provides a revelation mechanism.

Both MPC applications and libraries rely on revelation. Cryptographers rely on revelation to implement secure protocols such as ORAM,
Function Secret Sharing~\cite{}, and Zero-Knowledge Proofs\cite{}. Cryptographers are not the only ones who we expect to leverage the
revelation mechanism. It turns out that many application-level algorithms and data structures also rely on revelation. For example,
various comparison-based algorithms in MPC are optimized by permuting the collection prior to sorting~\cite{hamada2012}. This allows occurences of
comparison in the sorting algorithm to use â¸¨â¦‘ifâ¦’â¸© over revealed comparison, instead of â¸¨â¦‘muxâ¦’â¸©. These sorts of algorithms and
data structures are more likely to be implemented by developers who are not experts in cryptography.

A high assurance language is beneficial to both MPC experts and novices. Experts save time and gain confidence in their
experimental protocols by relying on the language to enforce confidentiality. For example, modifying line 7 in
Figure~\ref{fig:mpc-2-oram} to use a revelation means it need not be manually audited. Instead, the language would ensure that the
revelation is safe. Likewise, MPC novices will benefit by being able to safely experiment with their own cryptographic optimizations
without fear of accidentally leaking information they didn't intend to. They need only mark revelations that are expected to be
leak-free appropriately.

In Chapters~\ref{ch:lam-obliv} and~\ref{ch:proposal} we will formally define a \textbf{high assurance} language as one which provides
a mechanism for revelations and provably correct enforcement mechanism. For all the languages in this proposal, we will
assume that the enforcement mechanism is a static type system. If the type system accepts the program, then all the revelations
are guaranteed to be leak-free. This is proved through an appropriate obliviousness property, PMTO for \obliv and PMTO\% for \lang.

\ins{TODO: refer to PMTO and PMTO\% as theorems}
\ins{IDEA: In future paper, implement quicksort (1) on top of ORAM and then (2) using permutation optimization. Show that (2) is much
  faster, which suggests that building ORAM into the language and using it everywhere is not a good solution.}

\chapter{\mpc, A Language for Concise MPC}
\label{ch:lam-mpc}

In~\cref{sec:background-symphony} we walked through the sequential interpretation of the Millionaire's Problem in \mpc. Now that we have
the intution, let's look at the formal description of \mpc. Having a formal model will allow us to state the Simulation property of the
language precisely.

\ins{todo: refer to simulaion as theorem}

\section{Overview}
\label{sec:lam-mpc-overview}

The syntax of \mpc is presented in \Cref{fig:mpc-syntax}. \mpc types comprise a
series of standard types---integers, booleans functions, and pair types---augmented
with two additional elements.

Fâ…
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
Dâ…
Mâ…
AËrcrcl@{â }l
Aâ… b     â§¼âˆˆâ§½ ğ”¹            â§¼ â§½                                & âŸªbooleansâŸ«
Aâƒ i     â§¼âˆˆâ§½ â„¤            â§¼ â§½                                & âŸªintegersâŸ«
Aâƒ A,B,C â§¼âˆˆâ§½ â€¹partyâ€º      â§¼ â§½                                & âŸªpartiesâŸ«
Aâƒ m,p,q â§¼âˆˆâ§½ â€¹party-setâ€º  â§¼â‰œâ§½ â„˜(â€¹partyâ€º) â©´ â´A,â€¦,Aâµ          & âŸªsets of partiesâŸ«
Aâƒ Ïˆ     â§¼âˆˆâ§½ â€¹protâ€º       â§¼â©´â§½ â‹…                             & âŸªcleartextâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘encâ¦’â‹•m                        & âŸªencryptedâŸ«
Aâƒ Î¼     â§¼âˆˆâ§½ â€¹base-typeâ€º  â§¼â©´â§½ â¦‘intâ¦’                         & âŸªinteger typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘boolâ¦’                         & âŸªboolean typeâŸ«
Aâƒ Ïƒ     â§¼âˆˆâ§½ â€¹loc-typeâ€º   â§¼â©´â§½ Î¼â¸¢Ïˆâ¸£                          & âŸªprotocol typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Ï„ â†’â‚˜ Ï„                         & âŸªfunction typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Ï„ Ã— Ï„                          & âŸªpair typeâŸ«
Aâƒ Ï„     â§¼âˆˆâ§½ â€¹typeâ€º       â§¼â©´â§½ Ïƒ@m                           & âŸªlocated typeâŸ«
Aâƒ x,y,z â§¼âˆˆâ§½ â€¹varâ€º        â§¼ â§½                                & âŸªvariablesâŸ«
Aâƒ âŠ™     â§¼âˆˆâ§½ â€¹binopâ€º      â§¼ â§½                                & âŸªbinary operations (e.g., plus, times)âŸ«
Aâƒ e     â§¼âˆˆâ§½ â€¹exprâ€º       â§¼â©´â§½ x                             & âŸªvariable referenceâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ i                              & âŸªinteger literalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ b                              & âŸªboolean literalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ e âŠ™ e                          & âŸªbinary operationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘ifâ¦’â£eâ£â¦‘thenâ¦’â£eâ£â¦‘elseâ¦’â£e       & âŸªatomic conditionalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ e Â¿ e â—‡ e                      & âŸªatomic multiplexorâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ âŸ¨e,eâŸ©                          & âŸªpair creationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Ï€áµ¢â£e                           & âŸªpair projection (â¸¨i âˆˆ â´1,2âµâ¸©)âŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Î»â¸¤zâ¸¥x.â£e                       & âŸª(recursive) function creationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘readâ¦’â£Î¼                       & âŸªread int inputâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘writeâ¦’â£e                      & âŸªwrite outputâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘shareâ¦’[pâ†’p]â£e                 & âŸªshare encrypted valueâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘revealâ¦’[p]â£e                  & âŸªreveal encrypted valueâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ eâ£e                            & âŸªfunction eliminationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘parâ¦’[p]â£e                     & âŸªparallel executionâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘letâ¦’â£x=eâ£â¦‘inâ¦’â£e               & âŸªlet bindingâŸ«
Aâ†
Mâ†
Dâ†
\endgroup
\caption{\mpc Syntax}
\label{fig:mpc-syntax}
Fâ†

The first exotic feature is \emph{located types}. These types are located
in the sense that they can be manipulated only at particular principals.
The metavariable â¸¨mâ¸© represents a set of parties, and a type is written â¸¨Ïƒ@mâ¸©. The \mpc expression
â¸¨â¦‘parâ¦’[p]â£eâ¸© determines the locatedness. It says that â¸¨eâ¸© may be computed at
parties â¸¨pâ¸© in parallel (hence the syntax â¸¨â¦‘parâ¦’â¸©). That is, every
party â¸¨A âˆˆ pâ¸© may evaluate â¸¨eâ¸©. We say ``may'' here because
nesting such an expression in another â¸¨â¦‘parâ¦’â¸© could shrink the set of
parties. For example, â¸¨eâ¸© in â¸¨â¦‘parâ¦’[p]â£(â¦‘parâ¦’[q]â£e)â¸© will be
evaluated by â¸¨p âˆ© qâ¸©; if this intersection is â¸¨Ã¸â¸© then â¸¨eâ¸©
is essentially dead code.

We call the set of parties â¸¨mâ¸© computing an expression in parallel
the \emph{mode}. We say the parties â¸¨A âˆˆ mâ¸© are \emph{present}
for a computation. The semantics of many constructs depends on the
mode. A number $i$ created in mode $m$ (having type â¸¨â¦‘intâ¦’@mâ¸©) is
known only to parties $A \in m$. This means that adding two numbers
located at $p$ can only be done in a mode $m$ such that
$m \subseteq p$; if the mode contained additional parties
$A \not\in p$ then they wouldn't know what to do; such states will be
stuck in our semantics. The same goes for pairs and functions.
The â¸¨â¦‘readâ¦’â£Î¼â¸© and â¸¨â¦‘writeâ¦’â£eâ¸© expressions perform local
I/O and so can only be run in a mode with a single party.

On the other hand, it is possible that a variable $x$ is in scope for
$A$, but maps to a value only known to $B$. Party $A$ can
still manipulate a placeholder for $x$ (e.g., to store it in a
datastructure or pass it to a function) but may never compute with its
contents (e.g., add to it or branch on it). This approach
simplifies the design of the language at the cost of missing some
(unlikely, but ultimately harmless) logic errors.

Generally speaking, \mpc's design aims to ensure that any expression
$e$ of type $\sigma @ m$ will have the \emph{same run-time value} at
each $A \in m$. This is a key invariant underpinning \mpc's sequential
interpretation.

The second exotic feature is \emph{secret share types}.
Base types are annotated with a
\emph{protocol} $\psi$ that indicates whether they are either
cleartext ($\cdot$) or are \emph{encrypted} and shared among parties
$p$. For concreteness, we imagine the encryption protocol is
Goldreich, Widgerson, and Micali (GMW)~\citeyear{STOC:GolMicWig87},
and values of this type are \emph{secret shares}, but the formal
semantics is agnostic to the cryptographic details. Note that we
often just write â¸¨â¦‘intâ¦’â¸© for cleartext integer types, to reduce
clutter (i.e., eliding the $\cdot$).

The \mpc expression â¸¨â¦‘shareâ¦’[pâ†’q]â£eâ¸© directs $p$ (required to be a singleton party set) to
create secret shares of $e$, an integer, and distribute the shares to
each party in
$q$. All parties $p \cup q$ must be present. The resulting value
has type â¸¨â¦‘intâ¦’â¸¢â¦‘encâ¦’â‹•qâ¸£@qâ¸©. This type reads â€œan integer, encrypted
(i.e., secret shared) between parties â¸¨qâ¸©, and accessible to parties
â¸¨qâ¸©â€. The duplication of â¸¨qâ¸© may seem redundant, but they may differ
in other contexts. The first â¸¨qâ¸© represents \emph{who has the
shares} (determined when the share is created), and the second â¸¨qâ¸©
represents \emph{who has access to this value} (determined by the
enclosing â¦‘parâ¦’ blocks). If this encrypted value flows to a part of
the program only executed by â¸¨qâ€² âŠ‚ qâ¸©, then it will not be possible to
recombine shares, since not all parties â¸¨qâ¸© will be present.

Parties $q$ can all mutually compute on a shared, encrypted value
using â¸¨eâ‚ âŠ™ eâ‚‚â¸© and â¸¨e Â¿ eâ‚ â—‡ eâ‚‚â¸©. The latter is a
multiplexor: we select between â¸¨vâ‚â¸© and â¸¨vâ‚‚â¸©, the results of evaluating â¸¨eâ‚â¸© and â¸¨eâ‚‚â¸©,
based on whether $e$ is â¸¨trueâ¸© or â¸¨falseâ¸©. The former models binary operations over numeric and boolean types.
When operating on encrypted values, both the multiplexor and some binary
operation expressions will necessitate \emph{communication} in the
distributed semantics, and an actual implementation will use an
underlying MPC protocol to implement the computation over the encrypted value.
All parties to which a share was sent must be present when computing on it. E.g., for numbers of type
â¸¨â¦‘intâ¦’â¸¢â¦‘encâ¦’â‹•{A,B}â¸£â¸© to be added, both $A$ and $B$ must be
present. Indeed, it must be \emph{exactly} these parties which are
present; we do not allow more, since other parties would not be
able to carry out the operation (they don't have access to the
share).

An MPC is completed by invoking â¸¨â¦‘revealâ¦’[q]â£eâ¸©. This takes a share
(among some set of parties $p$) and converts it to cleartext,
sharing the result among parties $q$. Doing so requires that all of
$p \cup q$ are present so that the shareholders
can agree to send the value, and the result-receivers are ready to
receive it.

The notion of locatedness is crucial in proving that \mpc{} satisfies~\nameref{thm:mpc-simulation}.
The~\nameref{thm:mpc-simulation} property is what allows us to view the language as \textbf{abstractly sequential}. The
next section is dedicated to explaining this property, and highlighting some of its consequences.

\section{Simulation}
\label{sec:lam-mpc-simulation}

\subsection{Sequential Semantics}

\ins{TOOD: put actual figure here?}

The sequential semantics is defined by a judgement â¸¨Ï‚ â†’ Ï‚â¸© which says that
one configuration, â¸¨Ï‚ â©´ m,Î³,Îº,eâ¸©, can step to another. A configuration
â¸¨Ï‚â¸© is a 4-tuple comprising the current mode â¸¨mâ¸©, environment â¸¨Î³â¸©, stack
â¸¨Îºâ¸©, and expression â¸¨eâ¸©. Environments â¸¨Î³ â©´ var â‡€ valueâ¸©, map variables to
values. A stack â¸¨Îºâ¸© is a list of frames â¸¨âŸ¨â¦‘letâ¦’â£x=â–¡â£â¦‘inâ¦’â£eÂ¦m,Î³âŸ©â¸©, where
â¸¨âŠ¤â¸© represents the empty stack. Values, â¸¨v â©´ u@mâ£|â£â˜…â¸©, are either located
values â¸¨uâ¸© at mode â¸¨mâ¸© or else are opaque, â¸¨â˜…â¸©. A located value, â¸¨uâ¸©,
contains all standard values mutually defined on â¸¨vâ¸©, e.g. a pair value is â¸¨âŸ¨v, vâŸ©â¸©.
Base values are tagged with a protocol â¸¨Ïˆâ¸©. For example, a
pair of shares among â¸¨\{A,B\}â¸© is â¸¨âŸ¨iâ‚â¸¢â¦‘encâ¦’â‹•\{A,B\}â¸£@\{A,B\},iâ‚‚â¸¢â¦‘encâ¦’â‹•\{A,B\}â¸£@\{A,B\}âŸ©@\{A,B\}â¸©.

Finally, the semantics heavily relies on a metafunction, â¸¨â€—â†™â‚˜ âˆˆ â€¹valueâ€º â†’ â€¹valueâ€ºâ¸©, which \emph{(re)locates} a
value to a scope with parties â¸¨mâ¸© present. For located values â¸¨u@pâ¸©, â¸¨â€—â†™â‚˜â¸©
relocates them to â¸¨p âˆ© mâ¸©, unless the intersection is empty in which case the
value is inaccessible, so it becomes â¸¨â˜…â¸©. Relocating is a deep operation;
â¸¨u@pâ†™â‚˜â¸© also relocates the contents â¸¨uâ¸© to â¸¨uâ†™â‚˜â¸©, which recurses over
the sub-terms of â¸¨uâ¸©. This step has no effect on closures, though: the closure's
environment's variables get relocated when they are referenced.

The semantics ensure the whenever a located value â¸¨uâ¸© is introduced, it is tagged with
the appropriate mode â¸¨mâ¸© from the current configuration â¸¨Ï‚â¸©. The relocation metafunction
is used on variable access, to relocate a value to the mode of the current lexical scope.
For example, the program â¸¨â¦‘letâ¦’â£x = â¦‘parâ¦’â£[A,B] 10â£â¦‘inâ¦’â£â¦‘parâ¦’â£[A]â£xâ¸© should evaluate to
â¸¨10@{A}â¸©. Likewise, when a value â¸¨u@pâ¸© is eliminated, we check that all necessary parties
are present â¸¨m âŠ† pâ¸©. These two patterns ensure that the sequential semantics will get stuck
whenever a distributed deployment would get stuck. For example, in the program
â¸¨â¦‘parâ¦’â£[A,B]â£(â¦‘parâ¦’â£[A]â£10) + (â¦‘parâ¦’â£[B]â£20)â¸©, the introduction rules for integers ensure that
the inner â¸¨â¦‘parâ¦’â¸© expressions will reduce to â¸¨10@\{A\}â¸© and â¸¨20@\{B\}â¸©. The elimination rule, â¸¨+â¸©,
will check â¸¨\{A,B\} âŠ† \{A\}â¸© and â¸¨\{A,B\} âŠ† \{B\}â¸© which will fail, causing the program to get stuck.

\subsection{Distributed Semantics}

The distributed semantics is defined by a judgement â¸¨D â† Dâ¸© which says that
one distributed configuration, â¸¨D âˆˆ â€¹partyâ€º â‡€ â€¹local-configâ€ºâ¸©, can step to another.
A configuration, â¸¨Dâ¸©, is a partial mapping between parties and their local
view of execution. A â¸¨â€¹local-configâ€ºâ¸© is just like a sequential configuration, â¸¨Ï‚â¸©,
except that the components contain local values, â¸¨â‡¡.vâ¸©. Local values are just like
sequential values, except that location annotations â¸¨â€—@mâ¸© have been stripped away.
For example, a pair of shares among â¸¨\{A,B\}â¸© is â¸¨âŸ¨iâ‚â¸¢â¦‘encâ¦’â‹•\{A,B\}â¸£,iâ‚‚â¸¢â¦‘encâ¦’â‹•\{A,B\}â¸£âŸ©â¸©.

For most expressions, the distributed semantics simply steps an individual party independently of
the rest. To step an individual party, â¸¨Pâ¸©, we execute a step on its local configuration, â¸¨D(P)â¸©.
These individual steps look very similar to sequential steps, except that mode annotation is not added
or checked. A local configuration still has a mode component, because we do need to check that the mode
agrees with, for example, the protocol tag â¸¨â¦‘encâ¦’â‹•qâ¸©. When locally stepping an expression â¸¨â¦‘parâ¦’â£[P]â£â€¦â¸©
we additionally check that â¸¨P âˆˆ pâ¸© where â¸¨Pâ¸© is the whose local configuration we are stepping.

The only expressions which do not step on an
invididual party are the \emph{synchronizing} expressions, â¸¨â¦‘shareâ¦’â¸© and â¸¨â¦‘revealâ¦’â¸©. These expressions
step by transferring data from one party to the other(s), and so the rules maniuplate multiple local
configurations at once. In both the sequential and distributed rules we require that (1) the sharer,
â¸¨pâ¸©, be a singleton â¸¨|p| = 1â¸©, (2) the sharees, â¸¨qâ¸©, be non-empty â¸¨q â‰  Ã¸â¸©, and (3) that only the
sharer and sharees are present â¸¨m = p âˆª qâ¸©. In distributed mode, we move the shared value from â¸¨pâ¸©
to â¸¨qâ¸© by pulling â¸¨â‡¡.vâ¸© from â¸¨D(p)â¸© and updating all the local configurations â¸¨D(q)â¸©.

\subsection{Correspondence}

The key observation that makes these semantics agree is that if the sequential semantics
gets stuck due to an elimination form with a failing mode check then the distributed semantics
will get stuck due to an elimination form attempting to inspect the opaque value â¸¨â˜…â¸©. For example,
let's return to the example â¸¨â¦‘parâ¦’â£[A,B]â£(â¦‘parâ¦’â£[A]â£10) + (â¦‘parâ¦’â£[B]â£20)â¸©. We saw that this expression
gets stuck in the sequential semantics due to a failure of both mode checks when evaluating â¸¨+â¸©:
â¸¨\{A,B\} âŠˆ \{A\}â¸© and â¸¨\{A,B\} âŠˆ \{B\}â¸©. In the distributed semantics, we will execute each party
independently, eventually arriving at â¸¨10 + â˜…â¸© on $A$ and â¸¨â˜… + 20â¸© on $B$. Both parties will get
stuck, and the entire distributed configuration will be stuck.

We can state our formal correspondence between the sequential and distributed semantics formally
as~\nameref{thm:mpc-simulation}. This theorem says that for any well-typed sequential configuration,
â¸¨Ï‚â¸©, â¸¨Ï‚â¸© successfully terminates as â¸¨Ï‚'â¸© if and only if the corresponding distributed configuration
â¸¨Ï‚â†¯â¸© successfully terminates as â¸¨Ï‚'â†¯â¸©. The â¸¨â€—â†¯â¸© metafunction takes a sequential configuration to an
appropriate distributed configuration. We call it this metafunction \emph{slicing} since it ``slices''
away all of the mode annotations appropriately, leaving a distributed configuration in which each
party is mapped to a local configuration containing only local values which that party knows.

The forward direction of~\nameref{thm:mpc-simulation} is proved by induction. The backward direction
requires that we first establish that the distributed semantics enjoys \emph{confluence}. Confluence
says that any executions beginning with the same configuration must eventually arrive at a shared
configuration. For the distributed semantics, this means that for any distributed configuration â¸¨Dâ¸©,
if â¸¨D â†â‹† Dâ‚â¸© and â¸¨D â†â‹† Dâ‚‚â¸© then there must be a â¸¨D'â¸© such that â¸¨Dâ‚ â†â‹† D'â¸© and â¸¨Dâ‚‚ â†â‹† D'â¸©. The backward
direction can then be established by appealing to the forward direction, using confluence to rule out the
possibility of rogue executions.

\begin{theorem}[Forward Simulation] \label{thm:mpc-simulation}
  â¸¨âˆ€â£âŠ¢ Ï‚â¸©, â¸¨Ï‚ â€”â†’â‹† Ï‚'â¸© and â¸¨Ï‚'â¸© is terminal â¸¨âŸºâ¸© â¸¨Ï‚â†¯ â†â‹† Ï‚'â†¯â¸© and â¸¨Ï‚'â†¯â¸© is terminal.
\end{theorem}

Intuitively,~\nameref{thm:mpc-simulation} tells us that all well-typed, terminating programs
will give us the same answer whether they are executed in the sequential or distributed semantics.
This makes precise what it means for a language to be a \textbf{abstractly sequential}. Programmers
can reason about the behavior of their program without considering all the possible interleaved
executions that a deployment may encounter.

\section{Symphony: An Interpreter for \mpc}

\ins{TODO}

\chapter{\obliv, A Language for Probabilistically Oblivious Computation}
\label{ch:lam-obliv}

\ins{The goal is to sufficiently explain~\nameref{thm:obliv-pmto}.}

\begin{theorem}[PMTO] \label{thm:obliv-pmto}
  If â¸¨eâ‚ : Ï„â¸©, â¸¨eâ‚‚ : Ï„â¸©, â¸¨eâ‚ â‰ˆâ¸¤lâ¸¥ eâ‚‚â¸©, â¸¨eâ‚ â‡¢â‹† â‡¡~{tâ‚}â¸©, and â¸¨eâ‚‚ â‡¢â‹† â‡¡~{tâ‚‚}â¸©, then â¸¨â‡¡~{tâ‚} â‡¡~â‰ˆâ¸¤lâ¸¥ â‡¡~{tâ‚‚}â¸©.
\end{theorem}

In other words, if two expressions cannot be distinguished from each other, then neither can the distributions of memory traces
that their executions emit.

Fâ…
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
Dâ…
Mâ…
AËrcrcl@{â }l
Aâ… b   â§¼âˆˆâ§½ ğ”¹           â§¼ â§½                               & âŸªbooleansâŸ«
Aâƒ i   â§¼âˆˆâ§½ â„¤           â§¼ â§½                                & âŸªintegersâŸ«
Aâƒ â„“   â§¼âˆˆâ§½ â€¹labelâ€º     â§¼â©´â§½ â€¹Pâ€º Â¦ â€¹Sâ€º                     & âŸªpublic and secretâŸ«
Aâƒ     â§¼ â§½ ğ‘šğ‘3c{âŸª(Â«whereÂ» â¸¨â€¹Pâ€ºâŠâ€¹Sâ€ºâ¸©)âŸ«}                   & âŸªsecurity labelsâŸ«
Aâƒ Ï   â§¼âˆˆâ§½ R           â§¼ â§½                               & âŸªprobability regionâŸ«
Aâƒ Î¼   â§¼âˆˆâ§½ â€¹base-typeâ€º â§¼â©´â§½ â¦‘intâ¦’                         & âŸªinteger typeâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘boolâ¦’                         & âŸªboolean typeâŸ«
Aâƒ Ï„   â§¼âˆˆâ§½ â€¹typeâ€º      â§¼â©´â§½ Î¼â¸¤â„“â¸¥â¸¢Ïâ¸£                        & âŸªnon-random base typeâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘Â½â¦’ Î¼â¸¤â€¹Sâ€ºâ¸¥â¸¢Ïâ¸£                   & âŸªsecret uniform boolâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ Ï„ Ã— Ï„                          & âŸªtupleâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ Ï„ â†’ Ï„                          & âŸªfunctionâŸ«
Aâƒ x,y â§¼âˆˆâ§½ â€¹varâ€º       â§¼ â§½                                 & âŸªvariablesâŸ«
Aâƒ âŠ™   â§¼âˆˆâ§½ â€¹binopâ€º     â§¼ â§½                                & âŸªbinary operations (e.g., plus, times)âŸ«
Aâƒ e   â§¼âˆˆâ§½ â€¹exprâ€º      â§¼â©´â§½ x                              & âŸªvariable referenceâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ iâ¸¤â„“â¸¥                            & âŸªinteger literalâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ bâ¸¤â„“â¸¥                            & âŸªboolean literalâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ e âŠ™ e                          & âŸªbinary operationâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ e Â¿ e â—‡ e                      & âŸªatomic conditionalâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ âŸ¨e,eâŸ©                           & âŸªtuple creationâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘letâ¦’â£x,y = eâ£â¦‘inâ¦’â£e            & âŸªtuple eliminationâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ Î»â¸¤zâ¸¥xâª e                       & âŸª(recursive) function creationâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘unifâ¦’â¸¢Ïâ¸£â£Î¼                      & âŸªuniform, random sample in regionâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘castâ¦’â¸¤lâ¸¥â£x                    & âŸªcast from uniformâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ eâ£e                            & âŸªfunction eliminationâŸ«
Aâƒ     â§¼ â§½             â§¼Â¦â§½ â¦‘letâ¦’â£x = eâ£â¦‘inâ¦’â£e               & âŸªvariable bindingâŸ«
Aâ†
Mâ†
Dâ†
\endgroup
\caption{\obliv Syntax}
\label{fig:obliv-syntax}
Fâ†

\chapter{Proposal: \lang, A Secure MPC Language With User-Defined ORAM}
\label{ch:proposal}

\ins{Just describe the language as best you can, and then imagine doing the actual work and anticipate, write down issues.
  For example, when describing re-establishing simulation, describe issue w/ making sequential interpretation probabilistic.
  Should we allow uniform, random stuff which is not secret shared? Arguments for yes: labels are a combination of locatedness
  and protocol. Arguments for no: involves communicating between parties w/o secret sharing, also may not be useful.
  How do we establish PMTO\% when we are allowed to cast uniform values to public? It was important in lam-obliv that when you
  casted to secret that implied the value wouldn't be revealed.}

We will construct the \lang language by adding two features from the \obliv language to \mpc. In particular, \mpc lacks
the ability to draw uniform, random samples and to

Having seen \mpc and \obliv formally, we are now in a position to explain how the MPC language, \lang, will be constructed.
We will start by making \lang \textbf{probabilistic} by extending \mpc with a feature for uniform, random sampling. This new
feature will be analogous to the â¸¨â¦‘unifâ¦’â¸© feature of \obliv. By extending \mpc we expect that the language will already be ``mostly''
\textbf{abstractly centralized}. However, we will need to establish this formally by proving that \lang satisfies an appropriate
version of the~\nameref{thm:mpc-simulation} theorem from~\cref{sec:lam-mpc-simulation}. Finally, \lang will be made
\textbf{high assurance} by extending \lang with a feature for zero-information declassification of random values. This feature
is analogous to the â¸¨â¦‘castâ¦’â¸© feature of \obliv. We intend for the type system to ensure that uses of â¸¨â¦‘castâ¦’â¸© are appropriate
--- i.e. that they really don't reveal any information to other parties. Achieving this will require updating the type system
of \lang with the affinity and probability region features of the \obliv language. Again, we will need to establish that the
type system achieves its goal by proving~\nameref{thm:lang-pmto}.

As a means of confirming that \lang is useful, we will build on the existing Haskell implementation of \mpc. That implementation
includes only a centralized interpreter which does not actually perform any MPC. Adding on to this centralized interpreter, we will
add a distributed interpreter which uses the EMP MPC framework as the MPC backend. Finally, we will implement a type checker based
on the formal type system. Having done this, we will implement a number of case studies in \lang. At a minimum, we will implement
the ORAM schemes described in~\cref{ch:oram} --- Trivial ORAM, Circuit ORAM, and Recursive (Circuit) ORAM. Having done so, we will
have confirmed our type system is expressive enough to type check state of the art ORAM protocols. Finally, using our distributed
interpreter we will confirm that the ORAM schemes have the expected asymptotic complexity (and should therefore be competitive with
the ORAM protocols in existing languages like Obliv-C and SCALE-MAMBA).

\section{Design}

The syntax of \lang is shown in~\cref{fig:lang-syntax}. The security label lattice is the same as
the \mpc language. Labels are a combination of location and protocol. As such, we no longer need the â¸¨â€¹Pâ€ºâ¸© and â¸¨â€¹Sâ€ºâ¸© labels
of \obliv. \lang takes the uniform type of \obliv and adds a protocol to it, â¸¨â¦‘Â½â¦’ Î¼â¸¢Ï ; Ïˆâ¸£â¸©, indicating that random values
can be shared. The atomic conditional works as described in \obliv, returning a tuple of its arguments in-order if the guard
is true, and permuted otherwise. As in \obliv, this is necessary in an affine type system. Tuple elimination is now by
pattern-matching instead of projection, again for compatibility with affinity. The only non-trivial change is the additon of
uniform sampling, â¸¨â¦‘unifâ¦’â¸¢Ïâ¸£â£Î¼â¸©, and casting, â¸¨â¦‘castâ¦’â¸¤Ïˆâ¸¥[p]â£xâ¸©.

\ins{observation: pmto is hard when you are allowed to declassify b/c casting to secret doesn't imply that value will never be revealed.} \\

\ins{The goal is to sufficiently explain~\nameref{thm:lang-simulation} and~\nameref{thm:lang-pmto}.}

\begin{theorem}[Forward Simulation] \label{thm:lang-simulation}
  If â¸¨Ï‚ â€”â†’â‹† â‡¡~{Ï‚â€²}â¸©, â¸¨â‡¡~{Ï‚â€²}â¸© is terminal, â¸¨Ï‚â†¯ â†â‹† â‡¡~{G}â¸© and â¸¨â‡¡~{G} â«½â†â¸©, then â¸¨â‡¡~{G} = â‡¡~{Ï‚â€²}â†¯â¸©.
\end{theorem}

\begin{theorem}[PMTO\%] \label{thm:lang-pmto}
  If â¸¨Ï‚â‚ : Ï„â¸©, â¸¨Ï‚â‚‚ : Ï„â¸©, â¸¨Ï‚â‚ â‰ˆâ¸¤lâ¸¥ Ï‚â‚‚â¸©, â¸¨Ï‚â‚ â‡¢â‹† â‡¡~{tâ‚}â¸©, â¸¨Ï‚â‚‚ â‡¢â‹† â‡¡~{tâ‚‚}â¸©, and â¸¨Râ¸¤lâ¸¥(â‡¡~{tâ‚}) = Râ¸¤lâ¸¥(â‡¡~{tâ‚‚})â¸©, then â¸¨â‡¡~{tâ‚} â‡¡~â‰ˆâ¸¤lâ¸¥ â‡¡~{tâ‚‚}â¸©.
\end{theorem}

Fâ…
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
Dâ…
Mâ…
AËrcrcl@{â }l
Aâ… b     â§¼âˆˆâ§½ ğ”¹            â§¼ â§½                                & âŸªbooleansâŸ«
Aâƒ i     â§¼âˆˆâ§½ â„¤            â§¼ â§½                                & âŸªintegersâŸ«
Aâƒ A,B,C â§¼âˆˆâ§½ â€¹partyâ€º      â§¼ â§½                                & âŸªpartiesâŸ«
Aâƒ m,p,q â§¼âˆˆâ§½ â€¹party-setâ€º  â§¼â‰œâ§½ â„˜(â€¹partyâ€º) â©´ â´A,â€¦,Aâµ           & âŸªsets of partiesâŸ«
Aâƒ Ï     â§¼âˆˆâ§½ R           â§¼ â§½                               & âŸªprobability regionâŸ«
Aâƒ Ïˆ     â§¼âˆˆâ§½ â€¹protâ€º       â§¼â©´â§½ â‹…                              & âŸªcleartextâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘encâ¦’â‹•m                        & âŸªencryptedâŸ«
Aâƒ Î¼     â§¼âˆˆâ§½ â€¹base-typeâ€º  â§¼â©´â§½ â¦‘intâ¦’                         & âŸªinteger typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘boolâ¦’                         & âŸªboolean typeâŸ«
Aâƒ Ïƒ     â§¼âˆˆâ§½ â€¹loc-typeâ€º   â§¼â©´â§½ Î¼â¸¢Ï ; Ïˆâ¸£                          & âŸªprotocol typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘Â½â¦’ Î¼â¸¢Ï ; Ïˆâ¸£                   & âŸªuniform typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Ï„ áµâ†’ Ï„                         & âŸªfunction typeâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Ï„ Ã— Ï„                          & âŸªpair typeâŸ«
Aâƒ Ï„     â§¼âˆˆâ§½ â€¹typeâ€º       â§¼â©´â§½ Ïƒ@m                            & âŸªlocated typeâŸ«
Aâƒ x,y,z â§¼âˆˆâ§½ â€¹varâ€º        â§¼ â§½                                & âŸªvariablesâŸ«
Aâƒ âŠ™     â§¼âˆˆâ§½ â€¹binopâ€º      â§¼ â§½                                & âŸªbinary operations (e.g., plus, times)âŸ«
Aâƒ e     â§¼âˆˆâ§½ â€¹exprâ€º       â§¼â©´â§½ x                              & âŸªvariable referenceâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ i                              & âŸªinteger literalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ b                              & âŸªboolean literalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ e âŠ™ e                          & âŸªbinary operationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ e Â¿ e â—‡ e                      & âŸªatomic conditionalâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ âŸ¨e,eâŸ©                          & âŸªpair creationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘letâ¦’â£x,y = eâ£â¦‘inâ¦’â£e            & âŸªtuple eliminationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘parâ¦’[p]â£e                     & âŸªparallel executionâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘readâ¦’â£Î¼                       & âŸªread int inputâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘writeâ¦’â£e                      & âŸªwrite outputâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘embedâ¦’[p]â£e                   & âŸªencrypted a known constantâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘shareâ¦’[pâ†’p]â£e                 & âŸªshare encrypted valueâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘declassifyâ¦’[p]â£e              & âŸªdeclassify encrypted valueâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘unifâ¦’â¸¢Ïâ¸£â£Î¼                  & âŸªuniform, random sample in regionâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘castâ¦’â¸¤Ïˆâ¸¥[p]â£x                    & âŸªcast from uniformâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ Î»â¸¤zâ¸¥xâª e                       & âŸª(recursive) function creationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ eâ£e                            & âŸªfunction eliminationâŸ«
Aâƒ       â§¼ â§½              â§¼Â¦â§½ â¦‘letâ¦’â£x=eâ£â¦‘inâ¦’â£e               & âŸªlet bindingâŸ«
Aâ†
Mâ†
Dâ†
\endgroup
\caption{\mpc Syntax}
\label{fig:lang-syntax}
Fâ†

\section{Implementation}

We must now consider if the formal language we have designed is useful. Can we write interesting programs in the language?
Will those programs be efficient? Questions such as these must be answered empirically. We will address both of these questions
using the ORAM protocols described in~\cref{ch:oram}. In particular, since we are claiming that our type system has a very powerful
property ---~\cref{thm:lang-pmto} --- we might also expect it to be very restrictive. How do we know it actually accepts the ORAM
protocols we would like to prove are oblivious? For this reason, we take ORAM protcols to be representative ``interesting programs.''

The \mpc language has an existing Haskell interpreter. However, this interpreter only implements the centralized semantics of \mpc.
In particular, it doesn't actually perform any MPC and doesn't run as multiple communicating processes. Our first implementation
goal will be to extend the existing interpreter to also support a distribued mode. We have already partially completed this task
by implementing a Haskell FFI to the C++ bindings for EMP. The prototype distributed mode is capable of sharing integers, performing
primitive operations (e.g. addition, comparison), and revealing the result. For example, we have successfully implemented the Millionaire's Problem
from~\ref{sec:background-symphony}. There is more work to support ORAM -- we will need to handle random numbers, references, and
more primitive operations at a minimum. Furthermore, since EMP is limited to two parties, so too is our distributed mode.

The existing \mpc implementation does not have a type checker. We will first add the type checker of \mpc to the implementation without
the additional features (affinity, probability regions) required for \lang. This type system should be sufficient for checking, for example,
that Trivial ORAM\footnote{Interestingly, this will already confirm that Trivial ORAM in the MPC model is~\ref{thm:mpc-mto}.}. Then, we will
add the challenging features of affinity and probability regions. In prior work, we implemented the type system of \obliv and used it to
type check various ORAM case studies. We expect that we will be able to use our experience from that artifact here.

Finally, we can address the two empirical questions mentioned above. First, we will implement the ORAM protocols in our language and confirm
that they type check (and are therefore oblivious). Second, with our distributed mode, we will confirm that the ORAM protocols have the
expected asymptotic behavior. We will perform a series of experiments in which \ins{todo: similar to experiments in FLORAM paper}
This will confirm that our language can support RAM-model computation which is competitive with existing languages that offer ORAM support
(e.g. Obliv-C, SCALE-MAMBA).


\ins{mention somewhere that these ORAM implementations are different from the ones in \obliv -- these are not client-server but instead in
  the ORAM-SC model in which neither party knows the position tag of inserted elements.}

\chapter{Open Problems}

We briefly discuss some important open problems which affect the design of languages for
MPC and obliviousness. These are not addressed by \lang and I feel that they are promising
areas for future research.

\paragraph{Resource Awareness}
MPC programs are expensive. Something something orders of magnitude slower~\cite{}. This due principally to the communication
required. For example in GMW, an AND gate requires a round of communication and the 1-4 OT requires an encryption scheme.
Programmers who are not experts in MPC will require information about the cost of the programs they are writing. This could be
handled elegantly by the language. There is ample research in type-based resource analysis~\cite{}, for example. \ins{TODO: this is rough}

\paragraph{Oblivious Data Structures}
Our prior work has shown that Oblivious Data Structures (ODS's), proposed by Wang et al., do not satisfy PMTO.\ins{replace with ref. to theorem} Even though ODS's are safe due to negligibl overflow probability, we are unable to verify that fact in \lang. We would like to find some
way to support ODS's within the language while retaining the security guarantees provided by the tyep system.

\paragraph{Other Security Policies}
PMTO\% is perhaps the most obvious security policy one could prove about MPC programs which admit ORAM. However, it is not the only property
one could prove. There is a rich literature of different declassification policies, as well as weaker variants of (P)MTO like Differential
MTO~\cite{} and manual computational proofs of securit with explicit complexity-theoretic reductions~\cite{easycrypt}.

\paragraph{Usability of Abstractly Centralized Languages}
We make claims in this proposal that abstractly centralized languages are a good choice for MPC. We justify this claim by arguing that
programmers need not think about the distributed deployment of their program. Furthermore, the type safety theorem for the centralized
semantics implies safety of the distributed semantics. However, a more empirical approach to the question of usability is warranted.
A user study comparing two languages, one of which exposes more of the distributed computation, would lend more credibility to our claim
that abstractly centralized languages are preferable.

\paragraph{Support for PIR-based ORAM}
The most efficient modern ORAM schemes in the MPC context use Private Information Retrieval (PIR) protocols. These protocols rely on
features such as function secret sharing and cryptographic pseudo-random functions.

\appendix

\chapter{The GMW Protocol}
\label{ch:gmw}

MPC works by allowing a secret, in cleartext, to be split up into many ``shares'' which are considered ciphertext
and therefore may be safely distributed to other parties and recombined later. More specifically, shares have the following properties:
\begin{enumerate}
\item Shares can be combined to reveal the original cleartext secret.
\item A share does not reveal any information about the secret.
\item Parties can cooperate to compute over shares. For example, being able to create shares of boolean values
  and compute XOR and AND over those shares forms a complete basis for computation. Primitives such as addition,
  comparison, etc. can be built from these boolean operations.
\end{enumerate}

The languages discussed in this proposal are agnostic to the underlying MPC protocol. We only require that the underlying MPC protocol
have the properties listed above. For the purposes of exposition, however, we choose to use the GMW protocol [cite] as a
representative for MPC protocols in general.

In GMW, the secrets being shared are booleans. To represent integers with arithmetic, comparison, etc. we use a two's
complement representation. For example, a digital circuit with only XOR and AND gates can be used to half adders,
full-adders, and ripple-carry adders. A party \alice can generate her share of her (boolean) secret \aliceSec by
generating a random number:

Mâ…
\aliceSh{\aliceSec} â† ğ’°(â´0,1âµ)
Mâ†

The notation â¸¨âŒŠvâŒ‹â¸¤Pâ¸¥â¸© indicates that this is â¸¨Pâ¸©'s share of the value â¸¨vâ¸©. Then, \alice generates \bob's share of \aliceSec
as the XOR of her share with the original secret:

Mâ…
\bobSh{\aliceSec} â† \aliceSh{\aliceSec} âŠ• \aliceSec
Mâ†

At this point, there are a few important things to notice. First, \bob's share is effectively another random number.
As long as he never sees \aliceSh{\aliceSec} he can't distinguish his share \bobSh{\aliceSec} from a fresh, uniform
boolean value. This establishes property (2) of MPC above. Second, XOR has the following properties:

\begin{fact}[â¸¨âŠ•â¸©-Inverse]
\label{fact:xor-inverse}
  â¸¨âˆ€ b âˆˆ ğ”¹â£.â£b âŠ• b = 0â¸©
\end{fact}

\begin{fact}[â¸¨âŠ•â¸©-Identity]
\label{fact:xor-identity}
  â¸¨âˆ€ b âˆˆ ğ”¹â£.â£b âŠ• 0 = 0 âŠ• b = bâ¸©
\end{fact}

These two properties ensure that the original secret, \aliceSec, can be recovered by XOR'ing the shares together:

Mâ…
  AËllll
  Aâ… \aliceSh{\aliceSec} âŠ• \bobSh{\aliceSec} â§¼=â§½ \aliceSh{\aliceSec} âŠ• \aliceSh{\aliceSec} âŠ• \aliceSec & â âŸ… by \bobSh{\aliceSec} âŸ†
  Aâƒ                                         â§¼=â§½ 0 âŠ• \aliceSec & â âŸ… by \nameref{fact:xor-inverse} âŸ†
  Aâƒ                                         â§¼=â§½ \aliceSec & â âŸ… by \nameref{fact:xor-identity} âŸ†
  Aâ†
Mâ†

which establishes MPC property (1) above. Now, let's assume that \bob executes the same protocol to share his secret, \bobSec,
with \alice by splitting it into \aliceSh{\bobSec} and \bobSh{\bobSec}. So, at this point \alice has her shares of both secrets
and similarly for \bob. How can we accomplish property (3) of MPC? To compute â¸¨\aliceSec âŠ• \bobSecâ¸© we can simply have \alice and \bob
evaluate the XOR of their shares independently:

Mâ…
  AËllll
  Aâ… \aliceSh{Aâ¸¨ \aliceSec âŠ• \bobSec Aâ¸©} â§¼â†â§½ \aliceSh{\aliceSec} âŠ• \aliceSh{\bobSec}
  Aâƒ \bobSh{Aâ¸¨ \aliceSec   âŠ• \bobSec Aâ¸©} â§¼â†â§½ \bobSh{\aliceSec}   âŠ• \bobSh{\bobSec}
  Aâ†
Mâ†

Why does this work? Well, it's because XOR is associative:

Mâ…
  AËllll
  Aâ… \aliceSh{\aliceSec âŠ• \bobSec} âŠ• \bobSh{\aliceSec âŠ• \bobSec} â§¼=â§½
      (\aliceSh{\aliceSec} âŠ• \aliceSh{\bobSec}) âŠ• (\bobSh{\aliceSec} âŠ• \bobSh{\bobSec}) & â âŸª[Definition of XOR of shares]âŸ«
  Aâƒ â§¼=â§½
      (\aliceSh{\aliceSec} âŠ• \bobSh{\aliceSec}) âŠ• (\aliceSh{\bobSec} âŠ• \bobSh{\bobSec}) & â âŸª[Associativity of XOR]âŸ«
  Aâƒ â§¼=â§½
      \aliceSec âŠ• \bobSec & â âŸª[Share Recovery]âŸ«
  Aâ†
Mâ†

Now for the tricky bit. How do we compute â¸¨\aliceSec âˆ§ \bobSecâ¸©? To describe this gate we assume that we have access to a
protocol called 1-4 Oblivious Transfer (OT). This protocol allows a sender, â¸¨Sâ¸©, to send 4 messages to a receiver, â¸¨Râ¸©, in such a
way that (a) â¸¨Râ¸© is only allowed to see 1 of the 4 messages and (b) â¸¨Sâ¸© cannot tell which message â¸¨Râ¸© chose.

Assuming that we have access to such a protocol, we can compute \alice's share of the AND very simply:

Mâ…
  AËllll
  Aâ… \alices{Ïƒ}                          â§¼â†â§½ ğ’°(â´0,1âµ)
  Aâƒ \aliceSh{Aâ¸¨ \aliceSec âˆ§ \bobSec Aâ¸©} â§¼â†â§½ \alices{Ïƒ}
  Aâ†
Mâ†

Now, we still need to figure out how \bob will compute his share of the AND. This will involve the 1-4 OT protocol in which \alice is the
sender and \bob is the receiver. Consider Table~\ref{tab:and-ot}, which is constructed by \alice. Each row indicates one of the possible
outcomes for \bob's shares, \bobSh{\aliceSec} and \bobSh{\bobSec}.

\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    \bobSh{\aliceSec} & \bobSh{\bobSec} & Aâ¸¨ \aliceSh{\aliceSec} âŠ• \bobSh{\aliceSec} âˆ§ \aliceSh{\bobSec} âŠ• \bobSh{\bobSec} Aâ¸© & â¸¨râ¸© \\ \hline
    â¸¨0â¸© & â¸¨0â¸© & Aâ¸¨ Î±â¸¤0,0â¸¥ = \aliceSh{\aliceSec} âŠ• 0 âˆ§ \aliceSh{\bobSec} âŠ• 0 Aâ¸© & Aâ¸¨ râ¸¤0,0â¸¥ = \alices{Ïƒ} âŠ• Î±â¸¤0,0â¸¥ Aâ¸© \\ \hline
    â¸¨0â¸© & â¸¨1â¸© & Aâ¸¨ Î±â¸¤0,1â¸¥ = \aliceSh{\aliceSec} âŠ• 0 âˆ§ \aliceSh{\bobSec} âŠ• 1 Aâ¸© & Aâ¸¨ râ¸¤0,1â¸¥ = \alices{Ïƒ} âŠ• Î±â¸¤0,1â¸¥ Aâ¸© \\ \hline
    â¸¨1â¸© & â¸¨0â¸© & Aâ¸¨ Î±â¸¤1,0â¸¥ = \aliceSh{\aliceSec} âŠ• 1 âˆ§ \aliceSh{\bobSec} âŠ• 0 Aâ¸© & Aâ¸¨ râ¸¤1,0â¸¥ = \alices{Ïƒ} âŠ• Î±â¸¤1,0â¸¥ Aâ¸© \\ \hline
    â¸¨1â¸© & â¸¨1â¸© & Aâ¸¨ Î±â¸¤1,1â¸¥ = \aliceSh{\aliceSec} âŠ• 1 âˆ§ \aliceSh{\bobSec} âŠ• 1 Aâ¸© & Aâ¸¨ râ¸¤1,1â¸¥ = \alices{Ïƒ} âŠ• Î±â¸¤1,1â¸¥ Aâ¸© \\ \hline
  \end{tabular}
  \caption{Bâ¸¨testingBâ¸©\ins{TODO: couldn't figure out how to use colored math in here without an error.}}
  \label{tab:and-ot}
\end{table}

If \alice now sends â¸¨(râ¸¤0,0â¸¥,â£râ¸¤0,1â¸¥,â£râ¸¤1,0â¸¥,â£râ¸¤1,1â¸¥)â¸© via 1-4 OT to \bob, then \bob can select the message which corresponds the outcome
of his shares. For example, if \bob's shares are â¸¨\bobSh{\aliceSec} = \bobSh{\bobSec} = 0â¸© then he would select â¸¨râ¸¤0,0â¸¥â¸© (corresponding
to the first row in Table~\ref{tab:and-ot}).

Mâ…
  AËllll
  Aâ… \bobSh{\aliceSec âˆ§ \bobSec} â§¼â†â§½ râ£â€¹whereâ€ºâ£& r = râ¸¤0,0â¸¥â£â€¹ifâ€ºâ£\bobSh{\aliceSec} = 0â£â€¹andâ€ºâ£\bobSh{\bobSec} = 0
  Aâƒ & & & r = râ¸¤0,1â¸¥â£â€¹ifâ€ºâ£\bobSh{\aliceSec} = 0â£â€¹andâ€ºâ£\bobSh{\bobSec} = 1
  Aâƒ & & & r = râ¸¤1,0â¸¥â£â€¹ifâ€ºâ£\bobSh{\aliceSec} = 1â£â€¹andâ€ºâ£\bobSh{\bobSec} = 0
  Aâƒ & & & r = râ¸¤1,1â¸¥â£â€¹ifâ€ºâ£\bobSh{\aliceSec} = 1â£â€¹andâ€ºâ£\bobSh{\bobSec} = 1
  Aâ†
Mâ†

Finally, let's check that this is correct and secure. First, correctness:

Mâ…
  AËllll
  Aâ… \aliceSh{\aliceSec âˆ§ \bobSec} âŠ• \bobSh{\aliceSec âˆ§ \bobSec} â§¼=â§½ \alices{Ïƒ} âŠ• (\alices{Ïƒ} âŠ• Î±â¸¤i,jâ¸¥) & â âŸª[Definition of â¸¨âˆ§â¸©]âŸ«
  Aâƒ & & â€¹whereâ€ºâ£i = \bobSh{\aliceSec}â£â€¹andâ€ºâ£j = \bobSh{\bobSec}
  Aâƒ â§¼=â§½ Î±â¸¤i,jâ¸¥ & â âŸª[Fact~\ref{xor-inverse}]âŸ«
  Aâƒ â§¼=â§½ \aliceSh{\aliceSec} âŠ• \bobSh{\aliceSec} âˆ§ \aliceSh{\bobSec} âŠ• \bobSh{\bobSec} & â âŸª[Definition (by OT on Table~\ref{tab:and-ot})]âŸ«
  Aâƒ â§¼=â§½ \aliceSec âˆ§ \bobSec & â âŸª[Share Recovery]âŸ«
  Aâ†
Mâ†

Now, why is this secure? The security relies crucially on the properties of 1-4 OT. If \alice could tell which message \bob chose she would
immediately learn the values of \bob's shares and be able to recover \bob's secret. However, 1-4 OT guarantees that \alice cannot tell
which message \bob chose. Likewise, if \bob were able to see more than one of the messages sent by \alice then â¸¨Î± âŠ• \alices{Ïƒ}â¸© would not
sufficiently protect â¸¨Î±â¸©\footnote{More formally, the XOR with a random value forms a one-time pad (OTP) encryption scheme, which is only secure
  if the key is never reused.}. However, 1-4 OT guarantees that \bob can only see the message that he chooses.

\chapter{Oblivious RAM}
\label{ch:oram}


\end{document}
