\documentclass{report}

\usepackage{epigraph}
\usepackage{colortbl}
\usepackage{xspace}
\usepackage{listings}
\usepackage{relsize}

\input{darais-latex-imports}
\input{darais-latex-macros}

\newcommand{\lang}{Allyn\xspace}
\newcommand{\mpc}{\ensuremath{\lambda_{\mathrm{MPC}}}\xspace}
\newcommand{\obliv}{\ensuremath{\lambda_{\mathrm{Obliv}}}\xspace}

\newcommand{\ins}[1]{\textcolor{red}{Ian: #1}}

%%% Macros for MPC
\newcommand{\alice}{B⸨‹Alice›B⸩\xspace}
\newcommand{\bob}{C⸨‹Bob›C⸩\xspace}

\newcommand{\alices}[1]{B⸨#1⸤A⸥B⸩}
\newcommand{\bobs}[1]{C⸨#1⸤B⸥C⸩}

\newcommand{\aliceSec}{\alices{s}\xspace}
\newcommand{\bobSec}{\bobs{s}\xspace}

\newcommand{\aliceSh}[1]{\alices{⌊#1⌋}}
\newcommand{\bobSh}[1]{\bobs{⌊#1⌋}}

\newcommand{\opaque}{A⸨★A⸩\xspace}
%%%

%%% Macros from Symphony Paper
\newcommand{\eset}{⸨∅⸩}
%%%

\definecolor{implColor}{HTML}{EA9999}
\definecolor{theoryColor}{HTML}{A4C2F4}

\begin{document}

\title{A Programming Language for Obliviousness and Secure Computation}

\author{Ian Sweet \\
  \emph{University of Maryland, College Park} \\
  \emph{ins@cs.umd.edu}}

\date{}

\maketitle

\begin{abstract}
  \emph{Secure Multiparty Computation} (MPC) and \emph{Oblivious RAM} (ORAM) have emerged as promising approaches to
  confidential computation. Traditionally, MPC programs do not allow secrets to be used as indexes to dynamically
  allocated memory. This precludes, for example, a secure binary search in which the element being accessed is considered secret.
  This restriction is relaxed by using ORAM inside of the secure computation. Unfortunately, existing languages for MPC typically
  support ORAM by ``baking it in'' to the language as a trusted primitive. We propose the design and implementation of a language
  for MPC with \emph{application-level support} for ORAM with an associated \emph{proof of security}.

  \ins{TODO: generalize from ORAM to obliviousness in general}
\end{abstract}

\tableofcontents

\chapter{Introduction}
\label{ch:intro}

\epigraph{It seems like everywhere I go \\
          The more I see, the less I know}{
            Michael Franti \& Spearhead \\
            \emph{Say Hey I Love You}}

If our adversaries were more like Michael Franti then we wouldn't need to concern ourselves with privacy.
Unfortunately, that isn't the world we live in. People have a right to privacy and programming languages have
a duty to honor that right. In other words, programming languages have a duty of confidentiality. What do such
languages look like? How might they be improved?

\section{Secure Multiparty Computation and Obliviousness}
\label{sec:intro}

\emph{Secure Multiparty Computation} (MPC) is a subfield of cryptography
that allows mutually untrusting parties to compute arbitrary functions over their private inputs while revealing nothing
except the function output. That is, MPC allows parties to work together to run programs \emph{under encryption}.

Approaches to MPC have improved significantly over the years. The first full implementation, FairPlay~\cite{todo}, could evaluate
only a few hundred Boolean gates pers second. Modern implementations on custom setups evaluate \emph{billions} of Boolean gates per
second~\cite{todo}, and cryptographers continue to reduce the cost of MPC. Despite increasing efficiency and compelling applications
(secure auctions, secure databases, collaborative machine learning, and any other imaginable application with security concerns),
MPC has not been widely adopted. One significant barrier to adoption is a lack of appropriate infrastructure. Today, it is difficult
for non-experts to understand and work in the complex distributed model that MPC requires.

In addition to lack of infrastructure, languages for MPC also fail to provide adequate support for RAM-model programming. The standard
means by which RAM-model computation is supported in MPC languages is using \emph{Oblivious RAM} (ORAM). To date, most MPC languages
simply do not provide any access to ORAM. In their 2019 SoK,~\citet{todo} observe that only a ``few frameworks have ORAM support, either
natively (ObliVM and SCALE-MAMBA) or via a library (Obliv-C).'' The three languages mentioned, ObliVM~\cite{todo}, SCALE-MAMBA~\cite{todo}, and
Obliv-C~\cite{todo}, are \textbf{probabilistic} MPC languages. According to~\citet{todo}, a language must have support for sampling
from a uniform, random distribution to admit asymptotically optimal ORAM.
Indeed, each of these languages provides a highly optimized implementation of
Circuit ORAM~\cite{todo}, which is known to be asymptotically optimal (i.e. $O(\log{n})$). However, these languages could be improved by
being \textbf{abstractly centralized} and \textbf{high assurance}. An \textbf{abstractly centralized} language hides, as much as possible,
the distributed deployment of the MPC program from the programmer. Examples of existing languages which are abstractly centralized are
SCVM~\cite{todo}, Wysteria~\cite{todo}, and the recent Symphony language~\cite{todo}. A \textbf{high assurance} language
guarantees that programs written in the language are oblivious.
We describe these properties in more detail, with examples, in Chapter~\ref{ch:background}.

In summary, we would like the following properties from our MPC language.

\begin{enumerate}
\item \label{itm:probabilistic} \textbf{\underline{Probabilistic} -- A probabilistic language, which allows sampling from uniform, random distributions, is necessary
  for implementing asymptotically optimal ORAM, oblivious algorithms, and data structures.}
  When more efficient oblivious protocols are invented (which happens every year), cryptographers would like to be able to
  implement these protocols in a MPC library.
\item \label{itm:centralized} \textbf{\underline{Abstractly Centralized} -- An abstractly centralized language, which hides the distributed deployment from the
  programmer, is necessary for lowering the barrier of entry for developers.}
  Being able to program as though the program is being executed on a single machine, without worrying about the distributed deployment
  of the program, significantly reduces the complexity of MPC programming.
\item \label{itm:assurance} \textbf{\underline{High Assurance} -- A high assurance language, which guarantees that all programs are oblivious, is necessary
  for certifying that programs do not leak information through side channels.} Without certification of obliviousness, a domain expert
  would need to manually audit the declassifications in the program which are expected to reveal no information. Such declassifications
  are common in, for example, tree-based ORAM constructions.
\end{enumerate}

\paragraph{Problem.} No existing MPC language is \textbf{(all together) probabilistic, abstractly centralized, and high assurance.}

\section{Proposed Work}
\label{sec:intro-proposal}

\paragraph{Hypothesis.} It is possible to design and implement a language for MPC which is \textbf{probabilistic, abstractly centralized,
  and high assurance (as defined above).}

\paragraph{Contribution: \obliv is PMTO.} In prior work, we show that ObliVM's~\cite{todo} type system is not oblivious,
and show how to fix it in
such a way that is satisfies \emph{Probabilistic Memory Trace Obliviousness} (PMTO). We prove this property for \obliv, a non-MPC language
for oblivious programming.

\paragraph{Contribution: \mpc is MTO\%.} In ongoing work, we show that Symphony's type system guarantees that MPC programs are
\emph{Memory Trace Oblivious Modulo Declassifications} (MTO\%). To our knowledge, this is the first time such a theorem has been
proved for an MPC language. The SCVM language has a proof of a related property based on crypto-style ``simulation.''

\paragraph{Contribution: Identifying PMTO\%.} We identify and define the \emph{Probabilistic Memory Trace Oblivious Modulo Declassification}
(PMTO\%) as an appropriate definition of security for probabilistic MPC languages. We also investigate and explicate the connection between
this property and other common security properties involving declassifications (such as Gradual Release~\cite{todo}).

The contributions described above have already been accomplished. They are necessary but not sufficient to confirm our hypothesis.
To confirm our hypothesis, we propose the design and implementation of a new language for MPC, called \lang, which extends the
Symphony language with primitives for drawing uniform, random samples and declassifying them.

\paragraph{Contribution: \lang, a probabilistic, abstractly centralized, and high assurance MPC language.}
\lang will extend Symphony with sampling from uniform, random distribuitions. This will immediately satisfy
Property~\ref{itm:probabilistic} above. We will provide further evidence for the utility of this property by
implementing various ORAM protocols (Trivial ORAM, Circuit ORAM, and Recursive (Circuit) ORAM). We will
show that these implementations have the expected asymptotic behavior. Next, we will prove that \lang satisfies
the type safety and simulation theorems by adapting the proofs of these properties for Symphony. This will establish
that \lang satisfies Property~\ref{itm:centralized}.
Finally, we will design the type system of \lang to enforce PMTO\% and confirm that the case studies (ORAM protocols) type check.
This will establish that \lang satisfies Property~\ref{itm:assurance}. Having
accomplished this, we will have confirmed our hypothesis.

We summarize the tasks involved in the last contribution above, and give a rough timeline for their completion. Tasks in
\colorbox{implColor}{red} require adding additional functionality to the existing Haskell implementation of Symphony.
Tasks in \colorbox{theoryColor}{blue} require adapting the formal metatheory of Symphony. \\

\ins{TODO: when proposal document is done, revisit this and update timeline.}

\begin{tabular}{|p{.30\textwidth}|p{.30\textwidth}|p{.30\textwidth}|}
  \hline
  \textbf{Task} & \textbf{Description} & \textbf{Estimated Time of Completion} \\
  \hline
  \rowcolor{implColor}
  Case Studies:
  \begin{itemize}
  \item Trivial ORAM
  \item Tree ORAM(s)
  \item Recursive ORAM
  \end{itemize}    & Implement case studies in \lang;
  show that they are functionally correct and typecheck & 10/07/2020 ($\sim$2 weeks)  \\ \hline
  \rowcolor{implColor}
  Type Checker     & Implement the type checker for \lang                  & 11/07/2020 ($\sim$1 month)  \\ \hline
  \rowcolor{implColor}
  MPC Interpreter  & Implement an EMP MPC backend for \lang                & 01/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  Static Semantics & \lang is \mpc + \obliv                                & 03/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  PMTO\%           & Prove \lang satisfies PMTO\%                          & 05/07/2021 ($\sim$2 months) \\ \hline
  \rowcolor{theoryColor}
  Type Soundness   & Prove \lang satisfies Type Soundness                  & 05/14/2021 ($\sim$1 week)   \\ \hline
  \rowcolor{theoryColor}
  Simulation       & Prove \lang satisfies Simulation                      & 05/21/2021 ($\sim$1 week)   \\ \hline
  Thesis           & Write the thesis and defend it                        & 10/21/2021 ($\sim$5 months) \\ \hline
\end{tabular}

\chapter{Background}
\label{ch:background}

\epigraph{Trust in me in all you do \\
          Have the faith I have in you \\
          Love will see us through \\
          If only you trust in me}{
            Etta James \\
            \emph{Trust in Me}}

Since \lang is a modest extension of the Symphony programming language, we begin by introducing the Symphony language using a simple example.
Having done so, we will explain in more detail the MPC language properties that we advocate for in Section~\ref{sec:background-properties}.
Readers unfamiliar with MPC are encouraged to read Appendix~\ref{ch:gmw}, which describes the GMW protocol.
Readers unfamiliar with ORAM are encouraged to read Appendix~\ref{ch:oram}, which describes the ORAM protocols relevant to this proposal.

\section{A Taste of \mpc}
\label{sec:background-symphony}

Symphony is a MPC language proposed by Darais et al.~\cite{todo} which has a sophisticated type system.
From here on, we instead refer to this language as \mpc to more clearly constrast it with \obliv which is presented in
Chapter~\ref{ch:lam-obliv}. As a means of gentle introduction, let's consider the Millionaire's Problem in which two wealthy parties,
\alice and \bob, would like to know who has a higher net worth.

\begin{figure}[h]
M⁅
\begin{array}{r@{␠}lcl}
   «0:» & 𝑚𝑐3l{ ⦑par⦒[\alice,\bob] }
\\ «1:» & ␠⦑let⦒␣x    ⧼=⧽ ⦑par⦒[\alice]␣⦑read⦒␣⦑in⦒
\\ «2:» & ␠⦑let⦒␣y    ⧼=⧽ ⦑par⦒[\bob]␣⦑read⦒␣⦑in⦒
\\ «3:» & ␠⦑let⦒␣sx   ⧼=⧽ ⦑share⦒[\alice → \alice,\bob]␣x␣⦑in⦒
\\ «4:» & ␠⦑let⦒␣sy   ⧼=⧽ ⦑share⦒[\bob → \alice,\bob]␣y␣⦑in⦒
\\ «5:» & ␠⦑let⦒␣r    ⧼=⧽ sx < sy␣⦑in⦒
\\ «6:» & ␠⦑let⦒␣z    ⧼=⧽ ⦑reveal⦒[\alice,\bob]␣r␣⦑in⦒
\\ «7:» & ␠…
\end{array}
M⁆
\caption{\mpc{} code for the Millionaire's Problem}
\label{fig:millionaires-symphony}
\end{figure}

The code in Figure~\ref{fig:millionaires-symphony} is written in the \mpc language. On line 0, the ⸨⦑par⦒[\alice,\bob]⸩ block
means that \alice and \bob will execute everything in the block's lexical scope. Any other parties will ignore the
contents of the block and generate an \emph{opaque value} denoted \opaque. On line 1, \alice will ⸨⦑read⦒⸩ her own net worth,
⸨\alices{⋖net-worth⋗}⸩, from her local machine and bind it to ⸨x⸩. \bob, however, will evaluate the expression ⸨⦑par⦒[\alice]␣⦑read⦒⸩ to
\opaque because he is not included in the ⸨⦑par⦒[\alice]⸩ block. On line 2, the same thing happens except \bob reads his net worth,
⸨\bobs{⋖net-worth⋗}⸩, and binds it to ⸨y⸩ while \alice binds \opaque to ⸨y⸩ in her local environment. So, after line 2 the local
environments are as follows.

M⁅
  Aːcc
  A⁅ \alice & \bob
  A⁃ ⟨x ↦ \alices{⋖net-worth⋗},␣y ↦ \opaque⟩␠ & ␠⟨x ↦ \opaque,␣y ↦ \bobs{⋖net-worth⋗}⟩
  A⁆
M⁆

On line 3, \alice splits her ⸨\alices{⋖net-worth⋗}⸩ into two shares. She keeps her share and sends \bob's share to him. We use the same
notation for shares which appears in Appendix~\ref{ch:gmw} to emphasize the connection between the explanation of GMW and the execution model
of \mpc. On line 4, \bob splits his ⸨\bobs{⋖net-worth⋗}⸩ into two shares. He keeps his share and send's \alice's share to her. So, after
line 4 the local environments are as follows.

M⁅
  Aːllll
  A⁅ 𝑚𝑐2c{\alice} & 𝑚𝑐2c{\bob}
    A⁃ ⟨…,&␣sx ↦ \aliceSh{\alices{⋖net-worth⋗}}, & ␠⟨…,&␣sx ↦ \bobSh{\alices{⋖net-worth⋗}}
    A⁃    &␣sy ↦ \aliceSh{\bobs{⋖net-worth⋗}}⟩   &     &␣sy ↦ \bobSh{\bobs{⋖net-worth⋗}}⟩
  A⁆
M⁆

On line 5, \alice and \bob compute over their shares to produce a share indicating who is wealthier. Here we assume that the language knows
how to compute or encode ⸨<⸩ over shares. For example, if the underlying MPC protocol were GMW then we would encode ⸨<⸩ as a digital magnitude
circuit in terms of XOR and AND gates.

M⁅
  Aːcc
  A⁅ \alice & \bob
  A⁃ ⟨…,␣r ↦ \aliceSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩}⟩ & ␠⟨…,␣r ↦ \bobSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩}⟩
  A⁆
M⁆

Finally, on line 6, the shares of ⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}⸩ among \alice and \bob are combined and the
cleartext result is revealed to both parties. Note that we could have revealed the result only to \alice, for example,
in which case \bob would send his share to \alice but not vice versa. Then, \alice could recover the cleartext result but \bob could not.
In this case, however, they both send their shares to each other. The XOR operator, ⸨⊕⸩, is used to combine shares implicitly as part
of the ⸨⦑reveal⦒⸩.

M⁅
  Aːllll
  A⁅ 𝑚𝑐2c{\alice} & 𝑚𝑐2c{\bob}
    A⁃ ⟨…,␣z &{} ↦ \aliceSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩} & ␠⟨…,␣z &{} ↦ \aliceSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩}
    A⁃       &{}␣⊕ \bobSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩} & &{}␣⊕ \bobSh{A⸨\alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}A⸩}
    A⁃       &{}␣= \alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}⟩ & &{}␣= \alices{⋖net-worth⋗} < \bobs{⋖net-worth⋗}⟩
  A⁆
M⁆

There are some interesting things to notice about this program (and \mpc) more generally. First, the programmer controls which parties
evaluate which expressions by using ⸨⦑par⦒⸩ blocks. Second, cleartext ⸨⦑read⦒⸩ operations (lines 1,2) are mixed with ciphertext operations
(lines 3,4,5,6). Last, notice that the language is \textbf{abstractly centralized}. In a deployment, this program would run
independently on \alice and \bob who would communicate to jointly compute. Our explanation of the execution of
Figure~\ref{fig:millionaires-symphony} did not explicate any of that.

\section{Desirable Properties of MPC}
\label{sec:background-properties}

In Section~\ref{sec:intro} we claimed that a MPC language ought to be \textbf{probabilistic}, \textbf{abstractly centralized},
and \textbf{high assurance}. But, what exactly do these properties mean and why might we want them?

\subsection{Abstractly Centralized MPC Languages}
\label{subsec:background-properties-centralized}

A language which is abstractly centralized does not require the programmer to explicitly manage the distributed computation. The programmer
does not need to perform commands conditioned on which party is executing. Figure~\ref{fig:millionaires-oblivc} illustrates this by showing
the Obliv-C implementation of the Millionaire's Problem.

\begin{figure}[h]
\begin{lstlisting}[language=c,basicstyle=\footnotesize,numbers=left,stepnumber=1]
  // File: million.h
  typedef struct {
    int myinput;
    bool result;
  }

  void millionaire (void *args);

  // File: million.oc
  #include <million.h>
  #include <obliv.oh>

  void millionaire (void *args) {
    ProtocolIO *io = args;
    obliv int a, b;
    obliv bool res = false;
    a = feedOblivInt (io->myinput, 1);
    b = feedOblivInt (io->myinput, 2);
    obliv if (a < b) res = true;
    revealOblivBool(&io->result, res, 0);
  }

  // File: million.c
  #include <million.h>

  int main (int argc, char *argv[]) {
    ProtocolDesc pd;
    ProtocolIO io;
    int p = (argv[1] == '1' ? 1 : 2);
    sscanf(argv[2], "%d", &io.myinput);
    // ... set up TCP connections

    setCurrentParty (&pd, p);
    execYaoProtocol (&pd, millionaire, &io);
    printf ("Result: %d\n", result);
    // ... cleanup
  }
\end{lstlisting}
\caption{Obliv-C code for the Millionaire's Problem}
\label{fig:millionaires-oblivc}
\end{figure}

We can see that a lot of the details of the distributed, MPC deployment have leaked into the application code. The
\lstinline[language=c]{main} \ins{why isn't this teletype?} function is responsible for all sorts of scaffolding such as establishing TCP connections (line 31),
explicitly executing the protocol (line 34), and populating the \lstinline[language=c]{io} variable with party inputs (line 30). As
a point of comparison, take a look back at Figure~\ref{fig:millionaires-symphony}. Notice that this code makes no mention of TCP connections,
explicit execution of any protocol, or eagerly reading and caching secret inputs. The code knows to execute a Yao protocol due to
an appropriate type signature (not shown).

In Chapter~\ref{ch:lam-mpc} we will formally define an \textbf{abstractly centralized} MPC language as one which satisfies two theorems:
forward simulation and type safety. Forward simulation guarantees that if the centralized interpretation of a program doesn't get stuck,
then neither does its distributed deployment. Type safety ensures that well-typed programs do not get stuck in the centralized interpretation.
These two theorems work together to guarantee that well-typed programs cannot encounter, for example, distributed errors in
which one party is stuck waiting for a message from another party which will never be sent.

Although we will not make any formal claims regarding the usability of the language, we hope it is clear that a language which hides the
distributed nature of this MPC program is desirable.

\subsection{Probabilistic MPC Languages}
\label{subsec:background-properties-probabilistic}

In our terminology, a MCP language is \textbf{probabilistic} if it supports a primitive for drawing a uniform, random sample from a
discrete, finite set. For example, drawing a uniform, random sample from ⸨𝔹⸩, the booleans, corresponds to a fair coin toss. We
could also draw from ⸨ℕ⸤32⸥⸩, natural numbers modulo ⸨2^{32}⸩. Why is such a primitive important in a MPC language?

As discussed in Chapter~\ref{sec:intro-mpc}, MPC languages rely on ORAM to support a RAM-model of computation. In their seminal paper,~\citet{}
showed that Trivial ORAM, which has an overhead of $O(n)$, is optimal if the oblivious scheme is deterministic. However, provided the ability
to perform uniform, random samples, it is possible to design more efficient ORAMs. For example, the other ORAM schemes discussed in
Appendix~\ref{ch:oram}, Circuit ORAM and Recursive ORAM, rely on the ability to draw uniform, random samples. Additionally, there are
optimized algorithms and data structures which do not rely on ORAM, but still use random samples to achieve greater efficiency~\cite{}.

To see how the use of random sampling is used to improve efficiency, consider the code in Figure~\ref{fig:mpc-2-oram}. The purpose of
this code is to allow \bob to choose one of two secrets belonging to \alice without \alice learning which one \bob chose. On lines 1-2,
\alice's secrets, ⸨s⸤A1⸥⸩ and ⸨s⸤A2⸥⸩, are shared with \bob. On line 3, \bob's choice, ⸨s⸤B⸥⸩, is shared with \alice.
On line 4, a coin is flipped, ⸨u⸩, which is shared between \alice and \bob but \emph{visible to neither of them}
\footnote{This can be encoded by each of \alice and \bob flipping their own coins independently, then each sharing their choice with the other
  and XOR'ing them together. The result is a uniform, random sample visible to neither party.}. On lines 5-6, the array, ⸨a⸩, is populated
in-order if the coin ⸨u⸩ is heads, and permuted if the coin is tails. Finally, on line 7 the XOR of \bob's choice with the flipped
coin is revealed to both parties. Notice that if \bob's choice was ⸨0⸩ (tails) then he always gets ⸨s⸤A1⸥⸩ and
likewise for ⸨1⸩ (heads) and ⸨s⸤A2⸥⸩.

This code illustrates the importance of random sampling for efficient RAM access. If the MPC program had instead stored the array ⸨a⸩ in
a Trivial ORAM then the lookup on line 8 would require 2 accesses (one for each element in the ORAM). This may not seem so bad, but consider
the overhead if \bob wanted to choose from an array of length ⸨n⸩. In that case, the lookup on line 8 would incur an $O(n)$ overhead!

\begin{figure}[h]
M⁅
\begin{array}{r@{␠}lcl}
   «0:» & 𝑚𝑐3l{ ⦑par⦒[\alice,\bob] }
\\ «1:» & ␠⦑let⦒␣s⸤A1⸥   ⧼=⧽ ⦑share⦒[\alice → \alice,\bob]␣⦑par⦒[\alice]␣⦑read⦒␣⦑in⦒
\\ «2:» & ␠⦑let⦒␣s⸤A2⸥   ⧼=⧽ ⦑share⦒[\alice → \alice,\bob]␣⦑par⦒[\alice]␣⦑read⦒␣⦑in⦒
\\ «3:» & ␠⦑let⦒␣s⸤B⸥    ⧼=⧽ ⦑share⦒[\bob → \alice,\bob]␣⦑par⦒[\bob]␣⦑read⦒␣⦑in⦒
\\ «4:» & ␠⦑let⦒␣u       ⧼=⧽ 𝒰(❴0,1❵)␣⦑in⦒
\\ «5:» & ␠⦑let⦒␣l,r     ⧼=⧽ ⦑mux⦒␣u␣⦑then⦒␣s⸤A1⸥,s⸤A2⸥␣⦑else⦒␣s⸤A2⸥,s⸤A1⸥␣⦑in⦒
\\ «6:» & ␠⦑let⦒␣a       ⧼=⧽ [l;␣r]␣⦑in⦒
\\ «7:» & ␠⦑let⦒␣idx     ⧼=⧽ ⦑reveal⦒[\alice,\bob]␣s⸤B⸥␣⊕␣u␣⦑in⦒
\\ «8:» & ␠⦑let⦒␣r       ⧼=⧽ ⦑reveal⦒[\alice]␣a[idx]␣⦑in⦒
\\ «9:» & ␠…
\end{array}
M⁆
\caption{Conceptual 2 element ORAM lookup in \mpc{}}
\label{fig:mpc-2-oram}
\end{figure}

\subsection{High Assurance MPC Languages}
\label{subsec:background-properties-assurance}

Existing MPC languages which support uniform, random sampling cannot be considered \textbf{high assurance}. With the introduction of
uniform, random samples it is possible to have declassifications which are information-theoretically secure. In other words, there are
values which can be declassified but provide no information about secrets. For example, recall the code from
Figure~\ref{fig:mpc-2-oram}. On line 7, we reveal ⸨s⸤B⸥␣⊕␣u⸩ to \alice but claim that \alice learns nothing about ⸨s⸤B⸥⸩. This is valid,
but only because ⸨u⸩ is not known to \alice. This is a semantic property which is not checked by the declassification. If line 7
were changed instead to ⸨⦑reveal⦒[\alice,\bob]␣s⸤B⸥⸩ then the program would still be functionally correct but ⸨s⸤B⸥⸩ would be leaked to
\alice. This is what we mean by existing MPC languages failing to be \textbf{high assurance} -- they do not catch (even dynamically)
violations of confidentiality like the one above. In Chapters~\ref{ch:lam-obliv} and~\ref{ch:proposal} we will formalize this as the
PMTO and PMTO\% properties respectively.

A high assurance language is beneficial to both MPC experts (e.g. cryptographers) and novices. Experts save time and gain confidence in their
experimental protocols by relying on the language to enforce confidentiality. For example, the declassification which appears on line 7 in
Figure~\ref{fig:mpc-2-oram} need not be manually audited. Instead, the language would ensure that this declassification is indeed
oblivious. Likewise, MPC novices will benefit by being able to safely experiment with their own cryptographic optimizations
without fear of accidentally leaking information they didn't intend to. They need only mark declassifications that are expected to be
zero-information appropriately.

\chapter{\mpc, A Language for Concise MPC}
\label{ch:lam-mpc}

In~\cref{sec:background-symphony} we walked through the centralized interpretation of the Millionaire's Problem in \mpc. Now that we have
the intution, let's look at the formal description for this language. Having a formal model will allow us to state some properties of the
language more precisely.

\section{Overview}
\label{sec:lam-mpc-overview}

The syntax of \mpc is in \cref{fig:mpc-syntax}. \mpc types comprise a
series of standard types---integers, booleans functions, and pair types---augmented
with two additional elements.

The first exotic feature is \emph{located types}. These types are located
in the sense that they can be manipulated only at particular hosts.
The metavariable $m$ represents a set of parties, and a type is written $\sigma @ m$. The \mpc expression
⸨⦑par⦒[p]␣e⸩ determines the locatedness. It says that $e$ may be computed at
parties $p$ in parallel (hence the syntax ⸨⦑par⦒⸩). That is, every
party $A \in p$ may evaluate $e$. We say ``may'' here because
nesting such an expression in another ⸨⦑par⦒⸩ could shrink the set of
parties. For example, $e$ in ⸨⦑par⦒[p]␣(⦑par⦒[q]␣e)⸩ will be
evaluated by $p \cap q$; if this intersection is $\eset$ then $e$
is essentially dead code.

We call the set of parties $m$ computing an expression in parallel
the \emph{mode}. We say the parties $A \in m$ are \emph{present}
for a computation. The semantics of many constructs depends on the
mode. A number $i$ created in mode $m$ (having type ⸨⦑int⦒@m⸩) is
known only to parties $A \in m$. This means that adding two numbers
located at $p$ can only be done in a mode $m$ such that
$m \subseteq p$; if the mode contained additional parties
$A \not\in p$ then they wouldn't know what to do; such states will be
stuck in our semantics. The same goes for functions, sums, and
references. The ⸨⦑read⦒⸩ and ⸨⦑write⦒␣x⸩ expressions perform local
I/O and so can only be run in a mode with a single party.

On the other hand, it is possible that a variable $x$ is in scope for
$A$, but maps to a value only usable by $B$. Party $A$ can
still manipulate a placeholder for $x$ (e.g., to store it in a
datastructure or pass it to a function) but may never compute with its
contents (e.g., add to it or branch on it). This approach
simplifies the design of the language at the cost of missing some
(unlikely, but ultimately harmless) logic errors.

Generally speaking, \mpc's design aims to ensure that any expression
$e$ of type $\sigma @ m$ will have the \emph{same run-time value} at
each $A \in m$. This is a key invariant underpinning \mpc's centralized
interpretation.

The second exotic feature is \emph{secret share types}.
Base types are annotated with a
\emph{protocol} $\psi$ that indicates whether they are either
cleartext ($\cdot$) or are \emph{encrypted} and shared among parties
$p$. For concreteness, we imagine the encryption protocol is
Goldreich, Widgerson, and Micali (GMW)~\citeyear{STOC:GolMicWig87},
and values of this type are \emph{secret shares}, but the formal
language is indifferent to the cryptographic details. Note that we
often just write ⸨⦑int⦒⸩ for cleartext integer types, to reduce
clutter (i.e., eliding the $\cdot$).

The \mpc expression ⸨⦑share⦒[p→q]␣x⸩ directs $p$ (required to be a singleton party set) to
create secret shares of $x$, an integer, and distribute the shares to
each party in
$q$. All parties $p \cup q$ must be present. The resulting value
has type ⸨⦑int⦒⸢⦑enc⦒⋕q⸣@q⸩. This type reads “an integer, encrypted
(i.e., secret shared) between parties ⸨q⸩, and accessible to parties
⸨q⸩”. The duplication of ⸨q⸩ may seem redundant, but they may differ
in other contexts. The first ⸨q⸩ represents \emph{who has the
shares} (determined when the share is created), and the second ⸨q⸩
represents \emph{who has access to this value} (determined by the
enclosing ⦑par⦒ blocks). If this encrypted value flows to a part of
the program only executed by ⸨q′ ⊂ q⸩, then it will not be possible to
recombine shares, since not all parties ⸨q⸩ will be present.
We can also make a share of a constant
usable by parties $p$ via ⸨⦑embed⦒[p]␣x⸩; making shares of
constants does not require the sharing parties to communicate.

Parties $q$ can all mutually compute on a shared, encrypted value
using ⸨x ⊙ y⸩ and ⸨x ¿ y ◇ z⸩.  Recall from above that the latter is a
multiplexor: we select between ⸨y⸩ and ⸨z⸩ based on whether $x$ is zero or
non-zero. The former models binary operations over numeric types.
When operating on encrypted values, both the multiplexor and binary
operation expressions will necessitate \emph{communication} in the
distributed semantics, and an actual implementation will use an
underling MPC protocol to implement the computation over the encrypted value.
All parties to which a share was sent must
all be present when computing on it. E.g., for numbers of type
⸨⦑int⦒⸢⦑enc⦒⋕{A,B}⸣⸩ to be added, both $A$ and $B$ must be
present. Indeed, it must be \emph{exactly} these parties which are
present; we do not allow more, since other parties would not be
able to carry out the operation (they don't have access to the
share).
% Note that relational operators on shares (such as $<$ in the GCD example) can be encoded as arithmetic ones.

An MPC is completed by invoking ⸨⦑declassify⦒[q]␣x⸩. This takes a share
(among some set of parties $p$) and converts it to cleartext,
sharing the result among parties $q$. Doing so requires that all of
$p \cup q$ are present so that the shareholders
can agree to send the value, and the result-receivers are ready to
receive it.

The notion of locatedness is crucial in proving that \mpc satisfies
a property called~\nameref{thm:mpc-simulation}. The~\nameref{thm:mpc-simulation}
property is what allows us to view the langauge as \textbf{abstractly centralized}. The
next section is dedicated to explaining this property, and highlighting some of
its consequences.

\section{Simulation}

\ins{The goal is to sufficiently explain~\nameref{thm:mpc-simulation}.}

\begin{theorem}[Forward Simulation] \label{thm:mpc-simulation}
  If ⸨ς —→⋆ ς′⸩, ⸨ς′⸩ is terminal, ⸨ς↯ ↝⋆ G⸩ and ⸨G ⫽↝⸩, then ⸨G = ς′↯⸩.
\end{theorem}

In other words, we can centralized execute then slice, or we can slice and then distributed execute, but we'll get the same answer.

F⁅
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
D⁅
M⁅
Aːrcrcl@{␠}l
A⁅ b     ⧼∈⧽ 𝔹            ⧼ ⧽                                & ⟪booleans⟫
A⁃ i     ⧼∈⧽ ℤ            ⧼ ⧽                                & ⟪integers⟫
A⁃ A,B,C ⧼∈⧽ ‹party›      ⧼ ⧽                                & ⟪parties⟫
A⁃ m,p,q ⧼∈⧽ ‹party-set›  ⧼≜⧽ ℘(‹party›) ⩴ ❴A,…,A❵           & ⟪sets of parties⟫
A⁃ ψ     ⧼∈⧽ ‹prot›       ⧼⩴⧽ ⋅                              & ⟪cleartext⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑enc⦒⋕m                        & ⟪encrypted⟫
A⁃ μ     ⧼∈⧽ ‹base-type›  ⧼⩴⧽ ⦑int⦒                         & ⟪integer type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑bool⦒                         & ⟪boolean type⟫
A⁃ σ     ⧼∈⧽ ‹loc-type›   ⧼⩴⧽ μ⸢ψ⸣                          & ⟪protocol type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ τ ᵐ→ τ                         & ⟪function type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ τ × τ                          & ⟪pair type⟫
A⁃ τ     ⧼∈⧽ ‹type›       ⧼⩴⧽ σ@m                            & ⟪located type⟫
A⁃ x,y,z ⧼∈⧽ ‹var›        ⧼ ⧽                                & ⟪variables⟫
A⁃ ⊙     ⧼∈⧽ ‹binop›      ⧼ ⧽                                & ⟪binary operations (e.g., plus, times)⟫
A⁃ e     ⧼∈⧽ ‹expr›       ⧼⩴⧽ x                              & ⟪variable reference⟫
A⁃       ⧼ ⧽              ⧼¦⧽ i                              & ⟪integer literal⟫
A⁃       ⧼ ⧽              ⧼¦⧽ b                              & ⟪boolean literal⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e ⊙ e                          & ⟪binary operation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑if⦒␣e␣⦑then⦒␣e␣⦑else⦒␣e          & ⟪atomic conditional⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e ¿ e ◇ e                      & ⟪atomic conditional⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⟨e,e⟩                          & ⟪pair creation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ πᵢ␣e                           & ⟪pair projection (⸨i ∈ ❴1,2❵⸩)⟫
A⁃       ⧼ ⧽              ⧼¦⧽ λ⸤z⸥x⍪ e                       & ⟪(recursive) function creation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑read⦒␣μ                         & ⟪read int input⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑write⦒␣e                      & ⟪write output⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑embed⦒[p]␣e                   & ⟪encrypted a known constant⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑share⦒[p→p]␣e                 & ⟪share encrypted value⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑declassify⦒[p]␣e              & ⟪reveal encrypted value⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e␣e                            & ⟪function elimination⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑par⦒[p]␣e                     & ⟪parallel execution⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑let⦒␣x=e␣⦑in⦒␣e               & ⟪let binding⟫
A⁆
M⁆
D⁆
\endgroup
\caption{\mpc Syntax}
\label{fig:mpc-syntax}
F⁆

\chapter{\obliv, A Language for Probabilistically Oblivious Computation}
\label{ch:lam-obliv}

The goal is to sufficiently explain~\nameref{thm:obliv-pmto}.

\begin{theorem}[PMTO] \label{thm:obliv-pmto}
  If ⸨e₁ : τ⸩, ⸨e₂ : τ⸩, ⸨e₁ ≈⸤l⸥ e₂⸩, ⸨e₁ ⇢⋆ ⇡~{t₁}⸩, and ⸨e₂ ⇢⋆ ⇡~{t₂}⸩, then ⸨⇡~{t₁} ⇡~≈⸤l⸥ ⇡~{t₂}⸩.
\end{theorem}

In other words, if two expressions cannot be distinguished from each other, then neither can the distributions of memory traces
that they emit.

F⁅
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
D⁅
M⁅
Aːrcrcl@{␠}l
A⁅ b   ⧼∈⧽ 𝔹           ⧼ ⧽                               & ⟪booleans⟫
A⁃ i   ⧼∈⧽ ℤ           ⧼ ⧽                                & ⟪integers⟫
A⁃ ℓ   ⧼∈⧽ ‹label›     ⧼⩴⧽ ‹P› ¦ ‹S›                     & ⟪public and secret⟫
A⁃     ⧼ ⧽ 𝑚𝑐3c{⟪(«where» ⸨‹P›⊏‹S›⸩)⟫}                   & ⟪security labels⟫
A⁃ ρ   ⧼∈⧽ R           ⧼ ⧽                               & ⟪probability region⟫
A⁃ μ   ⧼∈⧽ ‹base-type› ⧼⩴⧽ ⦑int⦒                         & ⟪integer type⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑bool⦒                         & ⟪boolean type⟫
A⁃ τ   ⧼∈⧽ ‹type›      ⧼⩴⧽ μ⸤ℓ⸥⸢ρ⸣                        & ⟪non-random base type⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑½⦒ μ⸤‹S›⸥⸢ρ⸣                   & ⟪secret uniform bool⟫
A⁃     ⧼ ⧽             ⧼¦⧽ τ × τ                          & ⟪tuple⟫
A⁃     ⧼ ⧽             ⧼¦⧽ τ → τ                          & ⟪function⟫
A⁃ x,y ⧼∈⧽ ‹var›       ⧼ ⧽                                 & ⟪variables⟫
A⁃ ⊙   ⧼∈⧽ ‹binop›     ⧼ ⧽                                & ⟪binary operations (e.g., plus, times)⟫
A⁃ e   ⧼∈⧽ ‹expr›      ⧼⩴⧽ x                              & ⟪variable reference⟫
A⁃     ⧼ ⧽             ⧼¦⧽ i⸤ℓ⸥                            & ⟪integer literal⟫
A⁃     ⧼ ⧽             ⧼¦⧽ b⸤ℓ⸥                            & ⟪boolean literal⟫
A⁃     ⧼ ⧽             ⧼¦⧽ e ⊙ e                          & ⟪binary operation⟫
A⁃     ⧼ ⧽             ⧼¦⧽ e ¿ e ◇ e                      & ⟪atomic conditional⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⟨e,e⟩                           & ⟪tuple creation⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑let⦒␣x,y = e␣⦑in⦒␣e            & ⟪tuple elimination⟫
A⁃     ⧼ ⧽             ⧼¦⧽ λ⸤z⸥x⍪ e                       & ⟪(recursive) function creation⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑unif⦒⸢ρ⸣␣μ                      & ⟪uniform, random sample in region⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑cast⦒⸤l⸥␣x                    & ⟪cast from uniform⟫
A⁃     ⧼ ⧽             ⧼¦⧽ e␣e                            & ⟪function elimination⟫
A⁃     ⧼ ⧽             ⧼¦⧽ ⦑let⦒␣x = e␣⦑in⦒␣e               & ⟪variable binding⟫
A⁆
M⁆
D⁆
\endgroup
\caption{\obliv Syntax}
\label{fig:obliv-syntax}
F⁆

\chapter{Proposal: \lang, A Secure MPC Language With User-Defined ORAM}
\label{ch:proposal}

Building on \mpc and \obliv, I will design and implement a MPC language, \lang, which is \textbf{probabilistic},
\textbf{abstractly centralized}, and \textbf{high assurance}.

\section{Design}



The goal is to sufficiently explain~\nameref{thm:lang-simulation} and~\nameref{thm:lang-pmto}.

\begin{theorem}[Forward Simulation] \label{thm:lang-simulation}
  If ⸨ς —→⋆ ⇡~{ς′}⸩, ⸨⇡~{ς′}⸩ is terminal, ⸨ς↯ ↝⋆ ⇡~{G}⸩ and ⸨⇡~{G} ⫽↝⸩, then ⸨⇡~{G} = ⇡~{ς′}↯⸩.
\end{theorem}

\begin{theorem}[PMTO\%] \label{thm:lang-pmto}
  If ⸨ς₁ : τ⸩, ⸨ς₂ : τ⸩, ⸨ς₁ ≈⸤l⸥ ς₂⸩, ⸨ς₁ ⇢⋆ ⇡~{t₁}⸩, ⸨ς₂ ⇢⋆ ⇡~{t₂}⸩, and ⸨R⸤l⸥(⇡~{t₁}) = R⸤l⸥(⇡~{t₂})⸩, then ⸨⇡~{t₁} ⇡~≈⸤l⸥ ⇡~{t₂}⸩.
\end{theorem}

F⁅
\begingroup
\setlength\arraycolsep{0pt} % default is 6pt
\smaller
D⁅
M⁅
Aːrcrcl@{␠}l
A⁅ b     ⧼∈⧽ 𝔹            ⧼ ⧽                                & ⟪booleans⟫
A⁃ i     ⧼∈⧽ ℤ            ⧼ ⧽                                & ⟪integers⟫
A⁃ A,B,C ⧼∈⧽ ‹party›      ⧼ ⧽                                & ⟪parties⟫
A⁃ m,p,q ⧼∈⧽ ‹party-set›  ⧼≜⧽ ℘(‹party›) ⩴ ❴A,…,A❵           & ⟪sets of parties⟫
A⁃ ρ     ⧼∈⧽ R           ⧼ ⧽                               & ⟪probability region⟫
A⁃ ψ     ⧼∈⧽ ‹prot›       ⧼⩴⧽ ⋅                              & ⟪cleartext⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑enc⦒⋕m                        & ⟪encrypted⟫
A⁃ μ     ⧼∈⧽ ‹base-type›  ⧼⩴⧽ ⦑int⦒                         & ⟪integer type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑bool⦒                         & ⟪boolean type⟫
A⁃ σ     ⧼∈⧽ ‹loc-type›   ⧼⩴⧽ μ⸢ρ ; ψ⸣                          & ⟪protocol type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑½⦒ μ⸢ρ ; ψ⸣                   & ⟪uniform type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ τ ᵐ→ τ                         & ⟪function type⟫
A⁃       ⧼ ⧽              ⧼¦⧽ τ × τ                          & ⟪pair type⟫
A⁃ τ     ⧼∈⧽ ‹type›       ⧼⩴⧽ σ@m                            & ⟪located type⟫
A⁃ x,y,z ⧼∈⧽ ‹var›        ⧼ ⧽                                & ⟪variables⟫
A⁃ ⊙     ⧼∈⧽ ‹binop›      ⧼ ⧽                                & ⟪binary operations (e.g., plus, times)⟫
A⁃ e     ⧼∈⧽ ‹expr›       ⧼⩴⧽ x                              & ⟪variable reference⟫
A⁃       ⧼ ⧽              ⧼¦⧽ i                              & ⟪integer literal⟫
A⁃       ⧼ ⧽              ⧼¦⧽ b                              & ⟪boolean literal⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e ⊙ e                          & ⟪binary operation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e ¿ e ◇ e                      & ⟪atomic conditional⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⟨e,e⟩                          & ⟪pair creation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑let⦒␣x,y = e␣⦑in⦒␣e            & ⟪tuple elimination⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑par⦒[p]␣e                     & ⟪parallel execution⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑read⦒␣μ                       & ⟪read int input⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑write⦒␣e                      & ⟪write output⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑embed⦒[p]␣e                   & ⟪encrypted a known constant⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑share⦒[p→p]␣e                 & ⟪share encrypted value⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑declassify⦒[p]␣e              & ⟪declassify encrypted value⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑unif⦒[p]⸢ρ⸣␣μ                  & ⟪uniform, random sample in region⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑cast⦒[p]⸤l⸥␣x                    & ⟪cast from uniform⟫
A⁃       ⧼ ⧽              ⧼¦⧽ λ⸤z⸥x⍪ e                       & ⟪(recursive) function creation⟫
A⁃       ⧼ ⧽              ⧼¦⧽ e␣e                            & ⟪function elimination⟫
A⁃       ⧼ ⧽              ⧼¦⧽ ⦑let⦒␣x=e␣⦑in⦒␣e               & ⟪let binding⟫
A⁆
M⁆
D⁆
\endgroup
\caption{\mpc Syntax}
\label{fig:mpc-syntax}
F⁆

Labels are the combination of party set and protocol. We interpret functions and tuples as having an implicit cleartext protocl.

Differences from \mpc. We have a new uniform type. Atomic conditional works like in \obliv, returning tuple in-order or out
of order. This is necessary for affinity. Tuple elimination is now by pattern-matching, again for compatibility with affinity. The
only non-trivial change is the addition of uniform sampling and casting from \obliv.

\section{Implementation}

\ins{
\begin{enumerate}
\item What? Case Studies. Why? The ORAM implementations presented in \obliv are in client-server model. These implementations will
  be written to abide by the MPC type system and will be in the more restrictive ORAM-SC model. Also, frankly, the existing literature
  on the differences between these two models sucks. I hope to more clearly articulate the differences and similarities in my thesis
  by showing the implementations side-by-side. How? Adapt the implementations from~\citet{lam-obliv} according to the descriptions of
  ORAM-SC in the literature~\cite{}.
\item What? Type Checker. Why? To verify that the formal type sytem is feasible to implement and interesting. By ``interesting'' we mean
  that it can successfully typecheck the ORAM case studies. Also, as an additional contribution, the \mpc implementation presented
  in~\citet{symphony} does not include a type checker. So, we will also show that the interesting case studies from that paper type check.
  Finally, this will allow us to rapidly test different designs for the formal type system. How? Write a bunch of Haskell. As a first cut
  we will graft the affinity and probability region features from \obliv onto the type system of \mpc.
\item What? MPC Interpreter. Why? The formal semantics of \mpc and \lang are parameterized by the underlying MPC protocols. This may
  may create some doubt in readers that the semantics is truly modelling the implementation of an MPC language. Again, the implementation
  will serve to show that the formal semantics are feasible and interesting. How? We have already added the foundation of this functionality
  by using the Haskell FFI to call out to the (two-party, semi-honest) EMP library. For example, we have the Millionaire's Problem working.
\item What? Static Semantics. Why? We enforce the security properties of programs in \lang by showing that security is implied by
  well-typing. We want PMTO\% and simulation, so we have to design a type system which satisfies the former without wrecking the latter.
  How? Having implemented the type checker, we can base the static semantics on that.
\item What? Prove Type Safety, PMTO\%, and Simulation. These are all desirable properties. The first says that the types are coherent with
  the runtime behavior of the program. The second says that programs are secure, they only leak information which is explicitly declassified
  according to a reveal expression. The third says that the single-threaded, or centralized, interpretation of programs is consistent with
  the distributed (``real'') interpretation. How? We expect that the proof of type safety will be a standard syntactic proof using progress
  and preservation. The proof of PMTO\% will build on the techniques (mixed semantics, simulation) for PMTO in \obliv and the proof of MTO\%
  in \mpc. One possible challenge is the proof of simulation between the single-threaded and distributed semantics. Since we are adding a
  probabilistic choice operation to the single-threaded semantics it will no longer be deterministic. This could complicate the proof of
  simulation.
\end{enumerate}
}

\chapter{Open Problems}

We briefly discuss some important open problems which affect the design of languages for
MPC and obliviousness. These are not addressed by \lang and I feel that they are promising
areas for future research.

\paragraph{Resource Awareness}
MPC programs are expensive. Something something orders of magnitude slower~\cite{}. This due principally to the communication
required. For example in GMW, an AND gate requires a round of communication and the 1-4 OT requires an encryption scheme.
Programmers who are not experts in MPC will require information about the cost of the programs they are writing. This could be
handled elegantly by the language. There is ample research in type-based resource analysis~\cite{}, for example. \ins{TODO: this is rough}

\paragraph{Oblivious Data Structures}
Our prior work has shown that Oblivious Data Structures (ODS's), proposed by Wang et al., do not satisfy PMTO.\ins{replace with ref. to theorem} Even though ODS's are safe due to negligibl overflow probability, we are unable to verify that fact in \lang. We would like to find some
way to support ODS's within the language while retaining the security guarantees provided by the tyep system.

\paragraph{Other Security Policies}
PMTO\% is perhaps the most obvious security policone could prove about MPC programs which admit ORAM. However, it is not the only property
one could prove. There is a rich literature of different declassification policies, as well as weaker variants of (P)MTO like Differential
MTO~\cite{} and manual computational proofs of securit with explicit complexity-theoretic reductions~\cite{easycrypt}.

\paragraph{Usability of Abstractly Centralized Languages}
We make claims in this proposal that abstractly centralized languages are a good choice for MPC. We justify this claim by arguing that
programmers need not think about the distributed deployment of their program. Furthermore, the type safety theorem for the centralized
semantics implies safety of the distributed semantics. However, a more empirical approach to the question of usability is warranted.
A user study comparing two languages, one of which exposes more of the distributed computation, would lend more credibility to our claim
that abstractly centralized languages are preferable.

\paragraph{Support for PIR-based ORAM}
The most efficient modern ORAM schemes in the MPC context use Private Information Retrieval (PIR) protocols. These protocols rely on
features such as function secret sharing and cryptographic pseudo-random functions.

\appendix

\chapter{The GMW Protocol}
\label{ch:gmw}

MPC works by allowing a secret, in cleartext, to be split up into many ``shares'' which are considered ciphertext
and therefore may be safely distributed to other parties and recombined later. More specifically, shares have the following properties:
\begin{enumerate}
\item Shares can be combined to reveal the original cleartext secret.
\item A share does not reveal any information about the secret.
\item Parties can cooperate to compute over shares. For example, being able to create shares of boolean values
  and compute XOR and AND over those shares forms a complete basis for computation. Primitives such as addition,
  comparison, etc. can be built from these boolean operations.
\end{enumerate}

The languages discussed in this proposal are agnostic to the underlying MPC protocol. We only require that the underlying MPC protocol
have the properties listed above. For the purposes of exposition, however, we choose to use the GMW protocol [cite] as a
representative for MPC protocols in general.

In GMW, the secrets being shared are booleans. To represent integers with arithmetic, comparison, etc. we use a two's
complement representation. For example, a digital circuit with only XOR and AND gates can be used to half adders,
full-adders, and ripple-carry adders. A party \alice can generate her share of her (boolean) secret \aliceSec by
generating a random number:

M⁅
\aliceSh{\aliceSec} ← 𝒰(❴0,1❵)
M⁆

The notation ⸨⌊v⌋⸤P⸥⸩ indicates that this is ⸨P⸩'s share of the value ⸨v⸩. Then, \alice generates \bob's share of \aliceSec
as the XOR of her share with the original secret:

M⁅
\bobSh{\aliceSec} ← \aliceSh{\aliceSec} ⊕ \aliceSec
M⁆

At this point, there are a few important things to notice. First, \bob's share is effectively another random number.
As long as he never sees \aliceSh{\aliceSec} he can't distinguish his share \bobSh{\aliceSec} from a fresh, uniform
boolean value. This establishes property (2) of MPC above. Second, XOR has the following properties:

\begin{fact}[⸨⊕⸩-Inverse]
\label{fact:xor-inverse}
  ⸨∀ b ∈ 𝔹␣.␣b ⊕ b = 0⸩
\end{fact}

\begin{fact}[⸨⊕⸩-Identity]
\label{fact:xor-identity}
  ⸨∀ b ∈ 𝔹␣.␣b ⊕ 0 = 0 ⊕ b = b⸩
\end{fact}

These two properties ensure that the original secret, \aliceSec, can be recovered by XOR'ing the shares together:

M⁅
  Aːllll
  A⁅ \aliceSh{\aliceSec} ⊕ \bobSh{\aliceSec} ⧼=⧽ \aliceSh{\aliceSec} ⊕ \aliceSh{\aliceSec} ⊕ \aliceSec & ␠⟅ by \bobSh{\aliceSec} ⟆
  A⁃                                         ⧼=⧽ 0 ⊕ \aliceSec & ␠⟅ by \nameref{fact:xor-inverse} ⟆
  A⁃                                         ⧼=⧽ \aliceSec & ␠⟅ by \nameref{fact:xor-identity} ⟆
  A⁆
M⁆

which establishes MPC property (1) above. Now, let's assume that \bob executes the same protocol to share his secret, \bobSec,
with \alice by splitting it into \aliceSh{\bobSec} and \bobSh{\bobSec}. So, at this point \alice has her shares of both secrets
and similarly for \bob. How can we accomplish property (3) of MPC? To compute ⸨\aliceSec ⊕ \bobSec⸩ we can simply have \alice and \bob
evaluate the XOR of their shares independently:

M⁅
  Aːllll
  A⁅ \aliceSh{A⸨ \aliceSec ⊕ \bobSec A⸩} ⧼←⧽ \aliceSh{\aliceSec} ⊕ \aliceSh{\bobSec}
  A⁃ \bobSh{A⸨ \aliceSec   ⊕ \bobSec A⸩} ⧼←⧽ \bobSh{\aliceSec}   ⊕ \bobSh{\bobSec}
  A⁆
M⁆

Why does this work? Well, it's because XOR is associative:

M⁅
  Aːllll
  A⁅ \aliceSh{\aliceSec ⊕ \bobSec} ⊕ \bobSh{\aliceSec ⊕ \bobSec} ⧼=⧽
      (\aliceSh{\aliceSec} ⊕ \aliceSh{\bobSec}) ⊕ (\bobSh{\aliceSec} ⊕ \bobSh{\bobSec}) & ␠⟪[Definition of XOR of shares]⟫
  A⁃ ⧼=⧽
      (\aliceSh{\aliceSec} ⊕ \bobSh{\aliceSec}) ⊕ (\aliceSh{\bobSec} ⊕ \bobSh{\bobSec}) & ␠⟪[Associativity of XOR]⟫
  A⁃ ⧼=⧽
      \aliceSec ⊕ \bobSec & ␠⟪[Share Recovery]⟫
  A⁆
M⁆

Now for the tricky bit. How do we compute ⸨\aliceSec ∧ \bobSec⸩? To describe this gate we assume that we have access to a
protocol called 1-4 Oblivious Transfer (OT). This protocol allows a sender, ⸨S⸩, to send 4 messages to a receiver, ⸨R⸩, in such a
way that (a) ⸨R⸩ is only allowed to see 1 of the 4 messages and (b) ⸨S⸩ cannot tell which message ⸨R⸩ chose.

Assuming that we have access to such a protocol, we can compute \alice's share of the AND very simply:

M⁅
  Aːllll
  A⁅ \alices{σ}                          ⧼←⧽ 𝒰(❴0,1❵)
  A⁃ \aliceSh{A⸨ \aliceSec ∧ \bobSec A⸩} ⧼←⧽ \alices{σ}
  A⁆
M⁆

Now, we still need to figure out how \bob will compute his share of the AND. This will involve the 1-4 OT protocol in which \alice is the
sender and \bob is the receiver. Consider Table~\ref{tab:and-ot}, which is constructed by \alice. Each row indicates one of the possible
outcomes for \bob's shares, \bobSh{\aliceSec} and \bobSh{\bobSec}.

\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    \bobSh{\aliceSec} & \bobSh{\bobSec} & A⸨ \aliceSh{\aliceSec} ⊕ \bobSh{\aliceSec} ∧ \aliceSh{\bobSec} ⊕ \bobSh{\bobSec} A⸩ & ⸨r⸩ \\ \hline
    ⸨0⸩ & ⸨0⸩ & A⸨ α⸤0,0⸥ = \aliceSh{\aliceSec} ⊕ 0 ∧ \aliceSh{\bobSec} ⊕ 0 A⸩ & A⸨ r⸤0,0⸥ = \alices{σ} ⊕ α⸤0,0⸥ A⸩ \\ \hline
    ⸨0⸩ & ⸨1⸩ & A⸨ α⸤0,1⸥ = \aliceSh{\aliceSec} ⊕ 0 ∧ \aliceSh{\bobSec} ⊕ 1 A⸩ & A⸨ r⸤0,1⸥ = \alices{σ} ⊕ α⸤0,1⸥ A⸩ \\ \hline
    ⸨1⸩ & ⸨0⸩ & A⸨ α⸤1,0⸥ = \aliceSh{\aliceSec} ⊕ 1 ∧ \aliceSh{\bobSec} ⊕ 0 A⸩ & A⸨ r⸤1,0⸥ = \alices{σ} ⊕ α⸤1,0⸥ A⸩ \\ \hline
    ⸨1⸩ & ⸨1⸩ & A⸨ α⸤1,1⸥ = \aliceSh{\aliceSec} ⊕ 1 ∧ \aliceSh{\bobSec} ⊕ 1 A⸩ & A⸨ r⸤1,1⸥ = \alices{σ} ⊕ α⸤1,1⸥ A⸩ \\ \hline
  \end{tabular}
  \caption{B⸨testingB⸩\ins{TODO: couldn't figure out how to use colored math in here without an error.}}
  \label{tab:and-ot}
\end{table}

If \alice now sends ⸨(r⸤0,0⸥,␣r⸤0,1⸥,␣r⸤1,0⸥,␣r⸤1,1⸥)⸩ via 1-4 OT to \bob, then \bob can select the message which corresponds the outcome
of his shares. For example, if \bob's shares are ⸨\bobSh{\aliceSec} = \bobSh{\bobSec} = 0⸩ then he would select ⸨r⸤0,0⸥⸩ (corresponding
to the first row in Table~\ref{tab:and-ot}).

M⁅
  Aːllll
  A⁅ \bobSh{\aliceSec ∧ \bobSec} ⧼←⧽ r␣‹where›␣& r = r⸤0,0⸥␣‹if›␣\bobSh{\aliceSec} = 0␣‹and›␣\bobSh{\bobSec} = 0
  A⁃ & & & r = r⸤0,1⸥␣‹if›␣\bobSh{\aliceSec} = 0␣‹and›␣\bobSh{\bobSec} = 1
  A⁃ & & & r = r⸤1,0⸥␣‹if›␣\bobSh{\aliceSec} = 1␣‹and›␣\bobSh{\bobSec} = 0
  A⁃ & & & r = r⸤1,1⸥␣‹if›␣\bobSh{\aliceSec} = 1␣‹and›␣\bobSh{\bobSec} = 1
  A⁆
M⁆

Finally, let's check that this is correct and secure. First, correctness:

M⁅
  Aːllll
  A⁅ \aliceSh{\aliceSec ∧ \bobSec} ⊕ \bobSh{\aliceSec ∧ \bobSec} ⧼=⧽ \alices{σ} ⊕ (\alices{σ} ⊕ α⸤i,j⸥) & ␠⟪[Definition of ⸨∧⸩]⟫
  A⁃ & & ‹where›␣i = \bobSh{\aliceSec}␣‹and›␣j = \bobSh{\bobSec}
  A⁃ ⧼=⧽ α⸤i,j⸥ & ␠⟪[Fact~\ref{xor-inverse}]⟫
  A⁃ ⧼=⧽ \aliceSh{\aliceSec} ⊕ \bobSh{\aliceSec} ∧ \aliceSh{\bobSec} ⊕ \bobSh{\bobSec} & ␠⟪[Definition (by OT on Table~\ref{tab:and-ot})]⟫
  A⁃ ⧼=⧽ \aliceSec ∧ \bobSec & ␠⟪[Share Recovery]⟫
  A⁆
M⁆

Now, why is this secure? The security relies crucially on the properties of 1-4 OT. If \alice could tell which message \bob chose she would
immediately learn the values of \bob's shares and be able to recover \bob's secret. However, 1-4 OT guarantees that \alice cannot tell
which message \bob chose. Likewise, if \bob were able to see more than one of the messages sent by \alice then ⸨α ⊕ \alices{σ}⸩ would not
sufficiently protect ⸨α⸩\footnote{More formally, the XOR with a random value forms a one-time pad (OTP) encryption scheme, which is only secure
  if the key is never reused.}. However, 1-4 OT guarantees that \bob can only see the message that he chooses.

\chapter{Oblivious RAM}
\label{ch:oram}


\end{document}
