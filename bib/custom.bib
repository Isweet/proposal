@string{sigmod = "{ACM} SIGMOD International Conference on Management of Data (SIGMOD)"}
@string{openarch = "IEEE Conference on Open Architectures (OPENARCH)" }
@string{paste = "{ACM} Workshop on Program Analysis for Software Tools and Engineering (PASTE)"}
@string{inproc="Proceedings of the "}
@string{toplas = "{ACM} Transactions on Programming Languages and Systems (TOPLAS)"}
@string{tops = "{ACM} Transactions on Privacy and Security (TOPS)"}
@string{plas = "{ACM SIGPLAN} Workshop on Programming Languages and Analysis for Security (PLAS)"}
@string{scp = "Science of Computer Programming (SCP)"}
@string{icfp = "{ACM} International Conference on Functional Programming (ICFP)"}
@string{oopsla = "{ACM} Conference on Object-Oriented Programming Languages, Systems, and Applications (OOPSLA)"}
@string{ismm = "{ACM} International Symposium on Memory Management (ISMM)"}
@string{podc = "{ACM} Conference on Principles of Distributed Computing (PODC)"}
@string{popl = "{ACM} Conference on Principles of Programming Languages (POPL)"}
@string{csjp = "Workshop on Concurrency and Synchronization in Java Programs (CSJP)"}
@string{pam = "{IEEE} Passive/Active Measurement Workshop (PAM)"}
@string{coord = "International Conference on Coordination Models and Languages (COORDINATION)"}
@string{pldi = "{ACM} Conference on Programming Language Design and Implementation (PLDI)"}
@string{tldi = "{ACM} Workshop on Types in Language Design and Implementation (TLDI)"}
@string{ccs = "{ACM} Conference on Computer and Communications Security (CCS)"}
@string{oakland = "{IEEE} Symposium on Security and Privacy (Oakland)"}
@string{oops = "{ACM} Symposium on Applied Computing, Object-oriented Programming Languages and Systems Track (OOPS)"}
@string{sigcomm = "{ACM} {SIGCOMM} Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (SIGCOMM)"}
@string{dls = "{ACM} {SIGPLAN} Dynamic Languages Symposium (DLS)"}
@string{plateau = "Workshop on the Evaluation and Usability of Programming Languages and Tools (PLATEAU)"}
@string{hotswup = "Workshop on Hot Topics in Software Upgrades (HotSWUp)"}
@string{spe = "Software, Practice, and Experience"}
@string{stop = "Workshop on Scripts to Programs (STOP)"}
@string{csf = "Computer Security Foundations Symposium (CSF)"}
@string{post = "Symposium on Principles of Security and Trust (POST)"}
@string{sas = "Static Analysis Symposium (SAS)"}
@string{icse = "International Conference on Software Engineering (ICSE)"}
@string{asplos = "International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)"}
@string{cset = "USENIX Workshop on Cyber Security Instrumentation and Test (CSET)"}
@string{sec = "USENIX Security Symposium (USENIX SEC)"}
@string{icst = "International Conference on Software Testing (ICST)"}
@string{sosr = "Symposium on SDN Research (SOSR)"}
@string{icsme = "International Conference on Software Maintenance and Evolution (ICSME)"}
@string{fse = "European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE)"}
@string{esop = "European Symposium on Programming (ESOP)"}
@string{secdev = "IEEE Conference on Secure Development (SecDev)"}
@string{snapl = "Summit on Advances in Programming Languages (SNAPL)"}

@inproceedings{TPMPC:BLJVVS17,
  title={Design and Deployment of Usable, Scalable MPC},
  author={Azer Bestavros and Andrei Lapets and Frederick Jansen and Mayank Varia and Nikolaj Volgushev and Malte Schwarzkopf},
  booktitle={2017 Theory and Practice of Multi-Party Computation Workshop},
  year={2017},
}

@inproceedings{burnim2009wise,
  title={WISE: Automated test generation for worst-case complexity},
  author={Burnim, Jacob and Juvekar, Sudeep and Sen, Koushik},
  booktitle={2009 IEEE 31st International Conference on Software Engineering},
  pages={463--473},
  year={2009},
  organization={IEEE}
}

@inproceedings{zaparanuks2012algorithmic,
  title={Algorithmic profiling},
  author={Zaparanuks, Dmitrijs and Hauswirth, Matthias},
  booktitle={Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation},
  pages={67--76},
  year={2012}
}

@inproceedings{lemieux2018perffuzz,
  title={Perffuzz: Automatically generating pathological inputs},
  author={Lemieux, Caroline and Padhye, Rohan and Sen, Koushik and Song, Dawn},
  booktitle={Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages={254--265},
  year={2018}
}

@inproceedings{10.1145/1926385.1926427,
author = {Hoffmann, Jan and Aehlig, Klaus and Hofmann, Martin},
title = {Multivariate Amortized Resource Analysis},
year = {2011},
booktitle = {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
}

@inproceedings{10.1145/3009837.3009842,
author = {Hoffmann, Jan and Das, Ankush and Weng, Shu-Chun},
title = {Towards Automatic Resource Bound Analysis for OCaml},
year = {2017},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
}

@inproceedings{carbonneaux2015compositional,
  title={Compositional certified resource bounds},
  author={Carbonneaux, Quentin and Hoffmann, Jan and Shao, Zhong},
  booktitle={Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={467--478},
  year={2015}
}

@book{10.5555/509043,
author = {Pierce, Benjamin C.},
title = {Types and Programming Languages},
year = {2002},
isbn = {0262162091},
publisher = {The MIT Press},
edition = {1st}
}

@book{10.5555/3002812,
author = {Harper, Robert},
title = {Practical Foundations for Programming Languages},
year = {2016},
isbn = {1107150302},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd}
}

@inproceedings{siek2007gradual,
  title={Gradual typing for objects},
  author={Siek, Jeremy and Taha, Walid},
  booktitle={European Conference on Object-Oriented Programming},
  pages={2--27},
  year={2007},
  organization={Springer}
}

@inproceedings{HastingsHNZ19,
  author    = {Marcella Hastings and
               Brett Hemenway and
               Daniel Noble and
               Steve Zdancewic},
  title     = {{SoK}: General Purpose Compilers for Secure Multi-Party Computation},
  booktitle = inproc # oakland,
  year      = {2019},
}

@misc{liu20typeclasses,
  title = {Verifying Typeclasses in Liquid Haskell},
  author = {Yiyun Liu and James Parker and Michael Hicks and Niki Vazou},
  abstract = {
  While Haskell ensures that a typeclass's instances match the type
  signature of its definition, Haskell does not enforce that such
  implementations also respect the typeclass's accompanying set of
  laws (properties). For example, instances of the \texttt{Monad}
  typeclass should ensure that their \texttt{return} and \texttt{bind}
  methods enjoy \emph{left identity}. Failure to respect these laws
  may break a typeclass's clients.

  This paper presents an extension to Liquid Haskell that facilitates
  stating and semi-automatically proving typeclass laws. Liquid
  Haskell augments Haskell with \emph{refinement types}---our work
  allows such types to be attached to typeclass method definitions,
  and ensures that instance implementations respect these types. Using
  \emph{refinement reflection}, we can express laws as ``methods'' of
  a subclass of the typeclass of interest, where the types of these
  methods are the properties we want to prove. Thus proofs (carried
  out semi-automatically by an SMT solver) are modular
  and do not necessitate a full switch to Liquid Haskell (though,
  doing so would allow the programmer to take best advantage of the
  proved properties).

  We formalize our approach, describe its
  implementation (which takes significant advantage of the library API of
  GHC, the Glasgow Haskell Compiler), and present an evaluation on 34
  instances of 5 different typeclasses. We find that the manual proof
  burden is often low (a few lines) and verification times are often short
  (a few seconds), though more involved properties require more time
  and/or effort.
  },
  month = mar,
  year = 2020,
  submitted = {yes},
  category = {Miscellaneous},
  url = {http://www.cs.umd.edu/~mwh/papers/lh-typeclasses-draft.pdf}
}

@incollection{trilla20probprog,
  title        = "Probabilistic Abstract Interpretation: Sound Inference and Application to Privacy",
  booktitle    = "Foundations of Probabilistic Programming",
  author       = "Jose Manuel Calder\'{o}n Trilla and Michael Hicks and Stephen Magill and Piotr Mardziel and Ian Sweet",
  editor = {Gilles Barthe and Joost-Pieter Katoen and Alexandra Silva},
  chapter      = 15,
  pages        = "401--432",
  year         = 2020,
  publisher    = "Cambridge University Press",
  abstract = {
  Bayesian probability models uncertain knowledge and learning from observations. As a defining feature of optimal adversarial behaviour, Bayesian reasoning forms the basis of safety properties in contexts such as privacy and fairness. Probabilistic programming is a convenient implementation of Bayesian reasoning but the adversarial setting imposes obstacles to its use: approximate inference can underestimate adversary knowledge and exact inference is impractical in cases covering large state spaces.

By abstracting distributions, the semantics of a probabilistic language, and inference, jointly termed \emph{probabilistic abstract interpretation}, we demonstrate adversary models both approximate and sound.

We apply the techniques to build a privacy protecting monitor and describe how to trade off the precision and computational cost in its implementation all the while remaining sound with respect to privacy risk bounds.},
}

@inproceedings{darais20obliv,
  title = {A Language for Probabilistically Oblivious Computation},
  booktitle = inproc # popl,
  author = {David Darais and Ian Sweet and Chang Liu and Michael Hicks},
abstract = {
  An oblivious computation is one that is free of direct and indirect
  information leaks, e.g., due to observable differences in timing and
  memory access patterns.  This paper presents
  $\lambda_{obliv}$, a core language whose type system enforces obliviousness.
  Prior work on type-enforced oblivious computation has focused on
  deterministic programs. $\lambda_{obliv}$ is new in its consideration of
  programs that implement \emph{probabilistic} algorithms, such as
  those involved in cryptography. $\lambda_{obliv}$ employs a substructural type
  system and a novel notion of \emph{probability region} to ensure that
  information is not leaked via the distribution of visible
  events. The use of regions was motivated by a source of unsoundness
  that we discovered in the type system of ObliVM, a language for implementing
  state of the art oblivious algorithms and data structures. We prove
  that $\lambda_{obliv}$'s type system enforces obliviousness and show that it is
  expressive enough to typecheck advanced tree-based oblivious RAMs.
},
  year      = {2020},
  url = {https://arxiv.org/abs/1711.09305},
  month = jan,
  category = {Security},
}

@article{pierce20carbon,
  author = {Benjamin Pierce and Michael Hicks and Crista Lopes and Jens Palsberg},
  title = {Conferences in an Era of Expensive Carbon},
  journal = {Communications of the {ACM}},
  month = mar,
  year = 2020,
  url = {https://cacm.acm.org/magazines/2020/3/243024-conferences-in-an-era-of-expensive-carbon/abstract},
  abstract = {Air travel is a significant source of greenhouse gas emissions when tallied per traveler. This means that for many scientists, travel to conferences may be a substantial or even dominant part of their individual contribution to climate change. What should {ACM} do, in recognition of this situation? Two years ago, {SIGPLAN} convened an ad hoc Climate Committee to research this question; we are its members. After investigating many options and intensive and wide-ranging discussions, we are putting forward two concrete proposals. First, all {ACM} conferences should publicly account for the greenhouse gases emitted as a result of putting them on. Second, {ACM} should put a price on carbon in conference budgets, to create pressure on organizers to reduce their footprints.},
  category = {Miscellaneous},
  note = {Preprint at \url{https://www.cs.umd.edu/~mwh/papers/co2acm.pdf}}
}

@misc{hietala19voqc,
  author = {Kesha Hietala and Robert Rand and Shih-Han Hung and Xiaodi Wu and Michael Hicks},
  title = {A Verified Optimizer for Quantum Circuits},
  abstract = {
  We present \textsc{voqc}, the first fully verified compiler for quantum circuits, written using the Coq proof assistant. Quantum circuits are expressed as programs in a simple, low-level language called \textsc{sqir}, which is deeply embedded in Coq. Optimizations and other transformations are expressed as Coq functions, which are proved correct with respect to a semantics of \textsc{sqir} programs.
%\textsc{sqir} is also sufficiently expressive to write source programs and prove them correct.
We evaluate \textsc{voqc}'s verified optimizations on a series of benchmarks, and it performs comparably to industrial-strength compilers. \textsc{voqc}'s optimizations reduce total gate counts on average by 17.7\% on a benchmark of 29 circuit programs compared to a 10.7\% reduction when using IBM's Qiskit compiler.
},
  category = {Quantum_Computation},
  month = nov,
  url = {https://www.cs.umd.edu/~mwh/papers/voqc-draft.pdf},
  year = {2019},
  submitted = {yes},
}


@article{parker19bibifi,
  author = {James Parker and Michael Hicks and Andrew Ruef and Michelle L. Mazurek and Dave Levin and Daniel Votipka and Piotr Mardziel and Kelsey R. Fulton},
  title     = {Build It, Break It, Fix It: Contesting Secure Development},
  journal = tops,
abstract = {
Typical security contests focus on breaking or mitigating the impact
  of buggy systems. We present the Build-it, Break-it, Fix-it
  (BIBIFI) contest, which aims to assess the ability to securely
  build software, not just break it. In BIBIFI, teams build specified
  software with the goal of maximizing correctness, performance, and
  security. The latter is tested when teams attempt to break other
  teams' submissions. Winners are chosen from among the best builders
  and the best breakers. BIBIFI was designed to be open-ended---teams
  can use any language, tool, process, etc. that they like. As such,
  contest outcomes shed light on factors that correlate with
  successfully building secure software and breaking insecure
  software. We ran three contests involving a total of 156
  teams and three different programming problems.
  Quantitative analysis
  from these contests found that the most efficient build-it
  submissions used C/C++, but submissions coded in a statically-type safe
  language were $11\times$ less likely to have a security flaw than C/C++ submissions.
	Break-it teams that were also successful build-it teams were
  significantly better at finding security bugs.
},
  year      = {2020},
  url       = {https://www.cs.umd.edu/~mwh/papers/bibifi-long-draft.pdf},
  month = mar,
  note = {Accepted for publication},
  category = {Security},

}

@misc{ran19sqire,
  author = {Kesha Hietala and Robert Rand and Shih-Han Hung and Xiaodi Wu and Michael Hicks},
  title = {Verified Optimization in a Quantum Intermediate Representation},
  abstract = {
We present sqire, a low-level language for quantum computing and verification. sqire uses a global register of quantum bits, allowing easy compilation to and from existing `quantum assembly' languages and simplifying the verification process. We demonstrate the power of sqire as an intermediate representation of quantum programs by verifying a number of useful optimizations, and we demonstrate sqire's use as a tool for general verification by proving several quantum programs correct.
  },
  institution  = {CoRR},
  number    = {abs/1904.06319},
  year      = {2019},
  url = {https://arxiv.org/abs/1904.06319},
  archivePrefix = {arXiv},
  eprint    = {1904.06319},
  category = {Quantum_Computation},
  month = jun,
  note = {Extended abstract appeared at QPL 2019}
}

@inproceedings{lampropoulos19fuzzchick,
  author = {Leonidas Lampropoulos and Michael Hicks and Benjamin C. Pierce},
  title = {Coverage Guided, Property Based Testing},
  booktitle = inproc # oopsla,
  abstract = {
Property-based random testing, exemplified by frameworks such as
Haskell's QuickCheck, works by testing an executable predicate (a
\emph{property}) on a stream of randomly generated inputs.
Property testing works very well in many cases, but not always.
Some properties are conditioned on the input satisfying demanding
semantic invariants that are not consequences of its
syntactic structure---e.g., that an input list must be sorted or have no
duplicates.
Most randomly generated inputs fail to satisfy properties with such
\emph{sparse preconditions}, and so are simply discarded.
As a result, much of the target system may go untested.

We address this issue with a novel technique
called \emph{coverage guided, property based testing (CGPT)}. Our
approach is inspired by the related area of coverage guided fuzzing,
exemplified by tools like AFL\@.
Rather than just generating a fresh random input at each iteration, CGPT
can also produce new inputs by mutating previous ones using type-aware,
generic mutation operators.
The target program is instrumented to track which control flow
branches are executed during a run and
inputs whose runs expand control-flow coverage are retained for
future mutations.
This means that, when sparse conditions in the target are satisfied and new
coverage is observed, the input that triggered them will be retained
and used as a springboard to go further.

We have implemented CGPT as an extension to the QuickChick property testing
tool for Coq programs; we call our implementation FuzzChick.
We evaluate FuzzChick on two Coq developments for abstract machines
that aim to enforce flavors of noninterference, which has a (very)
sparse precondition.
We systematically inject bugs in the machines' checking rules and use
FuzzChick to look for counterexamples to the claim that they satisfy a standard
noninterference property.
We find that vanilla QuickChick almost always fails to find any bugs
after a long period of time, as does an earlier proposal for combining
property testing and fuzzing. In contrast, FuzzChick often finds them
within seconds to minutes.
Moreover, FuzzChick is almost fully automatic; although highly
tuned, hand-written generators can find the bugs faster than
FuzzChick, they require substantial amounts of insight and manual
effort.
  },
  category = {Testing},
  year = 2019,
  month = oct,
  url = {https://www.cs.umd.edu/~mwh/papers/fuzzchick.pdf},
}

@inproceedings{votipka19bibifiqual,
  AUTHOR = {Daniel Votipka and Kelsey Fulton and James Parker and Matthew Hou and Michelle L. Mazurek and Michael Hicks},
  TITLE = {Understanding security mistakes developers make: Qualitative analysis from {Build It, Break It, Fix It}},
  BOOKTITLE = inproc # sec,
  abstract = {
Secure software development is a challenging task requiring consideration of many possible threats and mitigations.
This paper investigates how and why programmers, despite a
baseline of security experience, make security-relevant errors.
To do this, we conducted an in-depth analysis of 94 submissions to a secure-programming contest designed to mimic
real-world constraints: correctness, performance, and security.
In addition to writing secure code, participants were asked
to search for vulnerabilities in other teams’ programs; in total, teams submitted 866 exploits against the submissions we
considered. Over an intensive six-month period, we used iterative open coding to manually, but systematically, characterize
each submitted project and vulnerability (including vulnerabilities we identified ourselves). We labeled vulnerabilities
by type, attacker control allowed, and ease of exploitation,
and projects according to security implementation strategy.
Several patterns emerged. For example, simple mistakes were
least common: only 21\% of projects introduced such an error.
Conversely, vulnerabilities arising from a misunderstanding
of security concepts were significantly more common, appearing in 78\% of projects. Our results have implications for
improving secure-programming APIs, API documentation,
vulnerability-finding tools, and security education.
  },
  YEAR = {2020},
  MONTH = aug,
  category = {Security},
  url = {https://www.usenix.org/system/files/sec20summer_votipka-understanding_prepub.pdf}
}

@InProceedings{rand19qplperspective,
  author =	{Robert Rand and Kesha Hietala and Michael Hicks},
  title =	{{Formal Verification vs. Quantum Uncertainty}},
  booktitle =	{3rd Summit on Advances in Programming Languages (SNAPL 2019)},
abstract = {
Quantum programming is hard: Quantum programs are necessarily probabilistic and impossible to examine without disrupting the execution of a program. In response to this challenge, we and a number of other researchers have written tools to verify quantum programs against their intended semantics. \emph{This is not enough.} Verifying an idealized semantics against a real world quantum program doesn't allow you to confidently predict the program's output. In order to have verification that works, you need both an error semantics related to the hardware at hand (this is necessarily low level) and certified compilation to the that same hardware. Once we have these two things, we can talk about an approach to quantum programming where we start by writing and verifying programs at a high level, attempt to verify properties of the compiled code, and repeat as necessary.
},
  pages =	{12:1--12:11},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-113-9},
  ISSN =	{1868-8969},
  MONTH = may,
  year =	{2019},
  volume =	{136},
  editor =	{Benjamin S. Lerner and Rastislav Bod{\'i}k and Shriram Krishnamurthi},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  category = {Quantum_Computation},
  url = {http://drops.dagstuhl.de/opus/volltexte/2019/10555/pdf/LIPIcs-SNAPL-2019-12.pdf},
  URN =		{urn:nbn:de:0030-drops-105558},
  doi =		{10.4230/LIPIcs.SNAPL.2019.12},
  annote =	{Keywords: Formal Verification, Quantum Computing, Programming Languages, Quantum Error Correction, Certified Compilation, NISQ}
}

@inproceedings{wysstar18wysstar,
  author = {Aseem Rastogi and Nikhil Swamy and Michael Hicks},
  title = {Wys$^*$: A DSL for Verified Secure Multi-party Computations},
  booktitle = inproc # post,
abstract = {
  Secure multi-party computation (MPC) enables a set of mutually
distrusting parties to cooperatively compute, using a cryptographic
protocol, a function over their private data.
This paper presents Wys$^*$, a new domain-specific language (DSL)
for writing MPCs. Wys$^*$ is an embedded DSL hosted in F$^*$, a
verification-oriented, effectful programming language.
Wys$^*$ source programs are
essentially F$^*$ programs written in a custom MPC effect, meaning
that the programmers can use F$^*$'s logic to verify the correctness
and security properties of their programs. To reason about the
distributed runtime semantics of these programs, we formalize a deep
embedding of Wys$^*$, also in F$^*$. We mechanize the necessary
metatheory to prove that the properties verified for the Wys$^*$
source programs carry over to the distributed, multi-party
semantics. Finally, we use F$^*$'s extraction mechanism to
extract an interpreter that we have proved matches this semantics,
yielding a verified implementation. Wys$^*$ is the first
DSL to enable formal verification of source MPC programs, and also the
first MPC DSL to provide a verified implementation.
With Wys$^*$ we have implemented several MPC protocols, including
private set intersection, joint median, and an MPC-based card dealing
application, and have verified their security and correctness.
},
  month = apr,
  category = {Security},
  year = 2019,
  url = {http://www.cs.umd.edu/~mwh/papers/wysstar.pdf},
}

@inproceedings{ruef18checkedc-incr,
  author = {Andrew Ruef and Leonidas Lampropoulos and Ian Sweet and David Tarditi and Michael Hicks},
  title = {Achieving Safety Incrementally with Checked C},
  booktitle = inproc # post,
  abstract = {
  Checked C is a new effort working toward a memory-safe C. Its design
  is distinguished from that of prior efforts by truly being an
  \emph{extension} of C: Every C program is also a Checked C
  program. Thus, one may make incremental safety improvements to
  existing codebases while retaining backward compatibility. This
  paper makes two contributions. First, to help developers convert
  existing C code to use so-called \emph{checked} (i.e., safe)
  pointers, we have developed a preliminary, automated porting tool. Notably, this
  tool takes advantage of the flexibility of Checked C's design: The
  tool need not perfectly classify every pointer, as required of prior
  all-or-nothing efforts. Rather, it can make a best effort to convert
  more pointers accurately, without letting inaccuracies inhibit
  compilation. However, such partial conversion raises the question:
  If safety violations can still occur, what sort of advantage does
  using Checked C provide? We draw inspiration from research on
  migratory typing to make our second contribution: We prove a
  \emph{blame} property that renders so-called \emph{checked regions}
  blameless of any run-time failure. We formalize this property for a
  core calculus and mechanize the proof in Coq.
  },
  category = "Safe_Low-Level_Programming",
  url = {http://www.cs.umd.edu/~mwh/papers/checkedc-incr.pdf},
  month = apr,
  year = 2019,
}

@inproceedings{pina19mvedsua,
  author = {Luis Pina and Anastasios Andronidis and Michael Hicks and Cristian Cadar},
  title = {{MVEDSUa}: Higher Availability Dynamic Software Updates via
    Multi-Version Execution},
  booktitle = inproc # asplos,
  year = {2019},
  month = apr,
  abstract = {
  Dynamic Software Updating (DSU) is a general-purpose technique for
patching stateful software without shutting it down, which enables
both timely updates and non-stop service. However, applying an update
could induce a long delay in service, and bugs in the
update---both in the changed code and in the specification for
effecting that change dynamically---may cause the updated software to
crash or misbehave.

This paper proposes MVEDSUa, a system that solves these problems by
augmenting a DSU system with support for Multi-Version Execution
(MVE). To start, MVEDSUa performs an update in
parallel with the original system, thereby avoiding any service
delay. Then, it monitors that the updated and original systems' responses agree
when given the same inputs. Expected differences are
specified by the programmer, so remaining differences signal likely
errors. If the new version shows no problems, it can be installed
permanently.

We implemented MVEDSUa on top of Kitsune and Varan, state-of-the-art DSU
and MVE systems respectively, and used it to update several
high-performance servers: redis, memcached, and vsftpd. Our
results show that MVEDSUa significantly reduces the update-time delay, imposes
little overhead in steady state, and easily recovers from a variety of
update-related errors.
  },
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/mvedsua.pdf}
}

@inproceedings{hung19qrobust,
  author    = {Shih-Han Hung and Kesha Hietala and Shaopeng Zhu and Mingsheng Ying and Michael Hicks and Xiaodi Wu},
  title     = {Quantitative Robustness Analysis of Quantum Programs},
  booktitle = inproc # popl,
  year      = {2019},
  month     = jan,
  abstract = {
  Quantum computation is a topic of significant recent interest, with
practical advances coming from both research and
industry. A major challenge in
quantum programming is dealing with errors (quantum noise) during
execution. Because quantum resources (e.g., qubits) are scarce,
classical error correction techniques applied at the level of the
architecture are currently cost-prohibitive. But while this reality means
that quantum programs are almost certain to have errors, there as yet
exists no principled means to reason about erroneous behavior.
This paper attempts to fill this gap by developing a semantics for
erroneous quantum while-programs, as well as a logic for reasoning
about them. This logic permits proving a property we have
identified, called $\epsilon$-robustness, which characterizes
possible ``distance'' between an ideal program and an erroneous one. We
have proved the logic sound, and showed its utility on several case
studies, notably: (1) analyzing the robustness of noisy versions of the
quantum Bernoulli factory (QBF) and quantum walk (QW); (2) demonstrating
the (in)effectiveness of different error correction schemes on
single-qubit errors; and (3) analyzing the robustness of a
fault-tolerant version of QBF.
},
 category = {Quantum_Computation},
 url = {http://www.cs.umd.edu/~mwh/papers/qcerrs-full.pdf}
}

@inproceedings{parker19lweb,
  author    = {James Parker and Niki Vazou and Michael Hicks},
  title     = {{LWeb}: Information Flow Security for Multi-Tier Web Applications},
  booktitle = inproc # popl,
  year      = {2019},
  month     = jan,
  abstract = {
  This paper presents LWeb, a framework for enforcing label-based,
  information flow policies in database-using web applications. In a
  nutshell, LWeb marries the LIO Haskell IFC enforcement library
  with the Yesod web programming framework. The implementation has
  two parts. First, we extract the core of LIO into a monad
  transformer (LMonad) and then apply it to Yesod's core monad. Second,
  we extend Yesod's table definition DSL and query functionality to
  permit defining and enforcing label-based policies on tables and enforcing
  them during query processing. LWeb's policy language is expressive,
  permitting dynamic per-table and per-row policies. We formalize the
  essence of LWeb in the LWebcalc calculus and mechanize the proof of
  noninterference in Liquid Haskell. This mechanization constitutes
  the first metatheoretic proof carried out in Liquid Haskell. We also
  used LWeb to build a substantial web site hosting the \emph{Build it,
  Break it, Fix it} security-oriented programming contest. The site
  involves 40 data tables and sophisticated policies. Compared to
  manually checking security policies, LWeb imposes a modest runtime
  overhead of between 2\% to 21\%. It reduces
  the trusted code base from the whole application to just 1\% of the
  application code, and 21\% of the code overall (when counting LWeb too).
},
 category = {Security},
 url = {https://arxiv.org/pdf/1901.07665.pdf}
}

@inproceedings{hicks17plas,
  author    = {Michael Hicks},
  title     = {Languages for Oblivious Computation},
  booktitle = inproc # plas,
  year      = {2017},
  month     = oct,
  url       = {http://www.cs.umd.edu/~mwh/papers/mto-plas-keynote.pdf},
  category  = {Security},
  abstract  = {
    This is a 1-page abstract of my keynote talk at Workshop on
    Programming Languages and Security, colocated with the ACM
    Symposium on Computer and Communications Security. It discusses
    the role of programming languages in ensuring oblivious (side
    channel-free) computation.
  }
}

@inproceedings{klees2018fuzzeval,
  author    = {George T. Klees and Andrew Ruef and Benjamin Cooper and Shiyi Wei and Michael Hicks},
  title     = {Evaluating Fuzz Testing},
  booktitle = inproc # ccs,
  abstract = { Fuzz testing has enjoyed great success at discovering
                  security critical bugs in real software. Recently,
                  researchers have devoted significant effort to
                  devising new fuzzing techniques, strategies, and
                  algorithms. Such new ideas are primarily evaluated
                  experimentally so an important question is: What
                  experimental setup is needed to produce trustworthy
                  results? We surveyed the recent research literature
                  and assessed the experimental evaluations carried
                  out by 32 fuzzing papers. We found problems in every
                  evaluation we considered. We then performed our own
                  extensive experimental evaluation using an existing
                  fuzzer. Our results showed that the general problems
                  we found in existing experimental evaluations can
                  indeed translate to actual wrong or misleading
                  assessments. We conclude with some guidelines that
                  we hope will help improve experimental evaluations
                  of fuzz testing algorithms, making reported results
                  more robust.},
  year      = {2018},
  month = oct,
  category = {Security},
  url = {https://arxiv.org/abs/1808.09700}
}

@inproceedings{elliott18checkedc,
  title = {Checked C: Making C Safe by Extension},
  author = {Archibald Samuel Elliott and Andrew Ruef and Michael Hicks and David Tarditi},
  booktitle = inproc # secdev,
  abstract = {
This paper presents Checked C, an extension to C designed to support spatial safety, implemented in Clang and LLVM. Checked C’s design is distinguished by its focus on backward-compatibility, incremental conversion, developer control, and enabling highly performant code. Like past approaches to a safer C, Checked C employs a form of checked pointer whose accesses can be statically or dynamically verified. Performance evaluation on a set of standard benchmark programs shows overheads to be relatively low. More interestingly, Checked C introduces the notions of a checked region and bounds-safe interfaces.
  },
  category = "Safe_Low-Level_Programming",
  month = sep,
  year = 2018,
  url = {http://www.cs.umd.edu/~mwh/papers/checked-c.pdf}
}

@techreport{darais19obliv,
  title = {A Language for Probabilistically Oblivious Computation},
  author = {David Darais and Ian Sweet and Chang Liu and Michael Hicks},
abstract = {
  An oblivious computation is one that is free of direct and indirect
  information leaks, e.g., due to observable differences in timing and
  memory access patterns.  This paper presents
  $\lambda_{obliv}$, a core language whose type system enforces obliviousness.
  Prior work on type-enforced oblivious computation has focused on
  deterministic programs. $\lambda_{obliv}$ is new in its consideration of
  programs that implement \emph{probabilistic} algorithms, such as
  those involved in cryptography. $\lambda_{obliv}$ employs a substructural type
  system and a novel notion of \emph{probability region} to ensure that
  information is not leaked via the distribution of visible
  events. The use of regions was motivated by a source of unsoundness
  that we discovered in the type system of ObliVM, a language for implementing
  state of the art oblivious algorithms and data structures. We prove
  that $\lambda_{obliv}$'s type system enforces obliviousness and show that it is
  expressive enough to typecheck advanced tree-based oblivious RAMs.
},
  institution   = {CoRR},
  number    = {abs/1711.09305},
  year      = {2019},
  url = {https://arxiv.org/abs/1711.09305},
  archivePrefix = {arXiv},
  eprint    = {1711.09305},
  month = jul,
  category = {Security},
}

@inproceedings{sweet18prob,
title = {What's the Over/Under? Probabilistic Bounds on Information Leakage},
booktitle = inproc # post,
author = {Ian Sweet and Jos\'e Manuel Calder\'on Trilla and
  Chad Scherrer and Michael Hicks and Stephen Magill},
abstract = {
  Quantitative information flow (QIF) is concerned with measuring
  how much of a secret is leaked to an adversary who observes the
  result of a computation that uses it. Prior work has shown that QIF
  techniques based on \emph{abstract interpretation} with
  \emph{probabilistic polyhedra} can be used to analyze the worst-case
  leakage of a query, on-line, to determine whether that query can be
  safely answered. While this approach can provide precise estimates,
  it does not scale well. This paper shows how to solve the
  scalability problem by augmenting the baseline technique with
  \emph{sampling} and \emph{symbolic execution}. We prove that our
  approach never underestimates a query's leakage (it is
  sound), and detailed experimental results show that we can
  match the precision of the baseline technique but with orders of
  magnitude better performance.
},
  category = {Security},
  month = apr,
  year = 2018,
  url = {http://www.cs.umd.edu/~mwh/papers/prob-post.pdf}
}

@inproceedings{wei18evaluating,
  author = {Shiyi Wei and Piotr Mardziel and Andrew Ruef and Jeffrey S. Foster and Michael Hicks},
  title = {Evaluating Design Tradeoffs in Numeric Static Analysis for Java},
  booktitle = inproc # esop,
  abstract = {
  Numeric static analysis for Java has a broad range of potentially
  useful applications, including array bounds checking and resource
  usage estimation. However, designing a scalable numeric static
  analysis for real-world Java programs presents a multitude of design
  choices, each of which may interact with others. For example, an
  analysis could handle method calls via either a top-down or
  bottom-up interprocedural analysis. Moreover, this choice could
  interact with how we choose to represent aliasing in the heap and/or
  whether we use a relational numeric domain, e.g., convex polyhedra.
  In this paper, we present a family of abstract interpretation-based
  numeric static analyses for Java and systematically evaluate the
  impact of 162 analysis configurations on the DaCapo benchmark
  suite. Our experiment considered the precision and performance of
  the analyses for discharging array bounds checks. We found that
  top-down analysis is generally a better choice than bottom-up
  analysis, and that using access paths to describe heap objects is
  better than using summary objects corresponding to points-to
  analysis locations. Moreover, these two choices are the most
  significant, while choices about the numeric domain, representation
  of abstract objects, and context-sensitivity make much less
  difference to the precision/performance tradeoff.
},
  category = {Static_Analysis},
  month = apr,
  year = 2018,
  url = {http://www.cs.umd.edu/~mwh/papers/jana-analysis.pdf}
}

@inproceedings{ngyuen17numinv,
author = {ThanhVu Nguyen and Timos Antopoulos and Andrew Ruef and Michael Hicks},
title = {A Counterexample-guided Approach to Finding Numerical Invariants},
booktitle = inproc # fse,
abstract = {
Numerical invariants, e.g., relationships among numerical variables
in a program, represent a useful class of properties to analyze programs.
General polynomial invariants represent more complex
numerical relations, but they are often required in many scientific
and engineering applications. We present NumInv, a tool that implements
a counterexample-guided invariant generation (CEGIR)
to automatically discover numerical invariants, which are polynomial
equality and inequality relations among numerical variables.
This CEGIR technique infers candidate invariants from program
traces and then checks them against the program source code using
the KLEE test-input generation tool. If the invariants are incorrect
KLEE returns counterexample traces, which help the dynamic
inference obtain better results. Existing CEGIR approaches often
require sound invariants, however NumInv sacrifices soundness
and produces results that KLEE cannot refute within certain time
bound. This design and the use of KLEE as a verifier allow NumInv
to discover useful and important numerical invariants for many
challenging programs.

Preliminary results show that NumInv generates required invariants
for understanding and verifying correctness of programs
involving complex arithmetic. We also show that NumInv discovers
polynomial invariants that capture precise complexity bounds of
programs used to benchmark existing static complexity analysis
techniques. Finally, we show that NumInv performs competitively
comparing to state of the art numerical invariant analysis tools
},
month = sep,
year = 2017,
category = {Static_Analysis},
url = {http://www.cs.umd.edu/~mwh/papers/dig2.pdf}
}

@inproceedings{antopoulous17blazer,
  author = {Timos Antonopoulos and Paul Gazzillo and Michael Hicks and Eric Koskinen and Tachio Terauchi and Shiyi Wei},
  booktitle = inproc # pldi,
  title = {Decomposition Instead of Self-Composition for Proving the Absence of Timing Channels},
  abstract = {
We present a novel approach to proving the absence of timing channels.
The idea is to partition the program's execution traces in such a way
that each partition component is checked for timing attack
resilience by a time complexity analysis and that per-component
resilience implies the resilience of the whole program.  We construct
a partition by splitting the program traces at
secret-independent branches.  This ensures that any pair of traces
with the same public input has a component containing both
traces.  Crucially, the per-component checks can be normal \emph{safety
properties} expressed in terms of a single execution.  Our approach is
thus in contrast to prior approaches, such as \emph{self-composition},
that aim to reason about multiple ($k\geq 2$) executions at once.

We formalize the above as an approach called {\em quotient partitioning},
generalized to any $k$-safety property, and prove it to be sound. A
key feature of our approach is a demand-driven partitioning strategy
that uses a regex-like notion called \emph{trails} to identify sets of
execution traces, particularly those influenced by tainted (or secret)
data.
We have applied our technique in a prototype implementation
tool called \emph{Blazer}, based on WALA, PPL, and the brics
automaton library.
We have proved timing-channel freedom of (or synthesized an attack
specification for) 24 programs
written in Java bytecode, including 6 classic examples from the literature and 6
examples extracted from the DARPA STAC challenge problems.
},
  category = {Static_Analysis},
  month = jun,
  year = 2017,
  url = {http://www.cs.umd.edu/~mwh/papers/blazer.pdf}
}

@inproceedings{alvim17strat,
  author = {M\'{a}rio S. Alvim and Piotr Mardziel and Michael Hicks},
  title = {Quantifying vulnerability of secret generation using hyper-distributions},
  booktitle = inproc # post,
  abstract = {
    Traditional approaches to Quantitative Information Flow (QIF)
  represent the adversary's prior knowledge of possible secret values
  as a single probability distribution.
  This representation may miss important
  structure.
  For instance, representing prior knowledge about
  passwords of a system's users in this way
  overlooks the fact  that many users generate passwords using
  some \emph{strategy}.  Knowledge of such strategies can
  help the adversary in guessing a secret, so ignoring them may
  underestimate the secret's vulnerability.
  In this paper we explicitly model strategies as
  distributions on secrets, and  generalize the representation of
  the adversary's prior knowledge from a distribution on secrets
  to an \emph{environment}, which is a distribution on strategies
  (and, thus, a distribution on distributions on secrets,
  called a \emph{hyper-distribution}).
  By applying information-theoretic techniques to environments
  we derive several meaningful generalizations of the traditional
  approach to QIF.
  In particular, we disentangle the
  \emph{vulnerability of a secret} from the \emph{vulnerability of the strategies}
  that generate secrets, and thereby distinguish
  \emph{security by aggregation}---which relies on the uncertainty over
  strategies---from \emph{security by strategy}---which relies on the
  intrinsic uncertainty within a strategy.
  We also demonstrate that, in a precise way, no further generalization
  of prior knowledge
  (e.g., by using distributions of even higher order)
  is needed to soundly quantify the vulnerability of the secret.
},
  year = 2017,
  month = apr,
  category = {Security},
  note = {Extended version of short paper that appeared at FCS 2016: \url{http://www.cs.umd.edu/~mwh/papers/stratquant.pdf}},
  url = {https://arxiv.org/abs/1701.04174}
}

@techreport{rastogi16wysstar,
  author = {Aseem Rastogi and Nikhil Swamy and Michael Hicks},
  title = {Wys$^*$: A Verified Language Extension for Secure Multi-Party Computations},
  abstract = {
  Secure multi-party computation (MPC) enables a set of mutually
distrusting parties to cooperatively compute, using a cryptographic
protocol, a function over their private data.
This paper presents Wys$^*$, a new domain-specific language (DSL)
implementation for
writing MPC{s}. Wys$^*$ is a
\emph{Verified, Domain-Specific Integrated Language Extension}
(VDSILE), a new kind of embedded DSL hosted in F$^*$, a
full-featured, verification-oriented programming language.
Wys$^*$ source programs are
essentially F$^*$ programs written against an MPC library, meaning
that the programmers can use F$^*$'s logic to verify the correctness
and security properties of their programs. To reason about the
distributed semantics of these programs, we formalize a deep
embedding of Wys$^*$, also in F$^*$. We mechanize the necessary
metatheory to prove that the properties verified for the Wys$^*$
source programs carry over to the distributed, multi-party
semantics. Finally, we use F$^*$'s extraction mechanism to
extract an interpreter that we have proved matches this semantics,
yielding a verified implementation. Indeed, Wys$^*$ is the first
DSL to enable formal verification of source MPC programs, and also the
first MPC DSL to provide a verified implementation.
With Wys$^*$ we have implemented several MPC protocols, including
private set intersection, joint median, and an MPC-based card dealing
application, and have verified their security and correctness.
},
  institution  = {CoRR},
  number    = {abs/1711.06467},
  year      = {2017},
  url = {https://arxiv.org/abs/1711.06467},
  archivePrefix = {arXiv},
  eprint    = {1711.06467},
  month = nov,
  category = {Security},
}

@inproceedings{ruef2016bibifi,
  author    = {Andrew Ruef and Michael Hicks and James Parker and Dave Levin and Michelle L. Mazurek and Piotr Mardziel},
  title     = {Build It, Break It, Fix It: Contesting Secure Development},
  booktitle = inproc # ccs,
  abstract = {
  Typical security contests focus on breaking or mitigating the impact
  of buggy systems. We present the Build-it, Break-it, Fix-it
  (BIBIFI) contest, which aims to assess the ability to securely
  build software, not just break it. In BIBIFI, teams build specified
  software with the goal of maximizing correctness, performance, and
  security. The latter is tested when teams attempt to break other
  teams' submissions. Winners are chosen from among the best builders
  and the best breakers. BIBIFI was designed to be open-ended---teams
  can use any language, tool, process, etc.~that they like. As such,
  contest outcomes shed light on factors that correlate with
  successfully building secure software and breaking insecure
  software. During 2015, we ran three contests involving a total of 116
  teams and two different programming problems. Quantitative analysis
  from these contests found that the most efficient build-it
  submissions used C/C++, but submissions coded in other statically-typed
  languages were less likely to have a security flaw; build-it teams
  with diverse programming-language knowledge also produced more
  secure code. Shorter programs correlated with better
  scores. Break-it teams that were also successful build-it teams were
  significantly better at finding security bugs.
  },
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01881},
  month = oct,
  category = {Security},
}

@article{ruef15bibifiNW,
  author = {Andrew Ruef and Michael Hicks},
  journal = {The Next Wave},
  title = {Build it, break it, fix it: Competing to build secure systems},
  abstract = { We have a long legacy of failing to build secure
                  systems; can a coding competition give us insight
                  into what we can do better? This article presents an
                  overview of the Build-it, Break-it, Fix-it
                  Security-oriented programming competition.  },
  volume = 21,
  number = 1,
  pages = {19--23},
  year = 2015,
  mon = oct,
  category = {Security},
  url = {https://www.nsa.gov/resources/everyone/digital-media-center/publications/the-next-wave/assets/files/TNW-21-1.pdf}
  }

@inproceedings{pina16tedsuto,
  author = {Luis Pina and Michael Hicks},
  booktitle = inproc # icst,
  title = {Tedsuto: A General Framework for Testing Dynamic Software Updates},
  abstract = {
  Dynamic software updating (DSU) is a technique for patching
  \emph{running} programs, to fix bugs or add new features.
  DSU avoids the downtime of stop-and-restart updates, but creates new
  risks---an incorrect or ill-timed dynamic update could result in a
  crash or misbehavior, defeating the whole purpose of DSU\@. To
  reduce such risks, dynamic updates should be carefully
  tested before they are deployed.
  This paper presents Tedsuto, a general testing framework for DSU,
  along with a concrete implementation of it for Rubah, a state-of-the-art Java-based
  DSU system. Tedsuto uses system-level tests developed for the old
  and new versions of the updateable software, and systematically
  tests whether a dynamic update might result in a test
  failure. Very often this process is fully automated, while in some
  cases (e.g., to test new-version functionality) some manual
  annotations are required.
  To evaluate Tedsuto's efficacy, we applied it to dynamic
  updates previously developed (and tested in an ad hoc manner) for
  the H2 SQL database server and the CrossFTP server--- two
  real-world, multithreaded systems.  We used three large test suites, totalling
  446 tests, and we found a variety of
  update-related bugs in short order, and at low cost.
},
  category = {Dynamic_Software_Updating},
  year = 2016,
  month = apr,
  url = {http://www.cs.umd.edu/~mwh/papers/tedsuto.pdf}
}

@inproceedings{ruef15bibifi,
  title = {Build It Break It: Measuring and Comparing Development Security},
  author = {Andrew Ruef and Michael Hicks and James Parker and Dave Levin and Atif Memon and Jandelyn Plane and Piotr Mardziel},
  booktitle = inproc # cset,
  abstract = {
There is currently little evidence about what tools, methods, processes,
and languages lead to secure software. We present the experimental design
of the Build it Break it secure programming contest as an aim to provide
such evidence. The contest also provides education value to participants
where they gain experience developing programs in an adversarial settings.
We show preliminary results from previous runs of the contest that
demonstrate the contest works as designed, and provides the data desired.
We are in the process of scaling the contest to collect larger data sets
with the goal of making statistically significant correlations between
various factors of development and software security.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/bibifi-cset15.pdf},
  month = aug,
  year = 2015,
  category = {Security}
}

@inproceedings{saur15morpheus,
  author = {Karla Saur and Joseph Collard and Nate Foster and Arjun Guha and Laurent Vanbever and Michael Hicks},
  title = {Safe and Flexible Controller Upgrades for {SDNs}},
  booktitle = inproc # sosr,
  abstract = {
    SDN controllers must be periodically upgraded to add features,
  improve performance, and fix bugs, but current techniques for
  implementing \emph{dynamic updates}---i.e., without disrupting
  ongoing network functions---are inadequate. Simply halting the old
  controller and bringing up the new one can cause state to be lost,
  leading to incorrect behavior. For example, if the state represents
  flows blacklisted by a firewall, then traffic that should be blocked
  may be allowed to pass through. Techniques based on record and
  replay can reconstruct controller state automatically, but they are
  expensive to deploy and do not work in all scenarios.

  This paper presents a new approach to implementing dynamic updates
  for SDN controllers. We present the design and implementation of a
  new controller platform called Morpheus that uses \emph{explicit state
  transfer} to implement dynamic updates. Morpheus enables programmers to
  directly initialize the upgraded controller's state as a function of
  its existing state, using a domain-specific language that is
  designed to be easy to use. Morpheus also offers a distributed protocol
  for safely deploying updates across multiple nodes. Experiments
  confirm that Morpheus provides correct behavior and good performance.
},
  category = {Programmable_Networks},
  year = 2016,
  month = mar,
  url = {http://www.cs.umd.edu/~mwh/papers/sdnupdate.pdf}
}

@Article{barthe2015dagstuhl,
  author =	{Gilles Barthe and Michael Hicks and Florian Kerschbaum and Dominique Unruh},
  title =	{{The Synergy Between Programming Languages and Cryptography (Dagstuhl Seminar 14492)}},
  pages =	{29--47},
  journal =	{Dagstuhl Reports},
  ISSN =	{2192-5283},
  year =	{2015},
  volume =	{4},
  number =	{12},
  editor =	{Gilles Barthe and Michael Hicks and Florian Kerschbaum and Dominique Unruh},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2015/5004},
  URN =		{urn:nbn:de:0030-drops-50045},
  doi =		{http://dx.doi.org/10.4230/DagRep.4.12.29},
  abstract = {
Increasingly, modern cryptography (crypto) has moved beyond the problem of secure communication to a broader consideration of securing computation. The past thirty years have seen a steady progression of both theoretical and practical advances in designing cryptographic protocols for problems such as secure multiparty computation, searching and computing on encrypted data, verifiable storage and computation, statistical data privacy, and more. More recently, the programming-languages (PL) community has begun to tackle the same set of problems, but from a different perspective, focusing on issues such as language design (e.g., new features or type systems), formal methods (e.g., model checking, deductive verification, static and dynamic analysis), compiler optimizations, and analyses of side-channel attacks and information leakage. This seminar helped to cross-fertilize ideas between the PL and crypto communities, exploiting the synergies for advancing the development of secure computing, broadly speaking, and fostering new research directions in and across both communities.
}
}

@inproceedings{saur16kvolve,
title = {Evolving {NoSQL} Databases Without Downtime},
booktitle = inproc # icsme,
author = {Karla Saur and Tudor Dumitra\c{s} and Michael Hicks},
abstract = {
  NoSQL
  databases like Redis, Cassandra, and MongoDB are
  increasingly popular because they are flexible, lightweight, and
  easy to work with. Applications that use these data\-bases
  will evolve over time, sometimes necessitating (or preferring) a change
  to the format or organization of the data. The problem we address in this paper is:
  How can we support the evolution of high-availability applications
  and their NoSQL data \emph{online}, without excessive delays or
  interruptions, even in the presence of backward-incompatible
  data format changes?

We present KVolve, an extension to the popular Redis NoSQL database, as a
  solution to this problem. KVolve permits a developer to
  submit an upgrade specification that defines how to
  transform existing data to the newest version. This transformation
  is applied \emph{lazily} as applications interact with the
  database, thus avoiding long pause times. We demonstrate that KVolve is
  expressive enough to support substantial practical updates,
  including format changes to RedisFS, a Redis-backed file system,
  while imposing essentially no overhead in general use and minimal
  pause times during updates.
},
  month = oct,
  year = 2016,
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/kvolve.pdf}
}

@inproceedings{liu15ghostrider,
author = {Chang Liu and Austin Harris and Martin Maas and Michael Hicks and Mohit Tiwari and Elaine Shi},
title = {GhostRider: A Hardware-Software System for Memory Trace Oblivious Computation},
booktitle = inproc # asplos,
abstract = {
This paper presents a new, co-designed compiler and architecture
called GhostRider for supporting privacy preserving computation in the
cloud. GhostRider ensures all programs satisfy a property called
memory-trace obliviousness (MTO): Even an adversary that observes
memory, bus traffic, and access times while the program executes can
learn nothing about the program's sensitive inputs and outputs. One
way to achieve MTO is employ Oblivious RAM (ORAM), allocating all code
and data in a single ORAM bank, and to also disable caches or fix the
rate of memory traffic. This baseline approach can be inefficient, and
so GhostRider's compiler uses a program analysis to do better,
allocating data to non-oblivious, encrypted RAM (ERAM) and employing a
scratchpad when doing so will not compromise MTO\@. The compiler can
also allocate to multiple ORAM banks, which sometimes significantly
reduces access times. We have formalized our approach and proved it
enjoys MTO\@. Our FPGA-based hardware prototype and simulation results
show that GhostRider significantly outperforms the baseline strategy.
},
month = mar,
year = 2015,
category = {Security},
note = {\textbf{Winner of Best Paper Award}},
url = {http://www.cs.umd.edu/~mwh/papers/ghostrider15.pdf}
}

@inproceedings{hammer14nominal,
  author = {Matthew Hammer and Kyle Headley and Nicholas Labich and Jeffrey S. Foster and Michael Hicks and David Van Horn and Joshua Dunfield},
  title = {Incremental Computation with Names},
  booktitle = inproc # oopsla,
  abstract = {
  Over the past thirty years, there has been significant progress in
  developing general-purpose, language-based approaches to
  \emph{incremental computation}, which aims to efficiently update the
  result of a computation when an input is changed. A key design
  challenge in such approaches is how to provide efficient incremental
  support for a broad range of programs.  In this paper, we argue that
  first-class \emph{names} are a critical linguistic feature for
  efficient incremental computation. Names identify computations to be
  reused across differing runs of a program, and making them first
  class gives programmers a high level of control over reuse. We
  demonstrate the benefits of names by presenting Nominal Adapton, an
  ML-like language for incremental computation with names. We describe
  how to use Nominal Adapton to efficiently incrementalize several
  standard programming patterns---including maps, folds, and
  unfolds---and show how to build efficient, incremental probabilistic
  trees and tries. Since Nominal Adapton's implementation is subtle,
  we formalize it as a core calculus and prove it is
  \emph{from-scratch consistent}, meaning it always produces the same
  answer as simply re-running the computation. Finally, we demonstrate
  that Nominal Adapton can provide large speedups over both
  from-scratch computation and Adapton, a previous state-of-the-art
  incremental system.
  },
  month = oct,
  year = 2015,
  url = {http://arxiv.org/abs/1503.07792}
}

@inproceedings{mardziel14qifgl,
  author = {Piotr Mardziel and M\'ario S. Alvim and Michael Hicks},
  title = {Adversary Gain vs. Defender Loss in Quantified Information Flow},
  booktitle = {(Unofficial) Proceedings of the International Workshop on Foundations of Computer Security (FCS)},
  abstract = {
Metrics for quantifying information leakage assume
  that an adversary's gain is the defender's loss.
  We demonstrate that this assumption does not always hold via a class
  of scenarios.
  We describe how to extend quantification to account for a defender
  with goals distinct from adversary failure.
  We implement the extension and experimentally explore the impact on
  the measured information leakage of the motivating scenario.
},
  category = {Security},
  month = jul,
  year = 2014,
  url = {http://www.cs.umd.edu/~mwh/papers/qifgl.pdf}
}

@inproceedings{liu14scram,
  author = {Chang Liu and Yan Huang and Elaine Shi and Jonathan Katz and Michael Hicks},
  title = {Automating Efficient {RAM}-Model Secure Computation},
  booktitle = inproc # oakland,
  abstract = {
RAM-model secure computation addresses the inherent limitations
of circuit-model secure computation considered in almost all previous work.
Here, we describe the first \emph{automated} approach for
RAM-model secure computation in the semi-honest model.
We define an intermediate representation
called SCVM and a corresponding type system suited for RAM-model secure computation.
Leveraging compile-time optimizations, our approach achieves
order-of-magnitude speedups compared to both circuit-model secure
computation and the state-of-art RAM-model secure computation.
  },
  category = {Security},
  month = may,
  year = 2014,
  url = {http://www.cs.umd.edu/~mwh/papers/ram-sc.pdf}
}

@inproceedings{mardziel14time,
  author = {Piotr Mardziel and Mario Alvim and Michael Hicks and Michael Clarkson},
  title = {Quantifying Information Flow for Dynamic Secrets},
  booktitle = inproc # oakland,
  abstract = {
  A metric is proposed for quantifying leakage of information about
  secrets and about how secrets change over time.
  The metric is used with a model of information flow for
  probabilistic, interactive systems with adaptive adversaries.
  The model and metric are implemented in a probabilistic programming
  language and used to analyze several examples.
  The analysis demonstrates that adaptivity increases the amount of
  information that adversaries learn.
  },
  category = {Security},
  month = may,
  year = 2014,
  url = {http://www.cs.umd.edu/~mwh/papers/qif-dynamic-secrets.pdf}
}


@techreport{mardziel14timeTR,
  author = {Piotr Mardziel and Mario Alvim and Michael Hicks and Michael Clarkson},
  title = {Quantifying Information Flow for Dynamic Secrets (extended version)},
  abstract = {
  A metric is proposed for quantifying leakage of information about
  secrets and about how secrets change over time.
  The metric is used with a model of information flow for
  probabilistic, interactive systems with adaptive adversaries.
  The model and metric are implemented in a probabilistic programming
  language and used to analyze several examples.
  The analysis demonstrates that adaptivity increases the amount of
  information that adversaries learn.
  },
  institution = {Department of Computer Science, the University of Maryland, College Park},
  number = {CS-TR-5035},
  category = {Security},
  month = may,
  year = 2014,
  url = {http://www.cs.umd.edu/~mwh/papers/qif-dynamic-secrets-tr.pdf}
}


@techreport{khoo:cs-tr-5021,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks},
  title = {{Expositor: Scriptable Time-Travel Debugging with First-Class Traces}},
  institution = {Department of Computer Science, University of Maryland, College Park},
  year = {2013},
  number = {CS-TR-5021},
  month = {February},
}



@techreport{rastogi14wysteriaTR,
  author = {Aseem Rastogi and Matthew A. Hammer and Michael Hicks},
  title = {Wysteria: A Programming Language for Generic, Mixed-Mode Multiparty Computations (extended version)},
  institution = {Department of Computer Science, the University of Maryland, College Park},
  number = {CS-TR-5034},
  abstract = {
In a Secure Multiparty Computation (SMC), mutually distrusting parties use cryptographic techniques to cooperatively compute over their private data; in the process each party learns only explicitly revealed outputs. In this paper, we present Wysteria, a high-level programming language for writing SMCs. As with past languages, like Fairplay, Wysteria compiles secure computations to circuits that are executed by an underlying engine. Unlike past work, Wysteria provides support for mixed-mode programs, which combine local, private computations with synchronous SMCs. Wysteria complements a standard feature set with built-in support for secret shares and with wire bundles, a new abstraction that supports generic n-party computations. We have formalized Wysteria, its refinement type system, and its operational semantics. We show that Wysteria programs have an easy-to-understand single-threaded interpretation and prove that this view corresponds to the actual multi-threaded semantics. We also prove type soundness, a property we show has security ramifications, namely that information about one party's data can only be revealed to another via (agreed upon) secure computations. We have implemented Wysteria, and used it to program a variety of interesting SMC protocols from the literature, as well as several new ones. We find that Wysteria's performance is competitive with prior approaches while making programming far easier, and more trustworthy.
  },
  month = may,
  year = 2014,
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/wysteria-tr.pdf},
}

@inproceedings{rastogi14wysteria,
  author = {Aseem Rastogi and Matthew A. Hammer and Michael Hicks},
  title = {Wysteria: A Programming Language for Generic, Mixed-Mode Multiparty Computations},
  booktitle = inproc # oakland,
  abstract = {
  In a Secure Multiparty Computation (SMC), mutually distrusting
  parties use cryptographic techniques to cooperatively compute over
  their private data; in the process each party learns only explicitly
  revealed outputs. In this paper, we present Wysteria, a high-level
  programming language for writing SMCs. As with past languages, like
  Fairplay, Wysteria compiles secure computations to circuits that
  are executed by an underlying engine. Unlike past work, Wysteria
  provides support for \emph{mixed-mode} programs, which combine
  local, private computations with synchronous SMCs. Wysteria
  complements a standard feature set with built-in support for secret
  shares and with \emph{wire bundles}, a new abstraction that supports
  generic $n$-party computations.  We have formalized Wysteria, its
  refinement type system, and its operational semantics. We
  show that Wysteria programs have an easy-to-understand
  single-threaded interpretation and prove that this view corresponds
  to the actual multi-threaded semantics. We also prove type
  soundness, a property we show has security ramifications, namely
  that information about one party's data can only be revealed to
  another via (agreed upon) secure computations. We have implemented
  Wysteria, and used it to program a variety of interesting SMC
  protocols from the literature, as well as several new ones. We find
  that Wysteria's performance
  is competitive with prior approaches while making
  programming far easier, and more trustworthy.
  },
  category = {Security},
  month = may,
  year = 2014,
  url = {http://www.cs.umd.edu/~mwh/papers/wysteria.pdf},
}

@misc{khoo13expositor-journal,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks},
  title = {Expositor: Scriptable Time-Travel Debugging with First Class Traces (Full version)},
  abstract = {
  We present Expositor, a new debugging environment that combines
  scripting and time-travel debugging to allow programmers to automate
  complex debugging tasks. The fundamental abstraction provided by
  Expositor is the \emph{execution trace}, which is a time-indexed
  sequence of program state snapshots or projections thereof.
  Programmers can manipulate traces as if they were simple
  lists with operations such as map and filter. Under the hood,
  Expositor efficiently implements traces as lazy, sparse
  interval trees whose contents are materialized on demand.
  Expositor also provides a novel data
  structure, the \emph{edit hash array mapped trie}, which is a lazy
  implementation of sets, maps, multisets, and multimaps that enables
  programmers to maximize the efficiency of their debugging scripts.
  In our micro-benchmarks, Expositor scripts are faster than
  the equivalent non-lazy scripts for common debugging scenarios.  We have also used
  Expositor to debug a stack overflow, and to unravel a subtle
  data race in Firefox. We believe that
  Expositor represents an important step forward in improving the
  technology for diagnosing complex, hard-to-understand bugs.
},
  note = {Extended version of ICSE'13 paper},
  month = dec,
  year = 2013,
  url = {http://www.cs.umd.edu/~mwh/papers/expositor-tse-submitted.pdf},
  category = {Miscellaneous},
}

@inproceedings{mardziel13belief,
  author = {Piotr Mardziel and Michael Hicks and Jonathan Katz and Matthew Hammer and Aseem Rastogi and Mudhakar Srivatsa},
  title = {Knowledge inference for optimizing and enforcing secure computations},
  booktitle = inproc # {Annual Meeting of the US/UK International Technology Alliance},
  abstract = {
We present several techniques that aim to compute
the belief or knowledge a party might have about the values of hidden variables involved in the computation. These techniques can be used for enforcing knowledge-based security policies and for optimizing secure multiparty computations.},
  note = {This short paper consists of coherent excerpts from several prior papers},
  year = 2013,
  month = sep,
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/knowledge-overview.pdf}
}

@inproceedings{miller14gpads,
  author = {Andrew Miller and Michael Hicks and Jonathan Katz and Elaine Shi},
  title = {Authenticated Data Structures, Generically},
  booktitle = inproc # popl,
  abstract = {
  An authenticated data structure (ADS) is a data structure whose
  operations can be carried out by an untrusted \emph{prover}, the
  results of which a \emph{verifier} can efficiently check as
  authentic. This is done by having the prover produce a compact proof
  that the verifier can check along with each operation's result.  ADSs thus
  support outsourcing data maintenance and processing tasks to
  untrusted servers without loss of integrity. Past work on ADSs has
  focused on particular data structures (or limited classes of data
  structures), one at a time, often with support only for particular
  operations.

This paper presents a generic method, using a simple
  extension to a ML-like functional programming language we call LambdaAuth,
  with which one can program authenticated operations
  over any data structure defined by standard type constructors,
  including recursive types, sums, and products. The programmer writes
  the data structure largely as usual and it is compiled to code
  to be run by the prover and verifier. Using a formalization of LambdaAuth
  we prove that all well-typed LambdaAuth programs result in code that is
  secure under the standard cryptographic assumption of
  collision-resistant hash functions. We have implemented LambdaAuth
  as an extension to the OCaml compiler, and have used it to produce
  authenticated versions of many interesting data structures including
  binary search trees, red-black+ trees, skip lists, and
  more. Performance experiments show that our approach is efficient,
  giving up little compared to the hand-optimized data structures
  developed previously.
  },
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/gpads.pdf},
  month = jan,
  year = 2014
}

@inproceedings{hammer13adapton,
  author = {Matthew Hammer and Yit Phang Khoo and Michael Hicks and Jeffrey S. Foster},
  booktitle = inproc # pldi,
  title = {Adapton: Composable, Demand-Driven Incremental Computation},
  abstract = {
  Many researchers have proposed programming languages that
  support \emph{incremental computation} (IC), which allows programs
  to be efficiently re-executed after a small change to the
  input. However, existing implementations of such languages have two
  important drawbacks. First, recomputation is oblivious to
  specific demands on the program output; that is, if a program input
  changes, all dependencies will be recomputed, even if an observer no
  longer requires certain outputs. Second, programs are made
  incremental as a unit, with little or no support for reusing
  results outside of their original context, e.g., when reordered.

  To address these problems, we present $λ^{CDD}_{IC}$, a core calculus that
  applies a \emph{demand-driven} semantics to incremental computation,
  tracking changes in a hierarchical fashion in a novel \emph{demanded
    computation graph}. $λ^{CDD}_{IC}$ also formalizes an explicit separation
  between inner, incremental computations and outer observers. This
  combination ensures $λ^{CDD}_{IC}$ programs only recompute computations as
  demanded by observers, and allows inner computations to be reused
  more liberally. We present Adapton, an OCaml library implementing
  $λ^{CDD}_{IC}$. We evaluated Adapton on a range of benchmarks, and found
  that it provides reliable speedups, and in many cases dramatically
  outperforms state-of-the-art IC approaches.
  },
  category = {Miscellaneous},
  month = jun,
  url = {http://www.cs.umd.edu/~mwh/papers/adapton-submit.pdf},
  year = 2014
}

@techreport{hammer13adaptontr,
  author = {Matthew Hammer and Yit Phang Khoo and Michael Hicks and Jeffrey S. Foster},
  title = {Adapton: Composable, Demand-Driven Incremental Computation},
  abstract = {
  Many researchers have proposed programming languages that
  support \emph{incremental computation} (IC), which allows programs
  to be efficiently re-executed after a small change to the
  input. However, existing implementations of such languages have two
  important drawbacks. First, recomputation is oblivious to
  specific demands on the program output; that is, if a program input
  changes, all dependencies will be recomputed, even if an observer no
  longer requires certain outputs. Second, programs are made
  incremental as a unit, with little or no support for reusing
  results outside of their original context, e.g., when reordered.
  To address these problems, we present lambdaCDDIC, a core calculus that applies
  a \emph{demand-driven} semantics to incremental computation,
  tracking changes in a hierarchical fashion in a novel \emph{demanded
    computation graph}. lambdaCDDIC also formalizes an explicit
  separation between inner, incremental computations and outer
  observers. This combination ensures lambdaCDDIC programs only recompute
  computations as demanded by observers, and allows inner computations
  to be composed more freely. We describe an algorithm for implementing
  lambdaCDDIC efficiently, and we present AdaptOn, a library for writing
  lambdaCDDIC-style programs in OCaml. We evaluated AdaptOn on a range of
  benchmarks, and found that it provides reliable speedups, and in
  many cases dramatically outperforms prior state-of-the-art IC approaches.
  },
  institution = {Department of Computer Science, the University of Maryland, College Park},
  url = {http://drum.lib.umd.edu/bitstream/1903/14708/1/CS-TR-5027.pdf},
  number = {CS-TR-5027},
  month = jul,
  category = {Miscellaneous},
  year = 2013
}

@inproceedings{pina13rubah,
title = {Rubah: Efficient, General-purpose Dynamic Software Updating for {Java}},
author = {Luis Pina and Michael Hicks},
booktitle = inproc # hotswup,
abstract = {
  This paper presents Rubah, a new dynamic software updating (DSU)
  system for Java programs that works on stock VMs.  Rubah supports a
  large range of program changes (e.g., changes to the class hierarchy
  and updates to running methods), does not restrict important
  programming idioms (e.g., reflection), and, as shown by performance
  experiments using an updatable version of the H2 database management
  system, imposes low overhead on normal execution.
},
month = jun,
year = 2013,
category = {Dynamic_Software_Updating},
url = {http://www.cs.umd.edu/~mwh/papers/rubah.pdf}
}

@inproceedings{pina14rubah,
title = {Rubah: {DSU} for Java on a stock {JVM}},
author = {Lu\'is Pina and Lu\'is Veiga and Michael Hicks},
booktitle = inproc # oopsla,
abstract = {
  This paper presents Rubah, the first \emph{dynamic software
    updating} system for Java that: is portable, implemented via
  libraries and bytecode rewriting on top of a standard JVM; is
  efficient, imposing essentially no overhead on normal, steady-state execution; is
  flexible, allowing nearly arbitrary changes to classes between updates; and
  is non-disruptive, employing either a novel \emph{eager} algorithm
  that transforms the program state with multiple threads, or a novel
  \emph{lazy} algorithm that transforms objects as they are demanded,
  post-update. Requiring little programmer effort, Rubah has been used
  to dynamically update five
  long-running applications: the H2 database, the
  Voldemort key-value store, the Jake2 implementation of the Quake
  2 shooter game, the CrossFTP server, and the JavaEmailServer.
},
month = oct,
year = 2014,
category = {Dynamic_Software_Updating},
url = {http://www.cs.umd.edu/~mwh/papers/rubah-oopsla14.pdf},
}

@article{saur15strider,
author = {Karla Saur and Michael Hicks and Jeffrey S. Foster},
title = {C-Strider: Type-Aware Heap Traversal for {C}},
journal = spe,
abstract = {
  Researchers have proposed many tools and techniques that work by
  traversing the heap, including checkpointing systems, heap
  profilers, heap assertion checkers, and dynamic software updating
  systems. Yet building a heap traversal for C remains difficult, and
  to our knowledge extant services have used their own application-specific
  traversals.  This paper presents C-strider, a framework for
  writing C heap traversals and transformations.  Writing a basic C-strider
  service requires implementing only four callbacks; C-strider then
  generates a program-specific traversal that invokes the callbacks as
  each heap location is visited.  Critically, C-strider is \emph{type aware}---it
  tracks types as it walks the heap, so every callback is supplied
  with the exact type of the associated location. We used C-strider to
  implement heap serialization, dynamic software
  updating, heap checking, and profiling,
  and then applied the resulting traversals to several
  programs.  We found C-strider requires little programmer
  effort, and the resulting services are efficient and effective.
},
month = may,
year = 2015,
issn = {1097-024X},
url = {http://dx.doi.org/10.1002/spe.2332},
doi = {10.1002/spe.2332},
opturl = {http://www.cs.umd.edu/~mwh/papers/cstrider.pdf}
}

@misc{rastogi13m3pc,
  title = {A Core Calculus for Mixed-Mode Secure Multiparty Computation},
  author = {Aseem Rastogi and Matthew A. Hammer and Michael Hicks},
  abstract = {
  In a Secure Multi-party Computation (SMC), mutually-dis\-trust\-ing
  parties cooperate to compute over their private data; parties only
  learn information that is explicitly revealed as per the agreed
  protocol.  Standard implementations of SMC, e.g., using \emph{garbled
  circuits}, can be very slow, so researchers have begun to explore
  what we call \emph{mixed-mode} secure computations that combine
  standard SMCs with local computations, resulting in orders of
  magnitude speedups. Ultimately, we would like to produce a compiler
  that takes ``ordinary code'' and compiles it into mixed-mode
  SMC\@. As a step in this direction, this paper presents a core
  calculus that aims to capture the essence of mixed-mode SMCs, and
  their compilation to realizable protocols. Our approach builds on
  Levy's call-by-push-value calculus, and permits one to specify where
  a computation occurs, which computations are done locally versus
  securely, and also which state is carried over from one secure
  computation to another.  We show that a well-typed program in core
  calculus is sound (it does not get stuck), compiles properly to a target
  protocol, and that the operational semantics of the source program
  corresponds to the operational semantics of the target protocol.  We
  show that our framework is elegant, expressive, and practical by
  showing how it elucidates several recently published optimized
  protocols, and that it naturally supports reasoning about even more
  general compositions of such protocols.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/m3pc-lang.pdf},
  year = 2013,
  month = mar,
  category = {Security},
  omitfromweb = {yes},
}

@inproceedings{liu13oblivious,
  title = {Memory Trace Oblivious Program Execution},
  author = {Chang Liu and Michael Hicks and Elaine Shi},
  booktitle = inproc # csf,
  abstract = {
  Cloud computing allows users to delegate data and computation to
  cloud service providers, at the cost of giving up physical control
  of their computing infrastructure.  An attacker (e.g., insider) with
  physical access to the computing platform can perform various
  physical attacks, including probing memory buses and cold-boot style
  attacks.  Previous work on secure (co-)processors provides hardware
  support for memory encryption and prevents direct leakage of
  sensitive data over the memory bus.  However, an adversary snooping
  on the bus can still infer sensitive information from the memory
  access traces.  Existing work on Oblivious RAM (ORAM) provides a
  solution for users to put all data in an ORAM; and accesses to an
  ORAM are obfuscated such that no information leaks through memory
  access traces.  This method, however, incurs significant memory
  access overhead.

  In this work, we are among the first to leverage programming
  language techniques to offer efficient memory-trace oblivious
  program execution, while providing formal security guarantees.  We
  formally define the notion of memory-trace obliviousness, and
  provide a type system for verifying that a program satisfies this
  property.  We also describe a compiler that transforms a program
  into a structurally similar one that satisfies memory trace
  obliviousness.  To achieve optimal efficiency, our compiler
  partitions variables into several small ORAM banks rather than one
  large one, without risking security.  We use several example
  programs to demonstrate the efficiency gains our compiler achieves
  in comparison with the naive method of placing all variables in the
  same ORAM.
  },
  month = jun,
  year = 2013,
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/csf2013oram.pdf},
  note = {Winner of the 2014 NSA \textbf{Best Scientific Cybersecurity Paper} competition}
}

@inproceedings{rastogi13knowledge,
  author = {Aseem Rastogi and Piotr Mardziel and Matthew Hammer and Michael Hicks},
  title = {Knowledge Inference for Optimizing Secure Multi-party Computation},
  booktitle = inproc # plas,
  abstract = {
In secure multi-party computation, mutually distrusting parties
cooperatively compute functions of their private data; in the process,
they only learn certain results as per the protocol (e.g., the final
output).
The realization of these protocols uses cryptographic techniques to
avoid leaking information between the parties.
A protocol for a secure computation can sometimes be optimized without
changing its security guarantee:
when the parties can use their private data and the revealed output to
infer the values of other data, then this other data need not be
concealed from them via cryptography.

In the context of automatically optimizing secure multi-party
computation, we define two related problems, \emph{knowledge
  inference} and \emph{constructive knowledge inference}.
In both problems, we attempt to automatically discover when and if
intermediate variables used in a protocol will (eventually) be known
to the parties involved in the computation.
Provably-known variables offer optimization opportunities.

We formally state the problem of knowledge inference (and its
constructive variant); we describe our solutions, which are built atop
existing, standard technology such as SMT solvers.
We show that our approach is sound, and further, we
characterize the completeness properties enjoyed by our approach.
We have implemented our approach, and present a preliminary experimental evaluation.
},
 month = jun,
  year = 2013,
  url = {http://www.cs.umd.edu/~mwh/papers/smc-knowledge.pdf},
  category = {Security},
}

@inproceedings{khoo13expositor,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks},
  title = {Expositor: Scriptable Time-Travel Debugging with First Class Traces},
  booktitle = inproc # icse,
  abstract = {
  We present \textsc{Expositor}, a new debugging environment that combines
  scripting and time-travel debugging to allow programmers to automate
  complex debugging tasks. The fundamental abstraction provided by
  \textsc{Expositor} is the execution \emph{trace}, which is a time-indexed
  sequence of program state snapshots. Programmers can manipulate traces as if they were simple
  lists with operations such as map and filter. Under the hood,
  \textsc{Expositor} efficiently implements traces as lazy, sparse
  interval trees whose contents are materialized on demand.
  \textsc{Expositor} also provides a novel data
  structure, the \emph{edit hash array mapped trie}, which is a lazy
  implementation of sets, maps, multisets, and multimaps that enables
  programmers to maximize the efficiency of their debugging scripts.  We have used
  \textsc{Expositor} to debug a stack overflow and to unravel a subtle
  data race in Firefox. We believe that
  \textsc{Expositor} represents an important step forward in improving the
  technology for diagnosing complex, hard-to-understand bugs.
},
  month = may,
  year = 2013,
  category = {Miscellaneous},
  url = {http://www.cs.umd.edu/~mwh/papers/icse13main-p326-p-15890-preprint.pdf}
}

@techreport{hicks12polymonadTR,
  title = {Polymonads},
  author = {Nataliya Guts and Michael Hicks and Nikhil Swamy and Daan Leijen and Gavin Bierman},
  note = {Extended version of POPL'13 submission},
  url = {http://www.cs.umd.edu/~mwh/papers/polymonadsTR.pdf},
  institution = {University of Maryland Department of Computer Science},
  abstract = {
  From their semantic origins to their use in structuring effectful
  computations, monads are now also used as a programming pattern to
  structure code in a number of important scenarios, including
  functional reactivity, information flow tracking and probabilistic
  computation. However, whilst these examples are inspired by monads
  they are not strictly speaking monadic but rather something more
  general. The first contribution of this paper is the definition of a
  new structure, the polymonad, which subsumes monads and encompasses
  the monad-like programming patterns that we have observed.  A
  concern is that given such a general setting, a program would
  quickly become polluted with polymonadic coercions, making it hard
  to read and maintain.  The second contribution of this paper is to
  build on previous work to define a polymorphic type inference
  algorithm that supports programming with polymonads using a direct
  style, e.g., as if computations of type $M\, \tau$ were expressions
  of type $\tau$.  During type inference the program is rewritten to
  insert the necessary polymonadic coercions, a process that we prove
  is coherent---all sound rewritings produce programs with the same
  semantics.  The resulting programming style is powerful and
  lightweight.
  },
  number = {XXX},
  month = jul,
  year = 2012
}

@inproceedings{hicks14polymonad,
  title = {Polymonadic Programming},
  author = {Michael Hicks and Gavin Bierman and Nataliya Guts and Daan Leijen and Nikhil Swamy},
  booktitle = inproc # {Fifth Workshop on Mathematically Structured Functional Programming (MSFP)},
  url = {http://arxiv.org/pdf/1406.2060v1.pdf},
  url = {http://www.cs.umd.edu/~mwh/polymonads-impl.tgz},
  abstract = {
  Monads are a popular tool for the working functional programmer to
  structure effectful computations. This paper presents
  \emph{polymonads}, a generalization of monads. Polymonads give the
  familiar monadic bind the more general type
  $\forall a,b.\, L\; a \rightarrow (a \rightarrow M\; b) \rightarrow N\; b$, to
  compose computations with three different kinds of effects, rather
  than just one. Polymonads subsume monads and parameterized monads,
  and can express other constructions, including precise
  type-and-effect systems and information flow tracking; more
  generally, polymonads correspond to Tate's \emph{productoid}
  semantic model. We show how to equip a core language (called $\lambda_{PM}$)
  with syntactic support for programming with polymonads. Type
  inference and elaboration in $\lambda_{PM}$ allows programmers to write
  polymonadic code directly in an ML-like syntax---our algorithms
  compute principal types and produce elaborated programs wherein
  the binds appear explicitly. Furthermore, we prove that the
  elaboration is \emph{coherent}: no matter which (type-correct) binds
  are chosen, the elaborated program's semantics will be the
  same. Pleasingly, the inferred types are easy to read: the polymonad
  laws justify (sometimes dramatic) simplifications, but with no
  effect on a type's generality.

\href{http://www.cs.umd.edu/~mwh/polymonads-impl.tgz}{A prototype implementation of $\lambda_{PM}$} is available.
  },
  month = apr,
  year = 2014,
  category = {Static_Analysis},
}

@inproceedings{srivatsa12mobility,
  author = {Mudhakar Srivatsa and Michael Hicks},
  title = {Deanonymizing Mobility Traces: Using a Social Network as a Side-Channel},
  booktitle = inproc # ccs,
  abstract = {
  Location-based services, which employ data from
  smartphones, vehicles, etc., are growing in popularity.
  To reduce the threat that shared location data poses to a user's
  privacy, some services anonymize or obfuscate this data.
  In this paper, we show these methods can be effectively defeated: a
  set of location traces can be deanonymized given an easily
  obtained social network graph.
  The key idea of our approach is that a user may be identified by those she
  meets: a \emph{contact graph} identifying meetings between
  anonymized users in a set of traces can be structurally correlated
  with a social network graph, thereby identifying anonymized
  users. We demonstrate the effectiveness of our approach using three
  real world datasets: University of St Andrews mobility trace and
  social network (27 nodes each), SmallBlue contact trace and Facebook
  social network (125 nodes), and Infocom 2006 bluetooth contact
  traces and conference attendees' DBLP social network (78 nodes). Our
  experiments show that 80\% of users are identified
  precisely, while only 8\% are identified incorrectly, with the
  remainder mapped to a small set of users.
  },
  month = oct,
  year = 2012,
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/GraphInfoFlow.CCS2012.pdf}
}

@article{hicks12popl,
  title = {{POPL}'12 Program Chair's Report (or, how to run a medium-sized conference)},
  author = {Michael Hicks},
  journal = {SIGPLAN Notices},
  volume = 47,
  number = 4,
  abstract = {
It was a pleasure and a privilege to serve as the program committee
(PC) chair of the 39th Symposium on the Principles of Programming
Languages (POPL).  This paper describes the review process we used,
why we used it, and an assessment of how it worked out.

We made some substantial changes to the review process this year, most
notably by incorporating a form of double-blind reviewing.  These and
other changes were made in an attempt to improve accepted paper
quality, as well as to improve review quality and fairness (both of which
ultimately support paper quality).

Much of this paper argues in favor of these changes based on
principle, i.e., why one might think the process should increase
quality.  Ideally we could also evaluate the process directly, i.e.,
by showing that this year's program was better than it would have been
under a different review process.  Unfortunately, I think it would be
very difficult to efficiently evaluate a review process directly
(e.g., by having two committees and two review processes on the same
papers).  As such, I exercised a more tractable alternative: I polled
the authors and reviewers to report on their experience, and to see
whether that experience convinces them that the process has merit.  In
most cases, the answer was ``yes.''
},
  year = 2012,
  month = apr,
  url = {http://www.cs.umd.edu/~mwh/papers/popl12recap.pdf}
}

@inproceedings{mardziel12smc,
  title = {Knowledge-Oriented Secure Multiparty Computation},
  author = {Piotr Mardziel and Michael Hicks and Jonathan Katz and Mudhakar Srivatsa},
  booktitle = inproc # plas,
  abstract = {
Protocols for \emph{secure multiparty computation} (SMC) allow a set
of mutually distrusting parties to compute a function~$f$ of their
private inputs while revealing nothing about their inputs beyond what
is implied by the result.  Depending on~$f$, however, the result
itself may reveal more information than parties are comfortable with.
Almost all previous work on SMC treats $f$ as given.  Left unanswered
is the question of how parties should decide whether it is ``safe''
for them to compute $f$ in the first place.

We propose here a way to apply \emph{belief tracking} to~SMC in order
to address exactly this question. In our approach, each participating
party is able to reason about the increase in knowledge that other
parties could gain as a result of computing $f$, and may choose not to
participate (or participate only partially) so as to restrict that
gain in knowledge.  We develop two techniques---the \emph{belief set}
method and the \emph{SMC belief tracking} method---prove them sound,
and discuss their precision/performance tradeoffs using a series of
experiments.
  },
  month = jun,
  year = 2012,
  category = {Security},
  url = {http://www.cs.umd.edu/~mwh/papers/belief-smc.pdf},
}

@article{hayden14kitsune-journal,
  title = {Efficient, General-purpose Dynamic Software Updating for C},
  author = {Christopher M. Hayden and Karla Saur and Edward K. Smith and Michael Hicks and Jeffrey S. Foster},
  journal = toplas,
  abstract = {
  Dynamic software updating (DSU) systems
  facilitate software updates to running programs,
  thereby permitting developers to add features and fix
  bugs without downtime.  This paper introduces Kitsune, a DSU
  system for C. Kitsune's design has three notable features.  First,
  Kitsune updates the whole program, rather than
  individual functions, using a mechanism that places no restrictions on data
  representations or allowed compiler optimizations.
  Second, Kitsune makes the
  important aspects of updating explicit in the program text, making
  the program's semantics easy to understand while minimizing programmer effort.
  Finally, the programmer can write simple specifications to
  direct Kitsune to generate code that traverses and transforms
  old-version state for use by new code; such state
  transformation is often necessary and is significantly more
  difficult in prior DSU systems.  We have used Kitsune
  to update six popular, open-source, single- and multi-threaded
  programs, and find that few program changes are required to use
  Kitsune, that it incurs essentially no performance overhead,
  and that update times are fast.},
  month = oct,
  year = 2014,
  volume = 36,
  number = 4,
  pages = 13,
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/kitsune-journal.pdf},
}


@inproceedings{hayden12kitsune,
  title = {Kitsune: Efficient, General-purpose Dynamic Software Updating for {C}},
  author = {Christopher M. Hayden and Edward K. Smith and Michail Denchev and Michael Hicks and Jeffrey S. Foster},
  booktitle = inproc # oopsla,
  abstract = {
  Dynamic software updating (DSU) systems allow programs to be updated
  while running, thereby permitting developers to add features and fix
  bugs without downtime.  This paper introduces Kitsune, a new DSU
  system for C whose design has three notable features.  First,
  Kitsune's updating mechanism updates the whole program, not
  individual functions.  This mechanism is more flexible than most
  prior approaches and places no restrictions on data representations
  or allowed compiler optimizations.  Second, Kitsune makes the
  important aspects of updating explicit in the program text, making
  the program's semantics easy to understand while minimizing programmer effort.  Finally, the programmer can write simple specifications to
  direct Kitsune to generate code that traverses and transforms
  old-version state for use by new code; such state
  transformation is often necessary, and is significantly more
  difficult in prior DSU systems.  We have used Kitsune
  to update five popular, open-source, single- and multi-threaded
  programs, and find that few program changes are required to use
  Kitsune, and that it incurs essentially no performance overhead.
  },
  month = oct,
  year = 2012,
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/kitsune.pdf}
}

@inproceedings{hayden12quiescence,
  title = {A Study of Dynamic Software Update Quiescence for Multithreaded Programs},
  author = {Christopher M. Hayden and Karla Saur and Michael Hicks and Jeffrey S. Foster},
  booktitle = inproc # hotswup,
  abstract = {
  Dynamic software updating (DSU) techniques show great promise in
  allowing vital software services to be upgraded without downtime,
  avoiding dropped connections and the loss of critical program state.
  For multithreaded programs, DSU systems must balance
  \emph{correctness} and \emph{timeliness}.  To simplify reasoning
  that an update is correct, we could limit updates to take place only
  when all threads have blocked at well-defined \emph{update
    points}.  However, several researchers have pointed out that this
  approach poses the risk of delaying an update for too long, even
  indefinitely, and therefore have developed fairly complicated
  mechanisms to mitigate the risk.  This paper argues that such
  mechanisms are unnecessary by demonstrating empirically that
  many multithreaded programs can be updated
  with minimal delay using only a small number of manually annotated
  update points.  Our study of the time taken for all of the
  threads in six real-world, event-driven programs to reach
  their update points ranged from 0.155 to 107.558 ms,
  and most were below 1 ms.
  },
  month = jun,
  pages = {6--10},
  year = 2012,
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/quiescence.pdf},
}

@inproceedings{smith12benchmark,
  title = {Towards Standardized Benchmarks for Dynamic Software Updating Systems},
  author = {Edward K. Smith and Michael Hicks and Jeffrey S. Foster},
  booktitle = inproc # hotswup,
  abstract = {
  Dynamic Software Updating (DSU) has been an active topic of research
  for at least the last 30 years. However, despite many recent
  advances, DSU has yet to see widespread adoption and deployment in
  practice. In this paper, we review a slice of the history of DSU
  research to study how DSU for C has evolved over the last two
  decades. We examine the ways DSU systems are
  evaluated in the research literature. We identify several
  shortcomings of the evaluation criteria that have been used, and
  propose key improvements. We believe that using better evaluation
  criteria can guide DSU research to produce systems that will
  be more practical, flexible, and usable.
  },
  month = jun,
  year = 2012,
  pages = {11--15},
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/dsubench.pdf},
}

@inproceedings{magill12tos,
  title = {Automating Object Transformations for Dynamic Software Updating},
  author = {Stephen Magill and Michael Hicks and Suriya Subramanian and Kathryn S. McKinley},
  booktitle = inproc # oopsla,
  abstract = {
  Dynamic software updating (DSU) systems eliminate costly downtime by
  dynamically fixing bugs and adding features to executing programs.
  Given a static \emph{code} patch, most DSU systems construct runtime
  code changes automatically.  However, a dynamic update must also
  specify how to change the running program's execution \emph{state},
  e.g., the stack and heap, to make it compatible with the new code.
  Constructing such \emph{state transformations} correctly and
  automatically remains an open problem.  This paper presents a
  solution called \emph{Targeted Object Synthesis} (TOS).  TOS first executes the same tests on
  the old and new program versions separately, observing the program
  heap state at a few corresponding points.  Given two corresponding
  heap states, TOS
  \emph{matches} objects in the two versions using \emph{key} fields
  that uniquely identify objects and correlate old and new-version
  objects. Given example object pairs, TOS then \emph{synthesizes} the simplest-possible
  function that transforms an old-version object to its new-version
  counterpart. We show
  that TOS  is effective on updates to four open-source server
  programs for which it generates non-trivial transformation functions that use conditionals,
  operate on collections, and fix memory leaks. These transformations help programmers
  understand their changes and apply dynamic software updates.
  },
  month = oct,
  year = 2012,
  url = {http://www.cs.umd.edu/~mwh/papers/tos.pdf},
  category = {Dynamic_Software_Updating},
}

@misc{mccann11nest,
  title = {The Network Stack Trace: Performance diagnosis for networked systems},
  author = {Justin McCann and Michael Hicks},
  abstract = {
Transient network stalls that degrade application performance are frustrating to
users and developers alike. Software bugs, network congestion, and intermittent
connectivity all have the same symptoms---low throughput, high latency, and
user-level timeouts. In this paper, we show how an end host can identify the
sources of network stalls using only simple counters from its local network stack.
By viewing the network stack as a producer-consumer dependency graph and
monitoring its activity as a whole, our rule-based expert system correctly
identifies which modules are hampering performance over 99\% of the time, with
false positive rates under 3\%.  The result is a network stack trace---a
lightweight snapshot of the end host's networking stack that describes the
behavior of each application, socket, connection, and interface.
  },
  month = oct,
  year = 2011,
  omitfromweb = {yes},
  url = {http://www.cs.umd.edu/~mwh/papers/nest.pdf}
}


@inproceedings{guts11coco,
  title = {A demo of {Coco}: a compiler for monadic coercions in {ML}},
  author = {Nataliya Guts and Michael Hicks and Nikhil Swamy and Daan Leijen},
  booktitle = {Informal proceedings of the {ML} Workshop},
  year = 2011,
  abstract = {
  Combining monadic computations may induce a significant syntactic overhead.
  To allow monadic programming in direct style, we have developed Coco, a type-based tool that automatically rewrites ML code inserting necessary binds, unit, and morphisms between monads.
 This tool demonstration will show how to take advantage of Coco to facilitate using monadic libraries in practice,
  and will discuss possible future development of Coco to fit the actual needs of programmers.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/coco-demo.pdf},
  http = {http://research.microsoft.com/en-us/projects/coco/},
  month = sep,
  category = {Static_Analysis}
}

@techreport{turpie11multiotter,
  title = {MultiOtter: Multiprocess Symbolic Execution},
  author = {Jonathan Turpie and Elnatan Reisner and Jeffrey S. Foster and Michael Hicks},
  number = {CS-TR-4982},
  institution = {University of Maryland Department of Computer Science},
  year = 2011,
  month = aug,
  abstract = {
  Symbolic execution can be an effective technique for exploring large numbers
  of program paths, but it has generally been applied to programs running in
  isolation, whose inputs are files or command-line arguments. Programs that
  take inputs from other programs---servers, for example---have been
  beyond the reach of symbolic execution. To address this, we developed a
  multiprocess symbolic
  executor called MultiOtter, along with an implementation of many of the POSIX functions, such as
  \texttt{socket} and \texttt{select}, that interactive programs usually rely on.
  However, that is just a first step. Next, we must determine what symbolic inputs
  to feed to an interactive program to make multiprocess symbolic execution effective.
  Providing completely unconstrained symbolic values causes symbolic execution
  to spend too much time exploring uninteresting paths, such as paths to handle
  invalid inputs. MultiOtter allows us to generate inputs that conform to a
  context-free grammar, similar to previous work, but it also enables new input
  generation capabilities because we can now run arbitrary programs concurrently
  with the program being studied. As examples, we symbolically executed a
  key-value store server, redis, and an FTP server, vsftpd, each with a variety
  of inputs, including symbolic versions of tests from redis's test suite
  and wget as a client for vsftpd. We report the coverage provided by symbolic
  execution with various forms of symbolic input, showing that different testing
  goals require different degrees of symbolic inputs.
  },
  category = {Static_Analysis},
  url = {http://www.cs.umd.edu/~mwh/papers/multiotter.pdf}
}

@techreport{ma11directedTR,
  title = {Directed Symbolic Execution},
  author = {Kin-Keung Ma and Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks},
  abstract = {
In this paper, we study the problem of automatically finding program
executions that reach a particular target line. This problem arises
in many debugging scenarios; for example, a developer may want to confirm
that a bug reported by a static analysis tool on a particular line is
a true positive.
We propose two new \emph{directed}
symbolic execution strategies that aim to solve this problem:
\emph{shortest-distance symbolic execution (SDSE)} uses a distance metric in
an interprocedural control flow graph to guide symbolic execution toward a
particular target; and \emph{call-chain-backward symbolic execution (CCBSE)}
iteratively runs forward symbolic execution, starting in the function
containing the target line, and then jumping backward up the call chain
until it finds a feasible path from the start of the program.
We also propose a hybrid strategy, Mix-CCBSE, which alternates CCBSE with
another (forward) search strategy.  We compare these three with several
existing strategies from the literature on a suite of six GNU
coreutils programs.
We find that SDSE performs extremely well in many cases
but may fail badly. CCBSE also performs quite well, but imposes
additional overhead that sometimes makes it slower than SDSE.  Considering
all our benchmarks together, Mix-CCBSE performed best on average,
combining to good effect the features of its constituent components.
},
  month = apr,
  category = {Static_Analysis},
  year = 2011,
  number = {CS-TR-4979},
  institution = {University of Maryland Department of Computer Science},
  url = {http://www.cs.umd.edu/~mwh/papers/directedSE-TR.pdf},
  note = {Extended version contains refinements and further experimental analysis}
}

@inproceedings{ma11directed,
  title = {Directed Symbolic Execution},
  author = {Kin-Keung Ma and Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks},
  booktitle = inproc # sas,
  series = {Lecture Notes in Computer Science},
  volume = {6887},
  editor = {Eran Yahav},
  publisher = {Springer},
  abstract = {
In this paper, we study the problem of automatically finding program
executions that reach a particular target line. This problem arises
in many debugging scenarios; for example, a developer may want to confirm
that a bug reported by a static analysis tool on a particular line is
a true positive.
We propose two new \emph{directed}
symbolic execution strategies that aim to solve this problem:
\emph{shortest-distance symbolic execution (SDSE)} uses a distance metric in
an interprocedural control flow graph to guide symbolic execution toward a
particular target; and \emph{call-chain-backward symbolic execution (CCBSE)}
iteratively runs forward symbolic execution, starting in the function
containing the target line, and then jumping backward up the call chain
until it finds a feasible path from the start of the program.
We also propose a hybrid strategy, Mix-CCBSE, which alternates CCBSE with
another (forward) search strategy.  We compare these three with several
existing strategies from the literature on a suite of six GNU
coreutils programs.
We find that SDSE performs extremely well in many cases
but may fail badly. CCBSE also performs quite well, but imposes
additional overhead that sometimes makes it slower than SDSE.  Considering
all our benchmarks together, Mix-CCBSE performed best on average,
combining to good effect the features of its constituent components.
},
  category = {Static_Analysis},
  url = {http://www.cs.umd.edu/~mwh/papers/dse-sas11.pdf},
  pages = {95--111},
  year = 2011,
  month = sep,
}


@inproceedings{swamy11monad,
  title = {Lightweight Monadic Programming in {ML}},
  author = {Nikhil Swamy and Nataliya Guts and Daan Leijen and Michael Hicks},
  booktitle = inproc # icfp,
  abstract = {
  Many useful programming constructions can be expressed as monads.
  Examples include probabilistic modeling,
  functional reactive programming, parsing, and information flow tracking,
  not to mention effectful functionality like state and I/O.  In this
  paper, we present a type-based rewriting algorithm to make
  programming with arbitrary monads as easy as using ML's built-in
  support for state and I/O.  Developers write programs using monadic
  values of type $M~t$ as if they were of type $t$, and our algorithm
  inserts the necessary binds, units, and monad-to-monad morphisms so
  that the program type checks.  Our algorithm, based on Jones'
  qualified types, produces principal types.  But principal
  types are sometimes
  problematic: the program's semantics could depend on the choice of
  instantiation when more than one instantiation is valid.  In such
  situations we are able to simplify the types to remove
  any ambiguity but without adversely affecting typability; thus we can
  accept strictly more programs.  Moreover, we have proved that this
  simplification is \emph{efficient} (linear in the number of constraints)
  and \emph{coherent}: while our algorithm induces a particular rewriting,
  all related rewritings will have the same semantics.
  We have implemented our approach for a core functional
  language and applied it successfully to simple examples from the
  domains listed above, which are used as illustrations throughout the
  paper.
  },
  category = {Static_Analysis},
  year = 2011,
  month = sep,
  pages = {15--27},
  http = {http://research.microsoft.com/en-us/projects/coco/},
  url = {http://www.cs.umd.edu/~mwh/papers/monadic.pdf}
}

@techreport{swamy11monadTR,
  title = {Lightweight Monadic Programming in {ML}},
  author = {Nikhil Swamy and Nataliya Guts and Daan Leijen and Michael Hicks},
  number = {MSR-TR-2011-039},
  institution = {Microsoft Research},
  abstract = {
  Many useful programming constructions can be expressed as monads.
  Examples include probabilistic computations,
  time-varying expressions, parsers, and information flow tracking,
  not to mention effectful features like state and I/O.  In this
  paper, we present a type-based rewriting algorithm to make
  programming with arbitrary monads as easy as using ML's built-in
  support for state and I/O.  Developers write programs using monadic
  values of type $M~t$ as if they were of type $t$, and our algorithm
  inserts the necessary binds, units, and monad-to-monad morphisms so
  that the program typechecks.  Our algorithm is based on Jones'
  qualified types and enjoys three useful properties: (1) principal
  types, i.e., the rewriting we perform is the most general; (2)
  coherence, i.e., thanks to the monad and morphism laws, all
  instances of the principal rewriting have the same semantics; (3)
  decidability; i.e., the solver for generated constraints will always
  terminate.  Throughout the paper we present simple examples from the
  domains listed above.  Our most complete example, which illustrates
  the expressive power of our system, proves that ML programs
  rewritten by our algorithm to use the information flow monad are
  equivalent to programs in FlowCaml, a domain-specific information
  flow tracking language.
  },
  category = {Static_Analysis},
  year = 2011,
  month = may,
  http = {http://research.microsoft.com/en-us/projects/coco/},
  url = {http://research.microsoft.com/pubs/147003/monadic.pdf}
}

@techreport{mardziel11beliefTR,
  title = {Dynamic Enforcement of Knowledge-based Security Policies},
  author = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  number = {CS-TR-4978},
  institution = {University of Maryland Department of Computer Science},
  abstract = {
  This paper explores the idea of \emph{knowledge-based security
    policies}, which are used to decide whether to answer queries over
  secret data based on an estimation of the querier's (possibly
  increased) knowledge given the results.  Limiting knowledge is the
  goal of existing information release policies that employ mechanisms
  such as noising, anonymization, and redaction.  Knowledge-based
  policies are more general: they increase flexibility by not fixing
  the means to restrict information flow.  We enforce a
  knowledge-based policy by explicitly tracking a model of a querier's
  belief about secret data, represented as a probability distribution,
  and denying any query that could increase knowledge above a given
  threshold.  We implement query analysis and belief tracking via
  abstract interpretation using a novel
  \emph{probabilistic polyhedral} domain, whose design permits trading off
  precision with performance while ensuring estimates of a querier's
  knowledge are sound.  Experiments with our implementation show that
  several useful queries can be handled efficiently, and performance
  scales far better than would more standard implementations of
  probabilistic computation based on sampling.
  },
  year = 2011,
  month = jul,
 note = "Extended version with proofs and additional benchmarks",
 category = {Security},
 url = {http://www.cs.umd.edu/~mwh/papers/beliefpolTR.pdf}
}

@article{mardziel13belieflong,
  title = {Dynamic Enforcement of Knowledge-based Security Policies using Probabilistic Abstract Interpretation},
  author = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  abstract = {
  This paper explores the idea of \emph{knowledge-based security
    policies}, which are used to decide whether to answer queries over
    secret data based on an estimation of the querier's (possibly
    increased) knowledge given the results.  Limiting knowledge is the
    goal of existing information release policies that employ
    mechanisms such as noising, anonymization, and redaction.
    Knowledge-based policies are more general: they increase
    flexibility by not fixing the means to restrict information flow.
    We enforce a knowledge-based policy by explicitly tracking a model
    of a querier's belief about secret data, represented as a
    probability distribution, and denying any query that could
    increase knowledge above a given threshold.  We implement query
    analysis and belief tracking via abstract interpretation, which allows us to
    trade off precision and performance through the use of
    abstraction. We have developed an approach to augment standard
    abstract domains to include probabilities, and thus define
    distributions.  We focus on developing \emph{probabilistic
      polyhedra} in particular, to support numeric programs. While
    probabilistic abstract interpretation has been
    considered before, our domain is the first whose design supports
    sound conditioning, which is required to ensure that estimates of
    a querier's knowledge are accurate. Experiments with our
    implementation show that several useful queries can be handled
    efficiently, particularly compared to exact (i.e., sound)
    inference involving sampling.  We also show that, for our
    benchmarks, restricting constraints to \emph{octagons}
    or \emph{intervals}, rather than full polyhedra, can dramatically
    improve performance while incurring little to no loss in
    precision.
  },
  year = 2013,
  month = oct,
  volume = 21,
  pages = {463--532},
  journal = {Journal of Computer Security},
 category = {Security},
 url = {http://www.cs.umd.edu/~mwh/papers/beliefpol-extended.pdf}
}

@inproceedings{mardziel11belief,
  title = {Dynamic Enforcement of Knowledge-based Security Policies},
  author = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  booktitle = inproc # csf,
  abstract = {
  This paper explores the idea of \emph{knowledge-based security
    policies}, which are used to decide whether to answer queries over
  secret data based on an estimation of the querier's (possibly
  increased) knowledge given the results.  Limiting knowledge is the
  goal of existing information release policies that employ mechanisms
  such as noising, anonymization, and redaction.  Knowledge-based
  policies are more general: they increase flexibility by not fixing
  the means to restrict information flow.  We enforce a
  knowledge-based policy by explicitly tracking a model of a querier's
  belief about secret data, represented as a probability distribution,
  and denying any query that could increase knowledge above a given
  threshold.  We implement query analysis and belief tracking via
  abstract interpretation using a novel
  \emph{probabilistic polyhedral} domain, whose design permits trading off
  precision with performance while ensuring estimates of a querier's
  knowledge are sound.  Experiments with our implementation show that
  several useful queries can be handled efficiently, and performance
  scales far better than would more standard implementations of
  probabilistic computation based on sampling.
  },
  category = {Security},
  year = 2011,
  month = jun,
  pages = {114--128},
  url = {http://www.cs.umd.edu/~mwh/papers/beliefpol.pdf}
}

@techreport{hayden11dsucorrectTR,
  title = {Specifying and Verifying the Correctness of Dynamic Software Updates},
  author = {Christopher M. Hayden and Stephen Magill and Michael Hicks and Nate Foster and Jeffrey S. Foster},
 institution = {University of Maryland Department of Computer Science},
 abstract = {
Dynamic software updating (DSU) systems allow running programs to be patched on-the-fly to add features or fix bugs. While dynamic updates can be tricky to write, techniques for establishing their correctness have received little attention. In this paper, we present the first methodology for automatically verifying the correctness of dynamic updates. Programmers express the desired properties of an updated execution using client-oriented specifications (CO-specs), which can describe a wide range of client-visible behaviors. We verify CO-specs automatically by using off-the-shelf tools to analyze a merged program, which is a combination of the old and new versions of a program. We formalize the merging transformation and prove it correct. We have implemented a program merger for C, and applied it to updates for the Redis key-value store and several synthetic programs. Using Thor, a verification tool, we could verify many of the synthetic programs; using Otter, a symbolic executor, we could analyze every program, often in less than a minute. Both tools were able to detect faulty patches and incurred only a factor-of-four slowdown, on average, compared to single version programs.},
 number = {CS-TR-4997},
  year = 2011,
  month = nov,
  url = {http://www.cs.umd.edu/~mwh/papers/dsucorrectnessTR.pdf},
  note = {Extended version of VSTTE'12 paper with proofs of theorems and additional discussion},
  category = {Dynamic_Software_Updating},
}

@inproceedings{hayden12dsucorrect,
  title = {Specifying and Verifying the Correctness of Dynamic Software Updates},
  author = {Christopher M. Hayden and Stephen Magill and Michael Hicks and Nate Foster and Jeffrey S. Foster},
  booktitle = inproc # {International Conference on Verified Software: Theories, Tools, and Experiments ({VSTTE})},
  abstract = {
  Dynamic software updating
  (DSU) systems allow running programs to be patched on-the-fly
  to add features or fix bugs.  While dynamic updates can be tricky
  to write, techniques for establishing their
  correctness have received little attention.
  In this paper, we present the first methodology for automatically
  verifying the correctness of dynamic updates.  Programmers express
  the desired properties of an updated execution using
  \emph{client-oriented specifications} (CO-specs), which can describe a
  wide range of client-visible behaviors.
  We verify CO-specs automatically by using off-the-shelf tools to
  analyze a \emph{merged} program, which is a combination of the old and new
  versions of a program, along with the CO-spec.
  We formalize the merging transformation and prove it correct.  We
  also implemented a C program merger, and applied it to updates
  for the Redis key-value server and to updates for several synthetic
  programs.  Using the Thor verification tool we could verify
  many of the synthetic programs, while Otter, a symbolic
  executor, could analyze every program, often in less than a minute.
  Both tools were able to detect faulty patches and incurred only a
  factor-of-four slowdown, on average, compared with analyzing individual
  versions.
  },
  year = 2012,
  month = jan,
  pages = {278--293},
  url = {http://drum.lib.umd.edu/bitstream/1903/12167/1/CS-TR-4997.pdf},
  category = {Dynamic_Software_Updating},
}

@inproceedings{hayden2011xfer,
  title = {State Transfer for Clear and Efficient Runtime Upgrades},
  author = {Christopher M. Hayden and Edward K. Smith and Michael
    Hicks and Jeffrey S. Foster},
  booktitle = inproc # hotswup,
  pages = {179--184},
  abstract = {
\begin{abstract}
Dynamic software updating (DSU), the practice of updating software while it
executes, is a lively area of research.  The DSU approach most
prominent in both commercial and research systems is \emph{in-place
  updating}, in which patches containing program modifications are
loaded into a running
process.  However, in-place updating suffers from several problems: it
requires complex tool support, it may adversely affect the performance of
normal execution, it requires challenging reasoning to understand the
behavior of an updated program, and it requires extra effort to modify
program state to be compatible with an update.

This paper presents preliminary work investigating the potential for \emph{state
transfer updating} to address these problems.  State transfer updates
work by launching a new process running the updated program version
and transferring program state from the running process to the updated
version.  In this paper, we describe the use and implementation of
Ekiden, a new state transfer updating library for C/C++ programs.
Ekiden seeks to redress the difficulties of in-place updating, and we report
on our experience updating vsftpd using Ekiden.  This initial
experience suggests that state transfer provides the availability
benefits of in-place DSU approaches while addressing many of their
shortcomings.
  },
  category = {Dynamic_Software_Updating},
  month = apr,
  year = 2011,
  url = {http://www.cs.umd.edu/~mwh/papers/dsuxfer.pdf},
}

@inproceedings{an2011position,
  title = {Position Paper: Dynamically Inferred Types for Dynamic Languages},
  author = {Jong-hoon (David) An and Avik Chaudhuri and
    Jeffrey S. Foster and Michael Hicks},
  booktitle = inproc # stop,
  abstract = {
    Capsule summary of results and future directions of dynamic type inference, as proposed in our \href{http://www.cs.umd.edu/~mwh/papers/an10rubydust.html}{POPL 2011 paper}.
  },
  month = jan,
  year = 2011,
  category = {Static_Analysis},
}

@inproceedings{mardziel10acita,
  title = {Secure sharing in distributed information management applications: problems and directions},
  author = {Piotr Mardziel and Adam Bender and Michael Hicks and Dave Levin and Mudhakar Srivatsa and Jonathan Katz},
  booktitle = inproc # {Annual Conference of the International Technology Alliance (ACITA)},
  abstract = {
Interaction between entities who may not trust each other is now
commonplace on the Internet.
This paper focuses on the specific problem of sharing information
between distrusting parties.
Previous work in this area shows that \textit{privacy} and \textit{utility}
can co-exist, but often do not provide strong assurances of one or the other.
In this paper, we sketch a research agenda with several directions for
attacking these problems, considering several alternative systems that
examine the privacy vs. utility problem from different angles.
We consider new mechanisms such as economic incentives to share data
or discourage
data leakage and a hybrid of code-splitting and secure multi-party
computation to provide various assurances of secrecy.
We discuss how to incorporate these mechanisms into practical applications,
including online social networks, a recommendation system based on users'
qualifications rather than identities, and a \emph{personal information
broker} that monitors data leakage over time.
  },
  month = sep,
  year = 2010,
  url = {http://www.cs.umd.edu/~mwh/papers/secure-sharing.pdf},
  category = {Security},
}

@techreport{an10rubydustTR,
 author = {Jong-hoon (David) An and Avik Chaudhuri and Jeffrey S. Foster and Michael Hicks},
 title = {Dynamic Inference of Static Types for Ruby},
 institution = {University of Maryland Department of Computer Science},
 number = {CS-TR-4965},
 abstract = {
  There have been several efforts to bring static type
  inference to object-oriented dynamic languages such as Ruby, Python,
  and Perl.  In our experience, however, such type inference systems
  are extremely difficult to develop, because dynamic languages are
  typically complex, poorly specified, and include
  features, such as \texttt{eval} and reflection, that are hard to
  analyze.  In this paper, we introduce
  \emph{constraint-based dynamic type inference}, a technique that
  infers static types based on dynamic program executions.  In our approach,
  we wrap each run-time value to associate it with a type variable,
  and the wrapper generates constraints on this type variable when
  the wrapped value is used.  This technique avoids many of the often
  overly conservative approximations of static tools,
  as constraints
  are generated based on how values are used during actual program runs.
  Using wrappers is also easy to implement, since we need only
  write a constraint resolution algorithm and a transformation to
  introduce the wrappers.
  The best part is that we can eat our
  cake, too: our algorithm will infer \emph{sound} types as long as it
  observes every
  path through each method body---note that the number of such paths
  may be dramatically smaller than the number of paths through the
  program as a whole.  We have developed Rubydust, an implementation of
  our algorithm for Ruby.  Rubydust takes advantage of Ruby's dynamic
  features to implement wrappers as a language library.  We applied
  Rubydust to a number of small programs.  We found it to be
  lightweight and useful: Rubydust discovered 1 real type error,
  and all other inferred types were correct, and readable.
 },
 month = jul,
 url = {http://www.lib.umd.edu/drum/bitstream/1903/10599/1/CS-TR-4965.pdf},
 year = 2010,
 note = "Extended version contains proofs of theorems",
 category = {Static_Analysis},
}

@inproceedings{an11rubydust,
 author = {Jong-hoon (David) An and Avik Chaudhuri and Jeffrey S. Foster and Michael Hicks},
 title = {Dynamic Inference of Static Types for Ruby},
 booktitle = inproc # popl,
 abstract = {
  There have been several efforts to bring static type
  inference to object-oriented dynamic languages such as Ruby, Python,
  and Perl.  In our experience, however, such type inference systems
  are extremely difficult to develop, because dynamic languages are
  typically complex, poorly specified, and include
  features, such as \texttt{eval} and reflection, that are hard to
  analyze.

In this paper, we introduce
  \emph{constraint-based dynamic type inference}, a technique that
  infers static types based on dynamic program executions.  In our approach,
  we wrap each run-time value to associate it with a type variable,
  and the wrapper generates constraints on this type variable when
  the wrapped value is used.  This technique avoids many of the often
  overly conservative approximations of static tools,
  as constraints
  are generated based on how values are used during actual program runs.
  Using wrappers is also easy to implement, since we need only
  write a constraint resolution algorithm and a transformation to
  introduce the wrappers.
  The best part is that we can eat our
  cake, too: our algorithm will infer \emph{sound} types as long as it
  observes every
  path through each method body---note that the number of such paths
  may be dramatically smaller than the number of paths through the
  program as a whole.

We have developed Rubydust, an implementation of
  our algorithm for Ruby.  Rubydust takes advantage of Ruby's dynamic
  features to implement wrappers as a language library.  We applied
  Rubydust to a number of small programs and found it to be both easy
  to use and useful:
  Rubydust discovered 1 real type error,
  and all other inferred types were correct and
  readable.
 },
 month = jan,
 url = {http://www.cs.umd.edu/~mwh/papers/rubydust.pdf},
 year = 2011,
 pages = {459--472},
 category = {Static_Analysis},
}

@techreport{hayden11testing-TR,
  author = {Christopher M. Hayden and Edward K. Smith and Eric A. Hardisty and Michael Hicks and Jeffrey S. Foster},
  title = {Evaluating Dynamic Software Update Safety Using Efficient Systematic Testing},
  number = {CS-TR-4993},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  abstract = {
Dynamic software updating (DSU) systems patch programs on the fly without incurring downtime. To avoid failures due to the updating process itself, many DSU systems employ timing restrictions. However, timing restrictions are theoretically imperfect, and their practical effectiveness is an open question. This paper presents the first significant empirical evaluation of three popular timing restrictions: activeness safety (AS), which prevents updates to active functions; confreeness safety (CFS), which only allows modifications to active functions when doing so is provably type-safe; and manual identification of the event-handling loops during which an update may occur. We evaluated these timing restrictions using a series of DSU patches to three programs: OpenSSH, vsftpd, and ngIRCd.We systematically applied updates at each distinct update point reached during execution of a suite of system tests for these programs to determine which updates pass and which fail. We found that all three timing restrictions prevented most failures, but only manual identification allowed none. Further, although CFS and AS allowed many more update points, manual identification still supported updates with minimal delay. Finally, we found that manual identification required the least developer effort. Overall, we conclude that manual identification is most effective.
  },
  year = 2011,
  month = sep,
  url = {http://drum.lib.umd.edu//handle/1903/12146},
  category = {Dynamic_Software_Updating},
}

@article{hayden12testing-journal,
  author = {Christopher M. Hayden and Edward K. Smith and Eric A. Hardisty and Michael Hicks and Jeffrey S. Foster},
  title = {Evaluating Dynamic Software Update Safety Using Efficient Systematic Testing},
  journal = {IEEE Transactions on Software Engineering},
  abstract = {
  Dynamic software updating (DSU) systems patch programs
  on the fly without incurring downtime.
  To avoid failures due to the updating process itself,
  many DSU systems employ \emph{timing restrictions}.
  However, timing restrictions are theoretically
  imperfect, and their practical effectiveness is an open question.

  This paper presents the first significant empirical evaluation of
  three popular timing restrictions: \emph{activeness safety} (AS),
  which prevents updates to active functions;
  \emph{con-freeness safety} (CFS), which only allows modifications to
  active functions when doing so is provably type-safe; and
  \emph{manual identification} of the event-handling loops during which an
  update may occur.

  We evaluated these timing restrictions using a series of DSU patches
  to three programs:
  Open\-SSH, vsftpd, and ngIRCd.  We systematically applied
  updates at each distinct update point reached during execution of
  a suite of system tests for these programs
  to determine which updates pass and which fail.
  We found that all
  three timing restrictions prevented most
  failures, but only manual identification allowed none.  Further,
   although CFS and AS allowed many
  more update points, manual identification
  still supported updates with minimal delay.  Finally,
  we found that manual identification required the least developer effort.
  Overall, we conclude that manual identification is most effective.
  },
  volume = {38},
  number = {6},
  pages = {1340--1354},
  year = 2012,
  month = dec,
  url = {http://www.cs.umd.edu/~mwh/papers/dsutesting-journal.pdf},
  note = {Accepted September 2011},
  doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.2011.101},
  category = {Dynamic_Software_Updating},
}

@inproceedings{hayden09testing,
  author = {Christopher M. Hayden and Eric A. Hardisty and Michael Hicks and Jeffrey S. Foster},
  title = {Efficient Systematic Testing for Dynamically Updatable Software},
  booktitle = inproc # hotswup,
  abstract = {
  Recent years have seen significant advances in dynamic software
  updating (DSU) systems, which allow programs to be patched
  on the fly.  However, a significant challenge remains: How can we
  ensure the act of applying a patch does not itself introduce errors?
  In this paper, we address this problem by presenting a new systematic
  testing methodology for updatable programs.
  Our idea is to transform standard
  system tests into \emph{update tests} that execute as before, but
  each transformed test applies a patch at a different \emph{update point} during
  execution.  To mitigate the increase in the number of tests, we
  developed an algorithm for \emph{test suite
    minimization} that finds a subset of update points that, if fully
  tested, yields the equivalent to full update point coverage.  We
  implemented our approach and evaluated it on OpenSSH and Vsftpd, two
  widely used server applications.  We found that minimization is
  highly effective, reducing the number of update tests required
  for full coverage by 93\%.
  },
  note = {Invited article},
  year = 2009,
  month = oct,
  url = {http://www.cs.umd.edu/~mwh/papers/dsutesting.pdf},
  category = {Dynamic_Software_Updating},
}

@inproceedings{khoo09checklist,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks and Vibha Sazawal},
  title = {Triaging Checklists: a Substitute for a {PhD} in Static Analysis},
  booktitle = inproc # plateau,
  abstract={
Static analysis tools have achieved great success in recent years in automating the process of
detecting defects in software. However, these sophisticated tools have yet to gain widespread
adoption, since many of these tools remain too difficult to understand and use. In
previous work, we discovered that even with an effective code visualization tool, users still found
it hard to determine if warnings reported by these tools were true errors or false warnings.
The fundamental problem users face is to understand enough of the underlying algorithm to determine
if a warning is caused by imprecision in the algorithm. In our current work, we propose to use
\emph{triaging checklists} to provide users with systematic guidance to identify false warnings by
taking into account specific sources of imprecision in the particular tool. Additionally, we plan to
provide \emph{checklist assistants}, which is a library of simple analyses designed to aid users in
answering checklist questions.
  },
  month = oct,
  year = 2009,
  category = {User_Interfaces},
  url = {http://www.cs.umd.edu/~mwh/papers/ppchecklists.pdf}
}

@inproceedings{martin10ownership,
  author = {Jean-Philippe Martin and Michael Hicks and Manuel Costa and Periklis Akritidis and Miguel Castro},
  title = {Dynamically Checking Ownership Policies in Concurrent {C/C++}
  Programs},
  booktitle = inproc # popl,
  pages = {457--470},
  abstract = {
Concurrent programming errors arise when threads share data
incorrectly. Programmers often avoid these errors by using
synchronization to enforce a simple ownership policy: data is either
\emph{owned exclusively} by a thread that can read or write the data,
or it is \emph{read owned} by a set of threads that can read but
not write the data.  Unfortunately, incorrect synchronization often
fails to enforce these policies and memory errors in languages like C
and C++ can violate these policies even when synchronization is
correct.

In this paper, we present a dynamic analysis for checking ownership
policies in concurrent C and C++ programs despite memory errors. The
analysis can be used to find errors in commodity multi-threaded
programs and to prevent attacks that exploit these errors.  We require
programmers to write ownership assertions that describe the sharing
policies used by different parts of the program.  These policies may
change over time, as may the policies' means of enforcement, whether
it be locks, barriers, thread joins, etc. Our compiler inserts checks
in the program that signal an error if these policies are violated at
runtime.  We evaluated our tool on several benchmark programs.  The
run-time overhead was reasonable: between 0 and 49\% with an average
of 26\%.  We also found the tool easy to use: the total number of
ownership assertions is small, and the asserted specification and
implementation can be debugged together by running the instrumented
program and addressing the errors that arise.  Our approach enjoys a
pleasing modular soundness property: if a thread executes a sequence
of statements on variables it owns, the statements are serializable
within a valid execution, and thus their effects can be reasoned about
in isolation from other threads in the program.
},
  month = jan,
  category = "Multithreaded_Programming",
  year = 2010,
  url = {http://www.cs.umd.edu/~mwh/papers/conccheck-full.pdf},
  note = {Full version}
}

@inproceedings{furr09stop,
  title = {Tests to the Left of Me, Types to the Right: How Not to Get Stuck in the Middle of a {Ruby} Execution (A Demo of Diamondback Ruby)},
  author = {Michael Furr and Jong-hoon (David) An and Jeffrey S. Foster and Michael Hicks},
  booktitle = inproc # stop,
  abstract = {
Ruby is a popular dynamic scripting language that permits
terse, expressive code, but provides no static checks to detect errors
before running the program. To address this, we have developed Diamondback
Ruby (DRuby), a tool that blends the beneﬁts of static and dynamic
typing. This paper brieﬂy describes the main features of DRuby, which
we will present in a tool demonstration. The presentation will concentrate
on the development of a small, statically typed Ruby program,
illustrating how DRuby might be used in practice. The audience will
learn about some of the practical design decisions that went into DRuby,
and how to use it to develop a type-safe Ruby program.},
  year = 2009,
  month = jul,
  url = {http://www.cs.umd.edu/~mwh/papers/rubydemo.pdf},
  category = {Static_Analysis},
}

@inproceedings{furr09ril,
  title = {The {Ruby} Intermediate Language},
  author = {Michael Furr and Jong-hoon (David) An and Jeffrey S. Foster and Michael Hicks},
  booktitle = inproc # dls,
  pages = {89--98},
  abstract = {
  Ruby is a popular, dynamic scripting language that aims to ``feel
  natural to programmers'' and give users the ``freedom to choose''
  among many different ways of doing the same thing.  While this
  arguably makes programming in Ruby easier, it makes it hard to build
  analysis and transformation tools that operate on Ruby source code.
  In this paper, we present the Ruby Intermediate Language (RIL), a
  Ruby front-end and intermediate representation that addresses these
  challenges.  Our system includes an extensible GLR parser for Ruby,
  and an automatic translation into RIL, an easy-to-analyze
  intermediate form.  This translation eliminates redundant language
  constructs, unravels the often subtle ordering among side effecting
  operations, and makes implicit interpreter operations explicit in
  its representation.

  We demonstrate the usefulness of RIL by presenting a simple static
  analysis and source code transformation to eliminate null pointer
  errors in Ruby programs.  We also describe several additional useful
  features of RIL, including a pretty printer that outputs RIL as
  syntactically valid Ruby code, a dataflow analysis engine, and a
  dynamic instrumentation library for profiling source code.  We hope
  that RIL's features will enable others to more easily build analysis
  tools for Ruby, and that our design will inspire the creation of
  similar frameworks for other dynamic languages.
},
  month = oct,
  year = 2009,
  url = {http://www.cs.umd.edu/~mwh/papers/ril.pdf},
  category = {Static_Analysis},
}

@inproceedings{khoo09arrowlets,
  author = {Yit Phang Khoo and Michael Hicks and Jeffrey S. Foster and Vibha Sazawal},
  title = {Directing {JavaScript} with Arrows},
  booktitle = inproc # dls,
  pages = {49--58},
  abstract={
  JavaScript programmers make extensive use of event-driven
  programming to help build responsive web applications. However,
  standard approaches to sequencing events are messy, and often lead
  to code that is difficult to understand and maintain. We have found
  that \emph{arrows}, a generalization of \emph{monads}, are an
  elegant solution to this problem. Arrows allow us to easily write
  asynchronous programs in small, modular units of code, and flexibly
  compose them in many different ways, while nicely abstracting the
  details of asynchronous program composition.  In this paper, we
  present Arrowlets, a new JavaScript library that offers arrows to
  the everyday JavaScript programmer. We show how to use Arrowlets to
  construct a variety of state machines, including state machines that
  branch and loop.  We also demonstrate how Arrowlets separate
  computation from composition with examples such as a drag-and-drop
  handler and a bubblesort animation.
  },
  month = oct,
  year = 2009,
  category = {User_Interfaces},
  url = {http://www.cs.umd.edu/~mwh/papers/jsarrows.pdf}
}

@inproceedings{swamy09coercion,
  author = {Nikhil Swamy and Michael Hicks and Gavin S. Bierman},
  title = {A Theory of Typed Coercions and its Applications},
  pages = {329--340},
  booktitle = inproc # icfp,
  abstract = {
  A number of important program rewriting scenarios can be recast as
  type-directed coercion insertion. These range from more theoretical
  applications such as coercive subtyping and supporting overloading
  in type theories, to more practical applications such as integrating
  static and dynamically typed code using gradual typing, and inlining
  code to enforce security policies such as access control and
  provenance tracking.  In this paper we give a general theory of
  type-directed coercion insertion.
  We specifically explore the inherent tradeoff between
  expressiveness and ambiguity---the more powerful the strategy for
  generating coercions, the greater the possibility of several,
  semantically distinct rewritings for a given program.  We consider
  increasingly powerful coercion generation strategies, work out
  example applications supported by the increased power (including
  those mentioned above), and identify the inherent ambiguity problems
  of each setting, along with various techniques to tame the
  ambiguities.
},
  month = aug,
  year = 2009,
  url = {http://www.cs.umd.edu/~mwh/papers/coercions.pdf},
  category = {Static_Analysis},
}

@inproceedings{papageorgiou09mgrp,
  author = {Pavlos Papageorge and Justin McCann and Michael Hicks},
  title = {Passive Aggressive Measurement with {MGRP}},
  booktitle = inproc # sigcomm,
  pages = {279--290},
  month = aug,
  year = 2009,
  abstract = {
  We present the \emph{Measurement Manager Protocol} (MGRP),
  an in-kernel service that schedules and transmits probes
  on behalf of active measurement tools.  Unlike prior measurement
  services, MGRP transparently piggybacks application packets inside
  the often significant amounts of empty padding contained in typical
  probes.  Using MGRP thus combines the modularity, flexibility, and
  accuracy of standalone active measurement tools with the lower
  overhead of passive measurement techniques.  Microbenchmark experiments
  show that the resulting bandwidth savings makes it possible to
  measure the network accurately, but faster and more aggressively than
  without piggybacking, and with
  few ill effects to piggybacked application or competing
  traffic.  When using MGRP to schedule
  measurements on behalf of MediaNet, an overlay service
  that adaptively schedules media streams, we show MediaNet can achieve
  significantly higher streaming rates under the same network
  conditions.
  },
  category = {Programmable_Networks},
  url = {http://www.cs.umd.edu/~mwh/papers/mgrp.pdf},
}

@inproceedings{neamtiu09stump,
  title = {Safe and Timely Dynamic Updates for Multi-threaded Programs},
  author = {Iulian Neamtiu and Michael Hicks},
  booktitle = inproc # pldi,
  abstract = {
  Many dynamic updating systems have been developed that enable a
  program to be patched while it runs, to fix bugs or add new
  features.  This paper explores techniques for supporting dynamic
  updates to multi-threaded programs, focusing on the problem of
  applying an update in a timely fashion
  while still producing correct behavior.  Past work has shown that
  this tension of \emph{safety} versus \emph{timeliness} can be balanced for
  single-threaded programs.  For
  multi-threaded programs, the task is more difficult because
  myriad thread interactions complicate understanding the possible
  program states to which a patch could be applied.  Our approach allows
  the programmer to specify a few program points (e.g., one per
  thread) at which a patch may be applied, which simplifies reasoning
  about safety.  To improve timeliness, a combination of static
  analysis and run-time support automatically expands these few points
  to many more that produce behavior equivalent to
  the originals.  Experiments with thirteen realistic updates to three
  multi-threaded servers show that we can safely perform a dynamic
  update within milliseconds when more straightforward alternatives would
  delay some updates indefinitely.
  },
  month = jun,
  year = 2009,
  pages = {13--24},
  url = {http://www.cs.umd.edu/~mwh/papers/ginsengMT.pdf},
  category = {Dynamic_Software_Updating},
}

@inproceedings{king08implicit,
  title = {Implicit Flows: Can't live with 'em, can't live without 'em},
  author = {Dave King and Boniface Hicks and Michael Hicks and Trent Jaeger},
  booktitle = inproc # {International Conference on Information Systems Security (ICISS)},
  month = dec,
  year = 2008,
  series = {Lecture Notes in Computer Science},
  volume = {5352},
  editor = {R. Sekar and Arun K. Pujari},
  publisher = {Springer},
  abstract = {
Verifying that programs trusted to enforce security actually do so is
a practical concern for programmers and administrators.  However, there is a
disconnect between the kinds of tools that have been successfully applied to real
software systems (such as taint mode in Perl and Ruby), and information-flow
compilers that enforce a variant of the stronger security property of
noninterference.  Tools that have been successfully used to find security
violations have focused on {\it explicit flows} of information, where
high-security information is directly leaked to output.  Analysis tools that
enforce noninterference also prevent {\it implicit flows} of
information, where high-security information can be inferred from a program's
flow of control.  However, these tools have seen little use in
practice, despite the stronger guarantees that they provide.

To better understand why, this paper experimentally investigates
the explicit and implicit flows identified by the standard
algorithm for establishing noninterference.  When applied to
implementations of authentication and cryptographic functions, the
standard algorithm discovers many real implicit flows of
information, but also reports an extremely high number of false alarms,
most of which are due to conservative handling of unchecked
exceptions (e.g., null pointer exceptions).  After a careful
analysis of all sources of
true and false alarms, due to both implicit and explicit flows, the
paper concludes with some ideas to improve the false alarm rate,
toward making stronger security analysis more practical.
  },
  pages = {56--70},
  optnote = {accept rate 15 full + 4 short + 2 ongoing research / 81},
  url = {http://www.cs.umd.edu/~mwh/papers/implicitflows.pdf},
  category = {Security},
}

@article{hicks10scoreshort,
  title = {Score: Agile Research Group Management},
  author = {Michael Hicks and Jeffrey S. Foster},
  journal = {Communications of the {ACM}},
  month = oct,
  volume = {53},
  number = {10},
  pages = {30--31},
  year = 2010,
  url = {http://www.cs.umd.edu/~mwh/papers/score-short.pdf},
  abstract = {Score is an adaptation of the Scrum agile software development methodology to the task of managing Ph.D. students in an academic research group.    This paper describes Score, conceived in October 2006, and our experience using it.  We have found that Score enables us---faculty and students---to be more efficient and thereby more productive, and enhances the cohesion of our research group.},
  category = {Miscellaneous},
}

@techreport{hayden09testingTR,
  title = {A Testing Based Empirical Study of Dynamic Software Update Safety Restrictions},
  author = {Christopher M. Hayden and Eric A. Hardisty and Michael Hicks and Jeffrey S. Foster},
  number = {CS-TR-4949},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  abstract = {
  Recent years have seen significant advances in dynamic software
  updating (DSU) systems, which allow programs to be patched on the
  fly.  Most DSU systems employ automatic safety checks to avoid
  applying a patch if doing so may lead to incorrect behavior.
  This
  paper presents what we believe is the first comprehensive empirical evaluation
  of the two most significant DSU safety checks: \emph{activeness
    safety} (AS), which disallows patches that modify functions
  on the stack, and \emph{con-freeness safety}
  (CFS), which allows modifications to active functions, but only
  when doing so will be type safe.

  To measure the checks' effectiveness, we tested them
  against three years of updates to Open\-SSH and
  vsftpd.  We performed this testing using a novel DSU testing methodology that
  systematically applies updates throughout the
  execution of a test suite.  After testing updates to both
  applications in this way, we tracked how often the safety checks
  allow updates and which updates result in
  test failures.  We found that updating without safety checks
  produced
  many failures, and that both AS and CFS dramatically reduced, but did not
  fully eliminate, these failures.  CFS yielded more failures
  than AS, but
  AS was more restrictive than CFS, disallowing far
  more successful updates.
  Our results suggest that neither AS nor CFS is likely
  suitable for general-purpose DSU on its own.
  Indeed, we found that selecting update points manually could
  avoid all failures while still permitting sufficient updates.
  Our results present a challenge and important insights for future
  work: to discover
  safe and sufficient update points fully automatically.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/dsutesting-tr.pdf},
  category = {Dynamic_Software_Updating},
  year = 2009,
  month = nov,
}

@techreport{hicks10score,
  title = {Adapting {Scrum} to Managing a Research Group},
  author = {Michael Hicks and Jeffrey S. Foster},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  number = {CS-TR-4966},
  month = sep,
  year = 2010,
  url = {http://www.cs.umd.edu/~mwh/papers/score.pdf},
  abstract = {Score is an adaptation of the Scrum agile software development methodology to the task of managing Ph.D. students in an academic research group.    This paper describes Score, conceived in October 2006, and our experience using it.  We have found that Score enables us---faculty and students---to be more efficient and thereby more productive, and enhances the cohesion of our research group.},
  category = {Miscellaneous},
}

@article{pratikakis11locksmith,
  title = {Locksmith: Practical Static Race Detection for {C}},
  author = {Polyvios Pratikakis and Jeffrey S. Foster and Michael Hicks},
  journal = toplas,
  month = jan,
  year = 2011,
  url = {http://www.cs.umd.edu/~mwh/papers/locksmith-journal.pdf},
  abstract = {
  Locksmith is a static analysis tool for automatically detecting
  data races in C programs.  In this paper, we describe each of
  Locksmith's component analyses precisely, and present systematic
  measurements that isolate interesting tradeoffs between precision
  and efficiency in each analysis.  Using a benchmark suite comprising
  standalone applications and Linux device drivers totaling more than
  200,000 lines of code, we found that a simple no-worklist strategy
  yielded the most efficient interprocedural dataflow analysis; that
  our sharing analysis was able to determine that most locations are
  thread-local, and therefore need not be protected by locks; that
  modeling C structs and void pointers precisely is key to both
  precision and efficiency; and that context-sensitivity yields a much
  more precise analysis, though with decreased scalability.  Put
  together, our results illuminate some of the key engineering
  challenges in building Locksmith and data race detection analyses
  in particular, and constraint-based program analyses in general.
  },
  category = "Multithreaded_Programming",
  volume = {33},
  number = 1,
  pages = {Article 3},
}

@misc{hicks08trusted,
  title = {Trusted Declassification: Policy Infrastructure for a Security-Typed Language},
  author = {Boniface Hicks and Dave King and Patrick McDaniel and Michael Hicks},
abstract = {
Security-typed languages are a powerful tools for developing verifiably secure software applications. Programs written in these languages enforce a strong, global policy of noninterference which ensures that high-security data will not be observable on low-security channels. Because noninterference is typically too strong a property, most programs use some form of declassification to selectively leak high security information, e.g. when performing a password check or data encryption. Unfortunately, such a declassification is often expressed as an operation within a given program, rather than as part of a global policy, making reasoning about the security implications of a policy difficult.

In this paper, we propose a simple idea we call trusted declassification in which special declassifier functions are specified as part of the global policy. In particular, individual principals declaratively specify which declassifiers they trust so all information flows implied by the policy can be reasoned about in absence of a particular program. We formalize our approach for a Java-like language and prove a modified form of noninterference which we call noninterference modulo trusted methods. We have implemented our approach as an extension to Jif, a security-typed variant of Java, and provide our experience using it to build a secure email client, JPmail.
},
  month = "June",
  url = "http://www.cs.umd.edu/~mwh/papers/tdeclass-submitted.pdf",
  category = "Security",
  note = {Full version of PLAS 06 paper},
  omitfromweb = {yes},
  year = 2008,
}

@techreport{swamy07fableTR,
	Author = {Nikhil Swamy and Brian J. Corcoran and Michael Hicks},
  INSTITUTION = {University of Maryland, Department of Computer Science},
        Number = {CS-TR-4895},
	Title = {Fable: A Language for Enforcing User-defined Security Policies},
	Year = 2007,
	month = nov,
        abstract = {
This paper presents Fable, a core formalism for a programming language
in which programmers may specify security policies and reason that
these policies are properly enforced. In Fable,
security policies can be expressed by associating \emph{security
labels} with the data or actions they protect. Programmers define the
semantics of labels in a separate part of the program called the
\emph{enforcement policy}. Fable prevents a policy from being circumvented
by allowing labeled terms to be manipulated only within the enforcement
policy; application code must treat labeled values abstractly.
Together, these features
facilitate straightforward proofs that programs implementing a
particular policy achieve their high-level security goals.  Fable is
flexible enough to implement a wide variety of security policies,
including access control, information flow, provenance, and security
automata. We have implemented Fable as part of the Links web
programming language; we call the resulting language SELinks.  We
report on our experience using SElinks to build two substantial
applications, a wiki and an on-line store, equipped with a combination of
access control and provenance policies.
 To our knowledge, no existing framework enables
the enforcement of such a wide variety of security policies with an
equally high level of assurance.
        },
         Note={Full version of Oakland 08 paper},
        url = {http://www.cs.umd.edu/~nswamy/papers/fable-tr.pdf},
        category = {Security},
}

@techreport{swamy08airTR,
	Author = {Nikhil Swamy and Michael Hicks},
  INSTITUTION = {University of Maryland, Department of Computer Science},
        Number = {CS-TR-4906},
	Title = {Verified Enforcement of Automaton-based Information Release Policies},
        mon = jun,
  abstract = {
  Many organizations specify \emph{information release} policies to
  describe the terms under which sensitive information may be released
  to other organizations.  This paper presents a new approach for
  ensuring that security-critical software correctly enforces its
  information release policy.  Our approach has two parts.  First, an
  information release policy is specified as a security automaton
  written in a new language called AIR.  Second, we enforce an AIR
  policy by translating it into an API for programs written in Lair,
  a core formalism for a functional programming language. Lair uses
  a novel combination of dependent, affine, and singleton types to
  ensure that the API is used correctly. As a consequence we can
  certify that programs written in Lair meet the requirements of
  the original AIR policy specification.
  },
	Year = 2008,
         Note={Full version of PLAS 08 paper},
	url = {http://www.cs.umd.edu/~nswamy/papers/lair-tr.pdf},
	category = {Security}
}


@article{meister10cir,
  author = {Jeffrey A. Meister and Jeffrey S. Foster and Michael Hicks},
  title = {Serializing {C} intermediate representations for efficient and portable parsing},
  journal = spe,
  abstract = {
  C static analysis tools often use intermediate representations (IRs)
  that organize program data in a simple, well-structured
  manner. However, the C parsers that create IRs are slow, and because
  they are difficult to write, only a few implementations exist,
  limiting the languages in which a C static analysis can be written. To
  solve these problems, we investigate two language-independent,
  on-disk representations of C IRs: one using XML, and the other using
  an Internet standard binary encoding called XDR. We benchmark the
  parsing speeds of both options, finding the XML to be about a factor
  of two slower than parsing C and the XDR
  over six times faster.
  Furthermore, we show that the XML files are far too large
  at 19 times the size of C source code, while XDR is only 2.2 times
  the C size. We also demonstrate the
  portability of our XDR system by presenting a C source code querying tool in
  Ruby. Our solution and the insights we gained from building it will
  be useful to analysis authors and other clients of C IRs. We have made
  our software freely available for download at
  \url{http://www.cs.umd.edu/projects/PL/scil/}.
  },
  month = feb,
  volume = 40,
  number = 3,
  pages = {225--238},
  url = {http://www.cs.umd.edu/~mwh/papers/scil.pdf},
  http = {http://www.cs.umd.edu/projects/PL/scil},
  year = 2010,
  category = {Static_Analysis},
}

@inproceedings{khoo08jsarrows,
  author = {Yit Phang Khoo and Michael Hicks and Jeffrey S. Foster and Vibha Sazawal},
  title = {Directing JavaScript with Arrows (poster summary)},
  booktitle = {Poster Proceedings of the } # icfp,
  abstract = {
Event-driven programming in JavaScript often leads to code that
is messy and hard to maintain. We have found \emph{arrows}, a generalization
of \emph{monads}, to be an elegant solution to this problem. Our
arrow-based \emph{Arrowlets} library makes it easy to compose eventdriven
programs in modular units of code. In particular, we show
how to implement \emph{drag-and-drop} modularly using arrows.
  },
  url = {http://www.cs.umd.edu/~khooyp/papers/poster-summary.pdf},
  month = sep,
  year = 2008,
  category = {User_Interfaces},
}

@techreport{khoo08jsarrowstr,
  author = {Yit Phang Khoo and Michael Hicks and Jeffrey S. Foster and Vibha Sazawal},
  title = {Directing JavaScript with Arrows (Functional Pearl)},
  abstract = {
JavaScript, being a single-threaded language, makes extensive use of event-driven programming to enable responsive web applications. However, standard approaches to sequencing events are messy, and often lead to code that is difficult to understand and maintain. We have found that arrows, a generalization of monads, are an elegant solution to this problem. Arrows allow us to easily write asynchronous programs in small, modular units of code, and flexibly compose them in many different ways, while nicely abstracting the details of asynchronous program composition. In particular, we show how to use arrows to construct a variety of state machines, such as autoscrollers and drag-and-drop handlers.
},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  number = {CS-TR-4923},
  month = aug,
  year = 2008,
  category = {User_Interfaces},
  note = {Extended version of ICFP 2008 poster},
  url = {http://hdl.handle.net/1903/8400}
}

@inproceedings{furr08druby,
  author = {Michael Furr and Jong-hoon (David) An and Jeffrey S. Foster and Michael Hicks},
  title = {Static Type Inference for {Ruby}},
  booktitle = inproc # oops,
  abstract = {
  Many general-purpose, object-oriented scripting languages are
  dynamically typed, which provides flexibility but leaves the
  programmer without the benefits of static typing, including early
  error detection and the documentation provided by type
  annotations.  This paper describes Diamondback Ruby
  (DRuby), a tool that blends Ruby's dynamic type system with a
  static typing discipline.  DRuby provides a type
  language that is rich enough to precisely type Ruby code we have
  encountered, without unneeded complexity.
  When possible, DRuby infers static types to discover
  type errors in Ruby programs.  When necessary, the programmer can
  provide DRuby with
  annotations that assign static types to dynamic code.  These
  annotations are checked at run time, isolating type errors to
  unverified code.  We applied DRuby to a suite of benchmarks and
  found several bugs that would cause run-time type
  errors. DRuby also reported a number of warnings that reveal questionable
  programming practices in the benchmarks. We believe that DRuby
  takes a major step toward bringing the benefits
  of combined static and dynamic typing to Ruby and other
  object-oriented languages.
  },
  category = {Static_Analysis},
  month = mar,
  year = 2009,
  pages = {1859--1866},
  url = {http://www.cs.umd.edu/~mwh/papers/druby.pdf}
}

@inproceedings{subramanian09jvolve,
  author = {Suriya Subramanian and Michael Hicks and Kathryn S. McKinley},
  title = {Dynamic Software Updates: A {VM}-Centric Approach},
  booktitle = inproc # pldi,
  abstract = {
Software evolves to fix bugs and add features. Stopping and restarting
programs to apply changes is inconvenient and often costly.  Dynamic
software updating (DSU) addresses this problem by updating programs while
they execute, but existing DSU systems for managed languages do not support
many updates that occur in practice and are inefficient.  This paper
presents the design and implementation of Jvolve, a DSU-enhanced Java VM.
Updated programs may add, delete, and replace fields and methods anywhere
within the class hierarchy. Jvolve implements these updates by adding to
and coordinating VM classloading, just-in-time compilation, scheduling,
return barriers, on-stack replacement, and garbage collection. Jvolve is
safe: its use of bytecode verification and VM thread synchronization
ensures that an update will always produce type-correct executions. Jvolve
is flexible: it can support 20 of 22 updates to three open-source
programs---Jetty web server, JavaEmailServer, and CrossFTP server---based
on actual releases occurring over 1 to 2 years.  Jvolve is efficient:
performance experiments show that incurs no overhead during steady-state
execution.  These results demonstrate that this work is a significant step
towards practical support for dynamic updates in virtual machines for
managed languages.}
,
  category = {Dynamic_Software_Updating},
  month = jun,
  year = 2009,
  url = {http://www.cs.umd.edu/~mwh/papers/jvolve.pdf},
  pages = {1--12},
}

@inproceedings{corcoran09selinks,
  author = {Brian J. Corcoran and Nikhil Swamy and Michael Hicks},
  title = {Cross-tier, Label-based Security Enforcement for Web Applications},
  booktitle = inproc # sigmod,
  abstract = {
  This paper presents SELinks, a programming language focused on
  building secure multi-tier web applications.  SELinks provides a
  uniform programming model, in the style of LINQ and Ruby on Rails,
  with language syntax for accessing objects residing either in the
  database or at the server.  Object-level security policies are
  expressed as fully-customizable, first-class \emph{labels} which may
  themselves be subject to security policies.  Access to labeled data
  is mediated via trusted, user-provided \emph{policy enforcement}
  functions.

  SELinks has two novel features that ensure security policies are
  enforced correctly and efficiently.  First, SELinks implements a
   type system called Fable that allows a protected
  object's type to refer to its protecting label. The type
  system can check that labeled data is never accessed directly by the
  program without first consulting the appropriate policy
  enforcement function.  Second, SELinks compiles policy enforcement
  code to database-resident user-defined functions that can be
  called directly during query processing.  Database-side checking
  avoids transferring data to the server needlessly, while still
  allowing policies to be expressed in a customizable and portable
  manner.

  Our experience with two sizable web applications, a model
  health-care database and a secure wiki with fine-grained security
  policies, indicates that cross-tier policy enforcement in SELinks
  is flexible, relatively easy to use, and, when compared to a
  single-tier approach, improves throughput by nearly an order of
  magnitude. SELinks is freely available.
  },
  month = jun,
  year = 2009,
  category = {Security},
  pages = {269--282},
  url = {http://www.cs.umd.edu/~mwh/papers/selinks.pdf},
}

@techreport{khoo08pathprojtr,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks and Vibha Sazawal},
  title = {Path Projection for User-Centered Static Analysis Tools (long version)},
  abstract = {
The research and industrial communities have made great strides in developing sophisticated defect detection tools based on static analysis. However, to date most of the work in this area has focused on developing novel static analysis algorithms, and neglected study of other aspects of static analysis tools, in particular user interfaces. In this work, we present a novel user interface toolkit called Path Projection that helps users visualize, navigate, and understand program paths, a common component of many static analysis tools’ error reports. We performed a controlled user study to measure the benefit of Path Projection in triaging error reports from Locksmith, a data race detection tool for C. We found that Path Projection improved participants’ time to complete this task, without affecting accuracy, and that participants felt Path Projection was useful.
},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  number = {CS-TR-4919},
  month = aug,
  year = 2008,
  category = {User_Interfaces},
  url = {http://hdl.handle.net/1903/8369}
}

@inproceedings{khoo08pathproj,
  author = {Yit Phang Khoo and Jeffrey S. Foster and Michael Hicks and Vibha Sazawal},
  title = {Path Projection for User-Centered Static Analysis Tools},
  booktitle = inproc # paste,
  pages = {57--63},
  abstract = {
  The research and industrial communities have made
  great strides in developing sophisticated defect detection tools
  based on static analysis.  To date most of the work in this
  area has focused on developing novel static analysis
  \emph{algorithms}, but has neglected study of other aspects of static
  analysis \emph{tools}, particularly user interfaces.  In this work,
  we present a novel user interface toolkit called Path Projection
  that helps users visualize, navigate, and understand program paths,
  a common component of many tools' error reports.
  We performed a controlled user study to measure the benefit of Path
  Projection in triaging error reports from Locksmith, a data race
  detection tool for C\@.  We found that Path Projection improved
  participants' time to complete this task without affecting
  accuracy, while participants felt Path Projection was useful and
  strongly preferred it to a more standard viewer.
  },
  month = nov,
  year = 2008,
  category = {User_Interfaces},
  url = {http://www.cs.umd.edu/~mwh/papers/pathproj-short.pdf}
}

@inproceedings{pratikakis08context,
  author = {Polyvios Pratikakis and Jeffrey S. Foster and Michael Hicks and Iulian Neamtiu},
  title = {Formalizing Soundness of Contextual Effects},
  booktitle = inproc # {International Conference on Theorem Proving in Higher Order Logics (TPHOLs)},
editor = {Otmane A\"it Mohamed and C\'esar Mu\={n}oz and Sofi\`ene Tahar},
pages = {262--277},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
volume = {5170},
  abstract = {
  A \emph{contextual effects} system generalizes standard type
  and effect systems: where a standard effects system computes the
  effect of an expression $e$, a contextual effects system
  additionally computes the \emph{prior} and \emph{future} effect of
  $e$, which characterize the behavior of computation prior to, and
  following, respectively, the evaluation of $e$.  This paper
  describes the formalization and proof of soundness of contextual
  effects, which we mechanized using the Coq proof assistant.
  Contextual effect soundness is an unusual property because the prior
  and future effect of a term $e$ depends not on $e$ itself (or its
  evaluation), but rather on the evaluation of the context in which
  $e$ appears.  Therefore, to state and prove soundness we must
  ``match up'' a subterm in the original typing derivation with the
  possibly-many evaluations of that subterm during the evaluation of
  the program, in a way that is robust under substitution.  We do this
  using a novel typed operational semantics.  We conjecture that our
  approach could prove useful for approaching other properties of
  derivations that rely on the context in which that derivation
  appears.
  },
  month = aug,
  year = 2008,
  category = {Static_Analysis},
  url = {http://www.cs.umd.edu/~mwh/papers/contextproof.pdf}
}

@inproceedings{swamy08air,
  author = {Nikhil Swamy and Michael Hicks},
  title = {Verified Enforcement of Stateful Information Release Policies},
  booktitle = inproc # plas,
  abstract = {
  Many organizations specify \emph{information release} policies to
  describe the terms under which sensitive information may be released
  to other organizations.  This paper presents a new approach for
  ensuring that security-critical software correctly enforces its
  information release policy.  Our approach has two parts.  First, an
  information release policy is specified as a security automaton
  written in a new language called AIR.  Second, we enforce an AIR
  policy by translating it into an API for programs written in Lair,
  a core formalism for a functional programming language. Lair uses
  a novel combination of dependent, affine, and singleton types to
  ensure that the API is used correctly. As a consequence we can
  certify that programs written in Lair meet the requirements of
  the original AIR policy specification.
  },
  month = jun,
  year = 2008,
  category = {Security},
  pages = {21--32},
  optnote = "accept rate 13/24",
  url = {http://www.cs.umd.edu/~mwh/papers/air.pdf}
}

@inproceedings{swamy08fable,
  author = {Nikhil Swamy and Brian Corcoran and Michael Hicks},
  title = {Fable: A Language for Enforcing User-defined Security Policies},
  booktitle = inproc # oakland,
  abstract = {
This paper presents Fable, a core formalism for a programming language
in which programmers may specify security policies and reason that
these policies are properly enforced. In Fable,
security policies can be expressed by associating \emph{security
labels} with the data or actions they protect. Programmers define the
semantics of labels in a separate part of the program called the
\emph{enforcement policy}. Fable prevents a policy from being circumvented
by allowing labeled terms to be manipulated only within the enforcement
policy; application code must treat labeled values abstractly.
Together, these features
facilitate straightforward proofs that programs implementing a
particular policy achieve their high-level security goals.  Fable is
flexible enough to implement a wide variety of security policies,
including access control, information flow, provenance, and security
automata. We have implemented Fable as part of the Links web
programming language; we call the resulting language SELinks.  We
report on our experience using SElinks to build two substantial
applications, a wiki and an on-line store, equipped with a combination of
access control and provenance policies.
 To our knowledge, no existing framework enables
the enforcement of such a wide variety of security policies with an
equally high level of assurance.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/fable.pdf},
  category = {Security},
  month = may,
  year = 2008,
  optnote = {Accept rate 28/249 (11.2\%)},
  pages = {369--383},
}


@unpublished{HicksKMGN06,
  author =       "Michael W. Hicks and Pankaj Kakkar and Jonathan T. Moore and Carl A. Gunter and Scott M. Nettles",
  title =        "{PLAN}: A Packet Language for Active Networks (Extended version)",
  month =        "May",
  year =         2006,
  abstract = {
The Internet protocols were designed to emphasize simple rout-
ing elements and intelligent hosts. However, there are applications
that benefit from allowing hosts to customize or program routers, a
concept known as active networking. Since routers are shared, this
raises challenges with delivering sufficient flexibility while preserving
or improving performance, security, and safety. PLAN (Packet Lan-
guage for Active Networks) is a language designed for the SwitchWare
active network architecture. This architecture comprises active pack-
ets containing PLAN programs that invoke service routines over an
active OS. PLAN is based on the polymorphic lambda calculus and
provides a restricted set of primitives and datatypes that enables rea-
soning about its impact on network resources based on features of the
language design. This paper focuses on the PLAN language with the
aim of consolidating a variety of studies that were carried out in the
years after its introduction in 1998. These studies include the require-
ments for PLAN, its design, programming in PLAN, the specification
and theory of PLAN, and its use in networking applications.
  },
  url =         "http://www.cs.umd.edu/~mwh/papers/plan-extended.pdf",
  note =        "Unpublished manuscript.  Consolidates ICFP 98, IPL 98, Allterton 99 papers",
  category = "Programmable_Networks"
}


@inproceedings{corcoran07provenance,
  author = {Brian Corcoran and Nikhil Swamy and Michael Hicks},
  title = {Combining Provenance and Security Policies in a Web-based
    Document Management System},
  booktitle = "On-line Proceedings of the Workshop on Principles of Provenance (PrOPr)",
  note = "\url{http://homepages.inf.ed.ac.uk/jcheney/propr/}",
  location = {Edinburgh, Scotland, UK},
  abstract = {
Provenance and security are intimately related. Cheney et
al. show that the dependencies underlying provenance
information also underly information flow security policies. Provenance
information can also play a role in history-based access control
policies.  Many real applications have the need to
combine a variety of security policies with provenance tracking. For
instance, an online stock trading website might restrict access to certain
premium features it offers using an access control policy, while at the same
time using an information flow policy to ensure that a user's sensitive
trading information is not leaked to other users. Similarly, the application
might need to track the provenance of transaction information to support an
annual financial audit while also using provenance to attest to the
reliability of stock analyses that it presents to its users.

We have been exploring the interaction between provenance and security
policies while developing a document management system we call the
\emph{Collaborative Planning Application} (CPA).  The CPA is written in
SELinks, our language for supporting user-defined, label-based security
policies. SELinks is an extension of the Links
web-programming language with means to express label-based
security policies.  Labels are associated with the data they protect by
using dependent types which, along with some syntactic restrictions, suffice
to ensure that user-defined policies enjoy \emph{complete mediation} and
cannot be circumvented.  Our interest in provenance and
security policies is thus part of a broader exploration of how security
policies can be encoded, composed, and reasoned about within SELinks.  In
this paper, we describe the architecture of the CPA and its approach to
label-based provenance and security policies
and we sketch directions for further exploration on the interaction between
the two.
  },
  month = nov,
  year = 2007,
  url = {http://www.cs.umd.edu/~mwh/papers/prov.pdf},
  category = "Security"
}

@inproceedings{swamy07milcom,
  author = {Nikhil Swamy and Michael Hicks and Simon Tsang},
  title = {Verified Enforcement of Security Policies for Cross-Domain
Information Flows},
  month = oct,
  year = 2007,
  booktitle = inproc # "2007 Military Communications Conference (MILCOM)",
  url = "http://www.cs.umd.edu/~mwh/papers/selinks-cpa.pdf",
  abstract = {
We describe work in progress that uses program analysis to show that
security-critical programs, such as cross-domain guards, correctly
enforce cross-domain security policies.
We are enhancing existing techniques from the field of
security-oriented programming languages to construct a new language
for the construction of secure networked applications, \emph{SELinks}.
In order to specify and enforce expressive and fine-grained policies,
we advocate dynamically associating security labels with sensitive
entities.
Programs written in \emph{SELinks} are statically guaranteed to
correctly manipulate an entity's security labels and to ensure that
the appropriate policy checks mediate all operations that are
performed on the entity.
We discuss the design of our main case study: a web-based
collaborative planning application that will permit a collection
of users, with varying security requirements and clearances, to access
sensitive data sources and collaboratively create documents based on
these sources.
  },
  category = "Security",
}

@inproceedings{neamtiu08context,
  author = {Iulian Neamtiu and Michael Hicks and Jeffrey S. Foster and Polyvios Pratikakis},
  title = {Contextual Effects for Version-Consistent Dynamic Software Updating and Safe Concurrent Programming},
  booktitle = inproc # popl,
  abstract = {
This paper presents a generalization of standard effect systems that
we call \emph{contextual effects}.  A traditional effect system
computes the effect of an expression $e$.  Our system additionally
computes the effects of the computational context in which $e$ occurs:
both the effect of the computation that has already occurred
(\emph{prior effects}) and the effect of the computation yet to take
place (\emph{future effects}).

Contextual effects can be used in any application in which the past or
future computation of the program is relevant at various program points.  We
present two substantial examples.  First, we show how prior and future
effects can be used to enforce \emph{transactional version consistency}
(TVC), a novel correctness property for dynamic software updates. TVC
ensures that programmer-designated transactional code blocks appear to
execute entirely at the same code version, even if a dynamic update occurs
in the middle of the block.  Second, we show how future effects can be used
in the analysis of multi-threaded programs to find thread-shared locations.
This is an essential step in applications such as data race detection.
},
  url = {http://www.cs.umd.edu/~mwh/papers/contexteffs.pdf},
  category = {Dynamic_Software_Updating},
  optnote = {Accept rate 35/212},
  pages = {37--50},
  month = jan,
  year = 2008,
}

@TECHREPORT{MT-TR,
  AUTHOR = {Iulian Neamtiu and Michael Hicks and Jeffrey S. Foster and Polyvios Pratikakis},
  TITLE = {Contextual Effects for Version-Consistent Dynamic Software Updating
  and Safe Concurrent Programming (extended version)},
  abstract = {
This paper presents a generalization of standard effect systems that
we call \emph{contextual effects}.  A traditional effect system
computes the effect of an expression $e$.  Our system additionally
computes the effects of the computational context in which $e$ occurs:
both the effect of the computation that has already occurred
(\emph{prior effects}) and the effect of the computation yet to take
place (\emph{future effects}).

Contextual effects can be used in any application in which the past or
future computation of the program is relevant at various program points.  We
present two substantial examples.  First, we show how prior and future
effects can be used to enforce \emph{transactional version consistency}
(TVC), a novel correctness property for dynamic software updates. TVC
ensures that programmer-designated transactional code blocks appear to
execute entirely at the same code version, even if a dynamic update occurs
in the middle of the block.  Second, we show how future effects can be used
in the analysis of multi-threaded programs to find thread-shared locations.
This is an essential step in applications such as data race detection.
},
  INSTITUTION = {University of Maryland, Department of Computer Science},
  NUMBER = {CS-TR-4875},
  category = {Dynamic_Software_Updating},
  url = {http://www.cs.umd.edu/~mwh/papers/ctxeffs-tr.pdf},
  YEAR = 2007,
  MONTH = jul
}

@TechReport{srivastava07cmodjournaltr,
  author = 	 {Saurabh Srivastava and Michael Hicks and Jeffrey S. Foster},
  title = 	 {Appendix to {CMod}: Modular Information Hiding and Type-Safe Linking for {C}},
  institution = {Department of Computer Science, University of Maryland},
  month = jun,
  year = 	 2007,
  number =	 {CS-TR-4874},
  abstract = {
This brief note is an appendix to \emph{CMod: Modular
  Information Hiding and Type-Safe Linking for C} (Srivastava et al., June 2007).
It consists of the proof of soundness for the formal language presented in that paper.
},
  url = {http://www.cs.umd.edu/~mwh/papers/appendix-proof.pdf},
  category = "Safe_Low-level_Programming"
}

@article{srivastava08cmodjournal,
  author = {Saurabh Srivastava and Michael Hicks and Jeffrey S. Foster and Patrick Jenkins},
  title = {Modular Information Hiding and Type Safe Linking for {C}},
  journal = {IEEE Transactions on Software Engineering},
  volume = 34,
  number = 3,
  note = {Full version of {TLDI} 07 paper},
  month = may,
  year = 2008,
  pages = {1--20},
  abstract = {
  This paper presents {\sc CMod}, a novel tool that provides a sound
  module system for C\@.  {\sc CMod} works by enforcing a set of four
  rules that are based on principles of modular reasoning and on
  current programming practice.  {\sc CMod}'s rules flesh out the
  convention that \texttt{.h} header files are module interfaces and
  \texttt{.c} source files are module implementations.  Although this
  convention is well-known, existing explanations of it are
  incomplete, omitting important subtleties needed for soundness.  In
  contrast, we have proven formally that {\sc CMod}'s rules enforce both
  information hiding and type-safe linking.

  To use {\sc CMod}, the programmer develops and builds their software as
  usual, redirecting the compiler and linker to {\sc CMod}'s wrappers.  We
  evaluated {\sc CMod} by applying it to 30 open source
  programs, totaling more than one million lines of code.  Violations to
  {\sc CMod}'s rules revealed more than a thousand information hiding errors,
  dozens of typing errors, and hundreds of cases that, although  not
  currently bugs, make programming mistakes more likely as the code
  evolves.  At the same time, programs generally adhere
  to the assumptions underlying {\sc CMod}'s rules, and so we could fix rule violations
  with a modest effort.  We conclude that {\sc CMod} can effectively support
  modular programming in C: it soundly enforces type-safe linking and
  information hiding while being largely compatible with existing practice.
  },
  url = {http://www.cs.umd.edu/~mwh/papers/cmod-journal.pdf},
  category = "Safe_Low-Level_Programming",
}


@inproceedings{petroni07sbcfi,
  author = {Petroni, Jr., Nick L. and Michael Hicks},
  title = {Automated Detection of Persistent Kernel Control-Flow Attacks},
  booktitle = inproc # ccs,
  month = oct,
  abstract = {
This paper presents a new approach to dynamically monitoring operating
system kernel integrity, based on a property called \emph{state-based
control-flow integrity} (SBCFI).  Violations of SBCFI signal a
persistent, unexpected modification of the kernel's control-flow
graph.  We performed a thorough analysis of 25 Linux rootkits and
found that 24 (96\%) employ persistent control-flow modifications; an
informal study of Windows rootkits yielded similar results.  We have
implemented SBCFI enforcement as part of the Xen and VMware virtual
machine monitors.  Our implementation detected all the control-flow
modifying rootkits we could install, while imposing unnoticeable
overhead for both a typical web server workload and CPU-intensive
workloads when operating at 10 second intervals.
},
 url = {http://www.cs.umd.edu/~mwh/papers/sbcfi.pdf},
 pages = {103--115},
 year = 2007,
 category = "Security"
}

@techreport{petroni07sbcfitr,
  author = {Petroni, Jr., Nick L. and Michael Hicks},
  title = {Automated Detection of Persistent Kernel Control-Flow Attacks},
  institution = {Department of Computer Science, University of Maryland},
  number = "CS-TR-4880",
  month = oct,
  abstract = {
This paper presents a new approach to dynamically monitoring operating
system kernel integrity, based on a property called \emph{state-based
control-flow integrity} (SBCFI).  Violations of SBCFI signal a
persistent, unexpected modification of the kernel's control-flow
graph.  We performed a thorough analysis of 25 Linux rootkits and
found that 24 (96\%) employ persistent control-flow modifications; an
informal study of Windows rootkits yielded similar results.  We have
implemented SBCFI enforcement as part of the Xen and VMware virtual
machine monitors.  Our implementation detected all the control-flow
modifying rootkits we could install, while imposing negligible
overhead for both a typical web server workload and CPU-intensive
workloads when operating at 1 second intervals on a multi-core machine.
},
 note = {Extends the CCS 2007 paper with more thorough performance results},
 url = {http://www.cs.umd.edu/~mwh/papers/CS-TR-4880.pdf},
 year = 2007,
 category = "Security"
}

@techreport{hicks07xdomtr,
  author = {Michael Hicks and Nikhil Swamy and Simon Tsang},
  title = {Toward Specifying and Validating Cross-Domain Policies},
  institution = {Department of Computer Science, University of Maryland},
  number = "CS-TR-4870",
  year = 2007,
  month = apr,
  url = "http://www.cs.umd.edu/~mwh/papers/xdom-tr.pdf",
  abstract = {
Formal security policies are extremely useful for two related reasons.
First, they allow a policy to be considered in isolation, separate
from programs under the purview of the policy and separate from the
implementation of the policy's enforcement.  Second, policies can be
checked for compliance against higher-level security goals by using
automated analyses.  By contrast, ad hoc enforcement mechanisms (for
which no separate policies are specified) enjoy neither benefit, and
non-formal policies enjoy the first but not the second.

We would like to understand how best to define
(and enforce) multi-level security policies when information must be
shared across domains that have varying levels of trust (the so-called
``cross domain'' problem).  Because we wish to show such policies meet
higher-level security goals with high assurance, we are interested in
specifying cross domain policies formally, and then reasoning about
them using automated tools.  In this report, we briefly survey
work that presents formal security policies with cross-domain
concerns, in particular with respect to the problem of
\emph{downgrading}.  We also describe correctness properties for such
policies, all based on \emph{noninterference}.  Finally, we briefly
discuss recently-developed tools for analyzing formal security
policies; though no existing tools focus on the analysis of
downgrading-oriented policies, existing research points the way
to providing such support.
},
  category = "Security"
}

@inproceedings{foster07improving,
  author = "Jeffrey S. Foster and Michael W. Hicks and William Pugh",
  title = "Improving Software Quality with Static Analysis",
  booktitle = inproc # paste,
  pages = {83--84},
  abstract = {
At the University of Maryland, we have been working to improve the
reliability and security of software by developing new, effective
static analysis tools.  These tools scan software for bug patterns
or show that the software is free from a particular class of defects.
There are two themes common to our different projects:
\begin{enumerate}
\item Our ultimate focus is on \emph{utility}: can a programmer
  actually improve the quality of his or her software using an analysis tool?
  The important first step toward answering this question is to
  engineer tools so that they can analyze existing, nontrivial
  programs, and to carefully report the results of such analyses
  experimentally.  The desire to better understand a more
  human-centered notion of utility underlies much of our
  future work.
\item We release all of our tools open
  source ({\url{http://www.cs.umd.edu/projects/PL/}}).
  This
  allows other researchers to verify our results, and to reuse some or
  all of our implementations, which often required significant
  effort to engineer.  We believe that
  releasing source code is important for accelerating the pace of
  research results software quality, and just as importantly allows
  feedback from the wider community.
\end{enumerate}
In this research group presentation, we summarize some recent work
and sketch future directions.
},
  url = {http://www.cs.umd.edu/~mwh/papers/paste41gp-foster.pdf},
  month = jun,
  year = 2007,
  category = {Static_Analysis}
}

@inproceedings{jim07beep,
  author = "Trevor Jim and Nikhil Swamy and Michael Hicks",
  title = "Defeating Scripting Attacks with Browser-Enforced Embedded Policies",
  booktitle = inproc # "International World Wide Web Conference (WWW)",
  pages = {601--610},
  month = may,
  year = 2007,
  location = "Banff, Alberta, Canada",
  optnote = "Accept rate 10/63 for this track, and 14% overall",
  url = "http://www.cs.umd.edu/~mwh/papers/jssecurity.pdf",
  abstract = {
  Web sites that accept and display content such as wiki articles or
  comments typically filter the content to prevent injected script
  code from running in browsers that view the site.  The diversity of
  browser rendering algorithms and the desire to allow rich content
  make filtering quite difficult, however, and attacks such as the
  Samy and Yamanner worms have exploited filtering weaknesses.  This
  paper proposes a simple alternative mechanism for preventing script
  injection called Browser-Enforced Embedded Policies (BEEP).  The idea is that a
  web site can embed a policy in its pages that specifies which
  scripts are allowed to run.  The browser, which knows exactly when
  it will run a script, can enforce this policy perfectly.  We have
  added BEEP support to several browsers, and built tools to
  simplify adding policies to web applications.  We found that
  supporting BEEP in browsers requires only small and localized
  modifications, modifying web applications requires minimal effort,
  and enforcing policies is generally lightweight.
  },
  category = "Security",
}

#  optinstitution = {University of Maryland, Department of Computer Science},
#  optnumber = {CS-TR-4835},

@techreport{hicks06trustedtr,
  title = {Trusted Declassification: high-level policy for a security-typed language (Extended version)},
  author = {Boniface Hicks and Dave King and Patrick McDaniel and Michael Hicks},
abstract = {
  Security-typed languages promise to be a powerful tool with which
  provably secure software applications may be developed.  Programs
  written in these languages enforce a strong, global policy of
  \emph{noninterference} which ensures that high-security data will
  not be observable on low-security channels.  Because noninterference
  is typically too strong a property, most programs use some form of
  \emph{declassification} to selectively leak high security information,
  e.g. when performing a password check or data encryption.
  Unfortunately, such a declassification is often expressed as an
  operation within a given program, rather than as part of a global
  policy, making reasoning about the security implications of a policy
  more difficult.

  In this paper, we propose a simple idea we call \textit{trusted
  declassification} in which special \emph{declassifier} functions are
  specified as part of the global policy.  In particular, individual
  principals declaratively specify which declassifiers they trust so
  that all information flows implied by the policy can be reasoned
  about in absence of a particular program.  We formalize our approach
  for a Java-like language and prove a modified form of
  noninterference which we call \emph{noninterference modulo trusted methods}.  We have implemented
  our approach as an extension to Jif and provide some of our
  experience using it to build a secure e-mail client.
},
  institution = {Department of Computer Science and Engineering, the Pennsylvania State University},
  number = {NAS-TR-033-2006},
  note = "Extended version of the PLAS 2006 paper with full formal development",
  month = "June",
  url = "http://www.cs.umd.edu/~mwh/papers/plas06-tr.pdf",
  category = "Security",
  year = 2006
}

@inproceedings{hicks06trusted,
  title = {Trusted Declassification: high-level policy for a security-typed language},
  author = {Boniface Hicks and Dave King and Patrick McDaniel and Michael Hicks},
abstract = {
  Security-typed languages promise to be a powerful tool with which
  provably secure software applications may be developed.  Programs
  written in these languages enforce a strong, global policy of
  \emph{noninterference} which ensures that high-security data will
  not be observable on low-security channels.  Because noninterference
  is typically too strong a property, most programs use some form of
  \emph{declassification} to selectively leak high security information,
  e.g. when performing a password check or data encryption.
  Unfortunately, such a declassification is often expressed as an
  operation within a given program, rather than as part of a global
  policy, making reasoning about the security implications of a policy
  more difficult.

  In this paper, we propose a simple idea we call \textit{trusted
  declassification} in which special \emph{declassifier} functions are
  specified as part of the global policy.  In particular, individual
  principals declaratively specify which declassifiers they trust so
  that all information flows implied by the policy can be reasoned
  about in absence of a particular program.  We formalize our approach
  for a Java-like language and prove a modified form of
  noninterference which we call \emph{noninterference modulo trusted methods}.  We have implemented
  our approach as an extension to Jif and provide some of our
  experience using it to build a secure e-mail client.
},
  booktitle = inproc # plas,
  month = "June",
  url = "http://www.cs.umd.edu/~mwh/papers/plas06-final-dist.pdf",
  optnote = "accept rate 10/18",
  category = "Security",
  pages = {65--74},
  year = 2006
}

@inproceedings{hicks06atomic,
  title = {Inferring Locking for Atomic Sections},
  author = {Michael Hicks and Jeffrey S. Foster and Polyvios Pratikakis},
  booktitle = {On-line Proceedings of the ACM SIGPLAN Workshop on Languages, Compilers, and Hardware Support for Transactional Computing (TRANSACT)},
  abstract = {
  Software transactions allow the programmer to specify sections of
  code that should be serializable, without the programmer needing to
  worry about exactly how atomicity is enforced.  Recent research
  proposes using optimistic concurrency to implement transactions.  In
  this short paper, we propose a pessimistic lock-based technique that
  uses the results of static whole-program analysis to enforce
  atomicity.  The input to our analysis is a program that contains
  programmer-specified atomic sections and calls to fork.  We present
  a sharing inference algorithm that uses the results of points-to
  analysis to determine which memory locations are shared.  Our
  analysis uses \emph{continuation effects} to track the locations
  accessed after a point in the program.  This allows data to be
  thread-local before a fork and thread-shared afterward.  We then
  present a mutex inference algorithm that determines a sufficient set
  of locks to guard accesses to shared locations.  After mutex
  inference, a compiler adds the appropriate lock acquires and
  releases to the beginning and end of atomic sections.  Our algorithm
  is efficient, and provides parallelism according to precision of the
  alias analysis while minimizing the number of required locks.
},
  url = "http://www.cs.umd.edu/~mwh/papers/infatomic.pdf",
  note = "\url{http://www.cs.purdue.edu/homes/jv/events/TRANSACT/transact-06.tgz}",
  year = 2006,
  month = jun,
  category = "Multithreaded_Programming",
}

@inproceedings{srivastava07cmod,
  title = "Modular Information Hiding and Type Safety for {C}",
  author = "Saurabh Srivastava and Michael Hicks and Jeffrey S. Foster",
  booktitle = inproc # tldi,
  pages = {3--14},
  abstract = {
  This paper presents CMod, a novel tool that provides a sound
  module system for C\@.  CMod works by enforcing a set of four rules
  that are based on principles of modular reasoning and on current
  programming practice.  CMod's rules flesh out the convention that
  \texttt{.h} header files are module interfaces and \texttt{.c}
  source files are module implementations.  Although this convention
  is well-known, developing CMod's rules revealed there are many
  subtleties in applying the basic pattern correctly.  We have proven
  formally that CMod's rules enforce both information hiding and
  type-safe linking.
  We evaluated CMod on a number of benchmarks, and found
  that most programs obey CMod's rules, or can be made to with
  minimal effort, while rule violations reveal brittle coding practices
  including numerous information hiding violations and occasional type errors.
},
  month = "January",
  year = 2007,
  optnote = "accept rate 6/12",
  url = {http://www.cs.umd.edu/~mwh/papers/cmod.pdf},
  http = {http://www.cs.umd.edu/~saurabhs/CMod/},
  category = "Safe_Low-Level_Programming",
}

@techreport{srivastava06cmodtr,
  title = "Defining and Enforcing {C}'s Module System",
  author = "Saurabh Srivastava and Michael Hicks and Jeffrey S. Foster and Bhargav Kanagal",
  abstract = {
  Programming language module systems are an important tool for
  managing the complexity of large software systems.  The C
  programming language is used to build many such systems, yet it
  lacks a proper module system.  Instead, C programmers typically
  follow a convention that treats \texttt{.h} header files as
  interfaces and \texttt{.c} source files as modules.  This
  convention can be effective, but there are many subtleties in using
  it correctly, and the compiler and linker provide no enforcement
  mechanism.  As a result, misuse of the convention can lead to
  hard-to-find bugs, can make reasoning about code in isolation more
  difficult, and can complicate future code maintenance.

  This paper presents {\sc CMod}, a module system for C that ensures
  abstraction via information hiding and type-safe separate compilation.  Our
  approach is to identify and enforce the circumstances under
  which C's current modular programming convention is sound.  The result is
  four rules that, using an operational semantics for an
  idealized preprocessor, we have proven are sufficient to guarantee
  the desired modularity properties.  We have implemented {\sc CMod} for the
  full C language and applied it to a number of benchmarks.  We found
  that most of the time legacy programs obey {\sc CMod}'s rules, or can be
  made to with minimal effort, and rule violations often result in
  type errors or brittle code.  Thus {\sc CMod} brings the benefits of
  modular programming to C while still supporting
  legacy systems.
},
  institution = {Department of Computer Science, University of Maryland},
  number = "CS-4816",
  month = "July",
  year = 2006,
  url = {http://www.cs.umd.edu/~mwh/papers/cmod-tr.pdf},
  http = {http://www.cs.umd.edu/~saurabhs/CMod/},
  category = "Safe_Low-Level_Programming",
}

@techreport{swamy06rxtr,
  title = "Managing Policy Updates in Security-Typed Languages (Extended version)",
author = "Nikhil Swamy and Michael Hicks and Stephen Tse and Steve Zdancewic",
  abstract = {
This paper presents RX, a new security-typed
programming language with features intended to make the management of
information-flow policies more practical.  Security labels in RX,
in contrast to prior approaches, are defined in terms of \emph{owned
roles}, as found in the RT role-based trust-management framework.
Role-based security policies allows flexible delegation, and our
language RX provides constructs through which programs can robustly
update policies and react to policy updates dynamically.  Our dynamic
semantics use statically verified \emph{transactions} to eliminate
illegal information flows across updates, which we call
\emph{transitive flow}.  Because policy updates can be observed
through dynamic queries, policy updates can potentially reveal
sensitive information.  As such, RX considers policy statements
themselves to be potentially confidential information and subject to
information-flow \emph{metapolicies}.
},
  institution = {Department of Computer Science, University of Maryland},
  number = "CS-TR-4793",
  month = "August",
  year = 2006,
  note = {Extends CSFW version to include full proofs and additional
discussion about metapolicies},
  url = {http://www.cs.umd.edu/~mwh/papers/rx-tr.pdf},
  http = {http://www.cs.umd.edu/projects/PL/rx/},
  category = "Security",
}

@inproceedings{swamy06rx,
  title = "Managing Policy Updates in Security-Typed Languages",
author = "Nikhil Swamy and Michael Hicks and Stephen Tse and Steve Zdancewic",
  booktitle = inproc # "Computer Security Foundations Workshop (CSFW)",
  abstract = {
This paper presents RX, a new security-typed
programming language with features intended to make the management of
information-flow policies more practical.  Security labels in RX,
in contrast to prior approaches, are defined in terms of \emph{owned
roles}, as found in the RT role-based trust-management framework.
Role-based security policies allows flexible delegation, and our
language RX provides constructs through which programs can robustly
update policies and react to policy updates dynamically.  Our dynamic
semantics use statically verified \emph{transactions} to eliminate
illegal information flows across updates, which we call
\emph{transitive flow}.  Because policy updates can be observed
through dynamic queries, policy updates can potentially reveal
sensitive information.  As such, RX considers policy statements
themselves to be potentially confidential information and subject to
information-flow \emph{metapolicies}.
},
  month = "July",
  pages = "202--216",
  optnote = "25/96 accept rate",
  year = 2006,
  url = {http://www.cs.umd.edu/~mwh/papers/rx.pdf},
  http = {http://www.cs.umd.edu/projects/PL/rx/},
  category = "Security",
}

@inproceedings{pratikakis06exists,
  author = {Polyvios Pratikakis and Jeffrey S. Foster and Michael Hicks},
  title = {Existential Label Flow Inference via {CFL} Reachability},
  booktitle = inproc # sas,
  year = 2006,
  month = aug,
  publisher = "Springer-Verlag",
  editor = {Kwangkeun Yi},
  series = "Lecture Notes in Computer Science",
  volume = "4134",
  pages = {88--106},
  url = "http://www.cs.umd.edu/~mwh/papers/existsflow.pdf",
  abstract = {
  In programming languages, existential quantification is useful for
  describing relationships among members of a structured type.  For
  example, we may have a list in which there \emph{exists} some
  mutual exclusion lock $l$ in each list element such that $l$
  protects the data stored in that element.
  With this information, a static analysis can reason
  about the relationship between locks and locations in the list even
  when the precise identity of the lock and/or location is unknown.
  To facilitate the construction of such static analyses, this paper
  presents a context-sensitive \emph{label flow analysis} algorithm with
  support
  for existential quantification.  Label flow analysis is a core part
  of many static analysis systems.  Following Rehof et al, we use context-free
  language (CFL) reachability to develop an efficient $O(n^3)$
  label flow inference algorithm.  We prove the algorithm sound by reducing its
  derivations to those in a system based on
  polymorphically-constrained types, in the style of Mossin.  We have
  implemented a variant of our analysis as part of a data race detection
  tool for C programs.
},
  category = "Static_Analysis",
  optnote = {accept rate 23/80}
}

@techreport{pratikakis05existstr,
  author = {Polyvios Pratikakis and Michael Hicks and Jeffrey S. Foster},
  title = {Existential Label Flow Inference via {CFL} Reachability (Extended Version)},
  institution = {Department of Computer Science, University of Maryland},
  number = "CS-TR-4700",
  year = 2005,
  month = jul,
  url = "http://www.cs.umd.edu/~mwh/papers/existsflow-tr.pdf",
  abstract = {
  Label flow analysis is a fundamental static analysis problem with a
  wide variety of applications.  Previous work by Mossin developed a
  polynomial time subtyping-based label flow inference that supports
  Hindley-Milner style polymorphism with polymorphic recursion.  Rehof
  et al have developed an efficient $O(n^3)$ inference algorithm for
  Mossin's system based on context-free language (CFL) reachability.
  In this paper, we extend these results to a system that also
  supports existential polymorphism, which is important for precisely
  describing correlations among members of a structured type, even
  when values of that type are part of dynamic data structures.  We
  first develop a provably sound checking system based on
  polymorphically-constrained types.  As usual, we restrict universal
  quantification to the top level of a type, but existential
  quantification is first class, with subtyping allowed between
  existentials with the same binding structure.  We then develop a
  CFL-based inference system.  Programmers specify which positions in
  a type are existentially quantified, and the algorithm infers the
  constraints bound in the type, or rejects a program if the
  annotations are inconsistent.
},
  category = "Static_Analysis"
}

@article{ swamy05experience,
  author = 	 {Nikhil Swamy and Michael Hicks and Greg Morrisett and Dan Grossman and Trevor Jim},
  title = 	 {Safe Manual Memory Management in {Cyclone}},
  journal =    scp,
  volume = 62,
  number = 2,
  month = oct,
  pages = {122--144},
  year = 2006,
  abstract = {
  The goal of the Cyclone project is to investigate how to make a
  low-level C-like language safe.  Our most difficult challenge has
  been providing programmers control over memory management while
  retaining safety.  This paper describes our experience trying
  to integrate and use effectively two previously-proposed, safe
  memory-management mechanisms: statically-scoped regions and tracked
  pointers.  We found that these typing mechanisms can be combined to
  build alternative memory-management abstractions, such as reference
  counted objects and arenas with dynamic lifetimes, and thus provide
  a flexible basis.  Our experience---porting C programs and device
  drivers, and building new applications for resource-constrained
  systems---confirms that experts can use these features to improve
  memory footprint and sometimes to improve throughput when used
  instead of, or in combination with, conservative garbage collection.
  },
  note =         {Special issue on memory management. Expands ISMM conference paper of the same name},
  publisher = "Elsevier",
  url = "http://www.cs.umd.edu/~mwh/papers/cyc-mm-scp.pdf",
  http = {http://cyclone.thelanguage.org},
  category = "Memory_Management"
}

@misc{despande05dbupdate,
  author = "Amol Deshpande and Michael Hicks",
  title = "Toward On-line Schema Evolution for Non-stop Systems",
  howpublished = "Presented at the 11th High Performance Transaction Systems Workshop",
  month = "September",
  location = "Pacific Grove, CA",
  category = "Dynamic_Software_Updating",
  url = "http://www.cs.umd.edu/~mwh/papers/db-dsu.pdf",
  abstract = {
    Considers how to perform handle database schema evolution for on-line systems that are actively using the database whose schema is to be changed.
  },
  year = 2005,
}

@inproceedings{hicks05secupdate,
  author = "Michael Hicks and Stephen Tse and Boniface Hicks and Steve Zdancewic",
  title = "Dynamic Updating of Information-Flow Policies",
  booktitle = inproc # "International Workshop on Foundations of Computer Security (FCS)",
  abstract = {
Applications that manipulate sensitive information should ensure
\emph{end-to-end} security by satisfying two properties:
\emph{sound execution} and some form of \emph{noninterference}.  By
the former, we mean the program should always perform actions in
keeping with its current policy, and by the latter we mean that these
actions should never cause high-security information to be visible to
a low-security observer.  Over the last decade, security-typed
languages have been developed that exhibit these properties,
increasingly improving so as to model important features of real
programs.
No current security-typed language, however, permits general changes
to security policies in use by running programs.  This paper presents
a simple information flow type system that allows for dynamic
security policy updates while ensuring sound execution and a relaxed
form of noninterference we term
\emph{noninterference between updates}.  We see this work as an
important step toward using language-based techniques to ensure
end-to-end security for realistic applications.
  },
  month = "June",
  pages = "7--18",
  location = "Chicago, IL",
  year = "2005",
  url = "http://www.cs.umd.edu/~mwh/papers/secupdate.pdf",
  category = "Security",
  optnote = "accept = 11/30",
}

@article{grossman04cuj,
  author = "Dan Grossman and Michael Hicks and Trevor Jim and Greg Morrisett",
  title = "Cyclone: a Type-safe Dialect of {C}",
  journal = "{C/C++} Users Journal",
  volume = 23,
  number = 1,
  month = "January",
  year = 2005,
  abstract = {
Cyclone is an effort to bring safety to C.  This article briefly
introduces Cyclone.
  },
  http = {http://cyclone.thelanguage.org},
  url = "http://www.cs.umd.edu/~mwh/papers/cyclone-cuj.pdf",
  url = "http://www.ddj.com/article/printableArticle.jhtml?articleID=184401896&dept_url=/dept/cpp/",
  category = "Safe_Low-Level_Programming"
}

@inproceedings{neamtiu05evolution,
  author = "Iulian Neamtiu and Jeffrey S. Foster and Michael Hicks",
  title = "Understanding Source Code Evolution Using Abstract Syntax Tree Matching",
  booktitle = inproc # "International Workshop on Mining Software Repositories (MSR)",
  pages = {1--5},
  abstract = {
Mining software repositories at the source code level can provide a
greater understanding of how software evolves.
We present a tool for quickly comparing the source code of different
versions of a C program.  The approach is based on partial abstract
syntax tree matching, and can track simple
changes to global variables, types and functions.  These changes can
characterize aspects of software evolution useful for answering higher
level questions.  In particular, we consider how they could be used to
inform the design of a dynamic software updating system.
We report results based on measurements of various versions of
popular open source
programs, including BIND, OpenSSH, Apache, Vsftpd and the Linux kernel.
  },
  category = "Dynamic_Software_Updating",
  month= "May",
  year = 2005,
  http = {http://www.cs.umd.edu/projects/dsu/},
  url = "http://www.cs.umd.edu/~mwh/papers/evolution.pdf",
  optnote = {accept rate 22/38}
}

@TECHREPORT{neamtiu06dsutr,
  AUTHOR = { Iulian Neamtiu and Michael Hicks and Gareth Stoyle and Manuel Oriol},
  TITLE = {Practical Dynamic Software Updating for {C} (Extended version)},
  INSTITUTION = {Department of Computer Science, University of Maryland},
  NUMBER = {CS-TR-4790},
  YEAR = 2006,
  MONTH = {March},
  NOTE = {Extended version of PLDI 06 paper},
  http = {http://www.cs.umd.edu/projects/dsu/},
  category = "Dynamic_Software_Updating",
}

@techreport{pratikakis06locksmithtr,
  title = "Context-sensitive Correlation Analysis for Detecting Races (Extended version)",
  author = "Polyvios Pratikakis and Jeffrey S. Foster and Michael Hicks",
  INSTITUTION = {Department of Computer Science, University of Maryland},
  number = {CS-TR-4789},
  abstract = {
One common technique for preventing data races in multi-threaded
programs is to ensure that all accesses to shared locations are
consistently protected by a lock.  We present a tool called Locksmith
for detecting data races in C programs by looking for violations of
this pattern.  We call the relationship between locks and the
locations they protect consistent correlation, and the core of our
technique is a novel constraint-based analysis that infers
consistent correlation context-sensitively, using the results to check that
locations are properly guarded by locks.  We present the core of
our algorithm for a simple formal language \emph{lambda-corr} which we have
proven sound, and discuss how we scale it up to an algorithm that
aims to be sound for all of C.
We develop several techniques to improve the precision and
performance of the analysis, including a sharing analysis for
inferring thread locality; existential quantification for modeling
locks in data structures; and heuristics for modeling unsafe
features of C such as type casts.  When applied to several
benchmarks, including multi-threaded servers and Linux device
drivers, Locksmith found several races while producing a modest
number of false alarms.
},
  note = "Extends PLDI 2006 paper with full formal development",
  url = {http://www.cs.umd.edu/~mwh/papers/locksmith-tr.pdf},
  month = "June",
  year = 2006,
  category = "Multithreaded_Programming",
}

@inproceedings{pratikakis06locksmith,
  title = "Context-sensitive Correlation Analysis for Detecting Races",
  booktitle = inproc # pldi,
  author = "Polyvios Pratikakis and Jeffrey S. Foster and Michael Hicks",
  abstract = {
One common technique for preventing data races in multi-threaded
programs is to ensure that all accesses to shared locations are
consistently protected by a lock.  We present a tool called Locksmith
for detecting data races in C programs by looking for violations of
this pattern.  We call the relationship between locks and the
locations they protect consistent correlation, and the core of our
technique is a novel constraint-based analysis that infers
consistent correlation context-sensitively, using the results to check that
locations are properly guarded by locks.  We present the core of
our algorithm for a simple formal language \emph{lambda-corr} which we have
proven sound, and discuss how we scale it up to an algorithm that
aims to be sound for all of C.
We develop several techniques to improve the precision and
performance of the analysis, including a sharing analysis for
inferring thread locality; existential quantification for modeling
locks in data structures; and heuristics for modeling unsafe
features of C such as type casts.  When applied to several
benchmarks, including multi-threaded servers and Linux device
drivers, Locksmith found several races while producing a modest
number of false alarms.
},
  pages = {320--331},
  location = {Ottawa, Canada},
  url = {http://www.cs.umd.edu/~mwh/papers/locksmith.pdf},
  http = {http://www.cs.umd.edu/~polyvios/locksmith/},
  month = "June",
  year = 2006,
  category = "Multithreaded_Programming",
  optnote = {Accept rate 36/174},
}

@inproceedings{neamtiu06dsu,
  author = "Iulian Neamtiu and Michael Hicks and Gareth Stoyle and Manuel Oriol",
  title = "Practical Dynamic Software Updating for {C}",
  booktitle = inproc # pldi,
  pages = {72--83},
  location = {Ottawa, Canada},
  month = "June",
  year = "2006",
  abstract = {
Software updates typically require stopping and restarting an
application, but many systems cannot afford to halt service, or would
prefer not to.  \emph{Dynamic software updating} (DSU) addresses this
difficulty by permitting programs to be updated while they run.  DSU
is appealing compared to other approaches for on-line upgrades because
it is quite general and requires no redundant hardware.  The challenge
is in making DSU \emph{practical}: it should be flexible, and yet
safe, efficient, and easy to use.

In this paper, we present Ginseng, a DSU implementation for C that aims to
meet this challenge.  We compile programs specially so that they can
be dynamically patched, and generate most of a dynamic patch
automatically.  Ginseng performs a series of analyses that when
combined with some simple runtime support ensure that an update will
not violate type-safety while guaranteeing that data is kept
up-to-date.  We have used Ginseng to construct and dynamically
apply patches to three substantial open-source server
programs---\emph{Very Secure FTP daemon}, \emph{OpenSSH sshd daemon}, and
\emph{GNU Zebra}.  In total, we dynamically patched each program with
three years' worth of releases.  Though the programs changed
substantially, the majority of updates were easy to generate.
Performance experiments show that all patches could be applied in less
than 5 $ms$, and that the overhead on application throughput due to
updating support ranged from 0 to at most 32\%.
},
  http = {http://www.cs.umd.edu/projects/dsu/},
  category = "Dynamic_Software_Updating",
  optnote = {Accept rate 36/174},
  url = {http://www.cs.umd.edu/~mwh/papers/ginseng.pdf}
}

@inproceedings{oriol05tset,
  title = "Tagged Sets: a Secure and Transparent Coordination Medium",
  author = "Manuel Oriol and Michael Hicks",
  booktitle = inproc # coord,
  abstract = {
A simple and effective way of coordinating distributed, mobile, and
parallel applications is to use a virtual shared memory (VSM), such as
a Linda tuple-space.  In this paper, we propose a new kind of VSM,
called a \emph{tagged set}.  Each element in the VSM is a value with
an associated tag, and values are read or removed from the VSM by
matching the tag.  Tagged sets exhibit three properties useful for
VSMs:
\begin{enumerate}
\item \emph{Ease of use}. A tagged value naturally corresponds to the
  notion that data has certain attributes, expressed by the tag, which
  can be used for later retrieval.

\item \emph{Flexibility}. Tags are implemented as propositional logic
  formulae, and selection as logical implication, so the resulting
  system is quite powerful.  Tagged sets naturally support a variety
  of applications, such as shared data repositories (e.g., for media
  or e-mail), message passing, and publish/subscribe algorithms;
  they are powerful enough to encode existing VSMs,
  such as Linda spaces.

\item \emph{Security}.  Our notion of tags naturally corresponds to
  keys, or capabilities: a user may not select data in the set unless
  she presents a legal key or keys.  Normal tags correspond to
  symmetric keys, and we introduce \emph{asymmetric tags} that
  correspond to public and private key pairs.  Treating tags as keys
  permits users to easily specify protection criteria for data at a
  fine granularity.
\end{enumerate}
This paper motivates our approach, sketches its basic theory, and
places it in the context of other data management strategies.
},
  month = "April",
  location = "Namur, Belgium",
  year = "2005",
  optnote = "accept rate 19/88",
  url = "http://www.cs.umd.edu/~mwh/papers/tsets.pdf",
  publisher = "Springer-Verlag",
  editor = "Jean-Marie Jacquet and Gian Pietro Picco",
  series = "Lecture Notes in Computer Science",
  volume = "3454",
  pages = "252--267",
  category = "Distributed_Programming"
}

@inproceedings{papageorgiou04probe,
  title = "Merging Network Measurement with Data Transport (Extended Abstract)",
  author = "Pavlos Papageorgiou and Michael Hicks",
  booktitle = inproc # pam,
  journal = {Lecture Notes in Computer Science},
  volume = 3431,
  publisher = "Springer-Verlag",
  optnote = "Accept rate 36/84 (12 abstracts, 24 full papers)",
  month = "March",
  where = "Boston, USA",
  year = "2005",
  abstract = {
The tasks of measurement and data transport are often treated
independently, but we believe there are benefits to bringing them
together.  This paper proposes the simple idea of a transport agent
to encapsulate useful data within probe packets in place of
useless padding.
},
  url = "http://www.cs.umd.edu/~mwh/papers/probe-transport.pdf",
  pages = "368--371",
  category = "Programmable_Networks"
}

@misc{KeromytisEPH04,
  author = "Angelos D. Keromytis and Stephen Edwards and Vassilis Prevelakis and Michael W. Hicks",
  title = "Open and Survivable Embedded Systems",
  month = "February",
  year = "2004",
  url = "http://www.cis.upenn.edu/~mwh/papers/oases_position.ps.gz",
  note = "Submitted for publication",
  omitfromweb = "yes",
  category = "Dynamic_Software_Updating"
}

@article{StoyleHBSN06,
  author = "Gareth Stoyle and Michael Hicks and Gavin Bierman and Peter Sewell and Iulian Neamtiu",
  title = "\emph{Mutatis Mutandis}: Safe and Flexible Dynamic Software Updating (full version)",
abstract = {
This paper presents Proteus, a core calculus that models dynamic
software updating, a service for fixing bugs and adding features to a
running program.  Proteus permits a program's type structure to change
dynamically but guarantees the updated program remains type-correct by
ensuring a property we call ``con-freeness.''  We show how con-freeness
can be enforced dynamically, and how it can be approximated via a
novel static analysis.  This analysis can be used to assess the
implications of a program's structure on future updates, to make
update success more predictable.  We have implemented Proteus for C,
and briefly discuss our implementation, which we have tested on
several well-known programs.
},
  volume = 29,
  number = 4,
  journal = toplas,
  note = {Full version of POPL 05 paper},
  url = {http://www.cs.umd.edu/~mwh/papers/mutatis-journal.pdf},
  year = 2007,
  month = aug,
  category = "Dynamic_Software_Updating",
}

@InProceedings{StoyleHBSN05,
  author = "Gareth Stoyle and Michael Hicks and Gavin Bierman and Peter Sewell and Iulian Neamtiu",
  title = "\emph{Mutatis Mutandis}: Safe and Flexible Dynamic Software Updating",
  booktitle = inproc # popl,
  pages = {183--194},
  url = "http://www.cs.umd.edu/~mwh/papers/proteus-popl.pdf",
  month = "January",
  year = "2005",
  where = "Long Beach, California",
  abstract = {
Dynamic software updates can be used to fix bugs or add features to a
running program without downtime.  Essential for some applications and
convenient for others, low-level dynamic updating support has been
used for many years.  However, there is little high-level
understanding that would support programmers in writing dynamic
updates effectively.

In an effort to bridge this gap, we present a formal calculus called
Proteus for modeling dynamic software updating in C-like languages
that is flexible, safe, and predictable.  Proteus supports dynamic
updates to functions (even those that are active) and types, allowing
on-line evolution to match source-code evolution as we have observed
it in practice.  All updates are provably type-safe and
\emph{representation-consistent}, meaning that only one version of a given
type may exist in the program at any time, simplifying reasoning and
avoiding unintuitive copy-based semantics.  Finally, Proteus's novel
and efficient static \emph{updateability analysis} allows a programmer to
automatically prove that an update is independent of the on-line
program state, and thus predict it will not fail dynamically.  Proteus
admits a straightforward implementation, and we sketch how it could be
extended to more advanced language features including threads.
  },
  optnote = "accept rate 31/172",
  category = "Dynamic_Software_Updating",
}

@inproceedings{ pratikakis04transparent,
  author = 	 {Polyvios Pratikakis and Jaime Spacco and Michael Hicks},
  title = 	 {Transparent Proxies for {Java} Futures},
  booktitle =	 inproc # oopsla,
  month =	 {October},
  year =	 2004,
  where =	 {Vancouver, Canada},
  abstract = {
A \emph{proxy} object is a surrogate or placeholder that controls access to
another target object.  Proxies can be used to support distributed
programming, lazy or parallel evaluation, access control, and other simple
forms of behavioral reflection.  However, \emph{wrapper proxies}
(like \emph{futures} or \emph{suspensions} for yet-to-be-computed results)
can require significant code changes to be used in statically-typed
languages, while proxies more generally can inadvertently violate
assumptions of transparency, resulting in subtle bugs.

To solve these problems, we have designed and implemented a simple framework
for proxy programming that employs a static analysis based on qualifier
inference, but with additional novelties.  Code for
using wrapper proxies is automatically introduced via a
classfile-to-classfile transformation, and potential violations of
transparency are signaled to the programmer.  We have formalized our
analysis and proven it sound.  Our framework has a variety of applications,
including support for asynchronous method calls returning futures.
Experimental results demonstrate the benefits of our framework: programmers
are relieved of managing and/or checking proxy usage, analysis times are
reasonably fast, overheads introduced by added dynamic checks are
negligible, and performance improvements can be significant.  For example,
changing two lines in a simple RMI-based peer-to-peer application and then
using our framework resulted in a large performance gain.
},
  pages = {206--223},
  optnote = "accept rate 27/173",
  url = {http://www.cs.umd.edu/~mwh/papers/transparent-proxies.pdf},
  category = "Multithreaded_Programming",
}

@techreport{ pratikakis04transparentTR,
  author = 	 {Polyvios Pratikakis and Jaime Spacco and Michael Hicks},
  title = 	 {Transparent Proxies for {Java} Futures (Extended version)},
  month =	 {October},
  year =	 2004,
  where =	 {Vancouver, Canada},
  abstract = {
A \emph{proxy} object is a surrogate or placeholder that controls access to
another target object.  Proxies can be used to support distributed
programming, lazy or parallel evaluation, access control, and other simple
forms of behavioral reflection.  However, \emph{wrapper proxies}
(like \emph{futures} or \emph{suspensions} for yet-to-be-computed results)
can require significant code changes to be used in statically-typed
languages, while proxies more generally can inadvertently violate
assumptions of transparency, resulting in subtle bugs.

To solve these problems, we have designed and implemented a simple framework
for proxy programming that employs a static analysis based on qualifier
inference, but with additional novelties.  Code for
using wrapper proxies is automatically introduced via a
classfile-to-classfile transformation, and potential violations of
transparency are signaled to the programmer.  We have formalized our
analysis and proven it sound.  Our framework has a variety of applications,
including support for asynchronous method calls returning futures.
Experimental results demonstrate the benefits of our framework: programmers
are relieved of managing and/or checking proxy usage, analysis times are
reasonably fast, overheads introduced by added dynamic checks are
negligible, and performance improvements can be significant.  For example,
changing two lines in a simple RMI-based peer-to-peer application and then
using our framework resulted in a large performance gain.
},
  number = {CS-TR-4574},
  institution = {University of Maryland, Department of Computer Science},
  url = {http://www.cs.umd.edu/~mwh/papers/proxies-tr.pdf},
  category = "Multithreaded_Programming",
}


@inproceedings{ hicks04experience,
  author = 	 {Michael Hicks and Greg Morrisett and Dan Grossman and Trevor Jim},
  title = 	 {Experience with Safe Manual Memory Management in {Cyclone}},
  booktitle = 	 inproc # ismm,
  note = 	 {An abstract of this paper appeared in SPACE `04, \url{http://www.diku.dk/topps/space2004/space_final/hicks-grossman-jim.pdf}},
  abstract = {
  The goal of the Cyclone project is to investigate
  type safety for low-level languages such as C\@.  Our
  hardest challenge has been providing programmers control over memory
  management while retaining type safety.  This paper reports on our
  experience trying to integrate and effectively use two previously
  proposed, type-safe memory management mechanisms: statically-scoped regions
  and unique pointers.  We found that these typing mechanisms can be combined
  to build alternative memory-management abstractions, such as reference
  counted objects and arenas with dynamic lifetimes, and thus provide
  a flexible basis.  Our experience---porting C code and building new
  applications for resource-constrained systems---confirms that experts can use
  these features to improve memory footprint and
  sometimes to improve
  throughput when used instead of, or in combination with, a conservative
  garbage collector.
},
  url = {http://www.cs.umd.edu/~mwh/papers/ismm.pdf},
  http = {http://cyclone.thelanguage.org},
  month = "October",
  year = 2004,
  pages = {73--84},
  optnote = "accept rate 15/43",
  category = "Memory_Management"
}

@article{ rose05scp,
  author =     {James Rose and Nikhil Swamy and Michael Hicks},
  title =      {Dynamic Inference of Polymorphic Lock Types},
  journal =    scp,
  volume = 58,
  number = 3,
  pages = {366--383},
  month = "December",
  year = 2005,
  note =         "Special Issue on Concurrency and Synchronization in Java programs.  Supercedes 2004 CSJP paper of the same name.",
  publisher = "Elsevier",
  category = "Multithreaded_Programming",
  url = {http://www.cs.umd.edu/~mwh/papers/dynamic-locktypes-scp.pdf}
}

@inproceedings{ rose04dynamic,
  author = 	 {James Rose and Nikhil Swamy and Michael Hicks},
  title = 	 {Dynamic Inference of Polymorphic Lock Types},
  booktitle =	 inproc # podc # " " # csjp,
  pages = {18--25},
  abstract = {
We present an approach for automatically proving the absence of race
conditions in multi-threaded Java programs, using a combination of
dynamic and static analysis.  The program in question is instrumented
so that when executed it will gather information about locking
relationships.  This information is then fed to our tool, {\sc FindLocks},
that generates annotations needed to type check the program using the
Race-Free Java type system.  Our approach
extends existing inference algorithms by being fully
context-sensitive.  We describe the design and implementation of our
approach, and our experience applying the tool to a variety of Java
programs.  In general, we have found the approach works well, but has
trouble scaling to large programs, which require extensive testing for
full coverage.
},
  url = {http://www.cs.umd.edu/~mwh/papers/dynamic-locktypes.pdf},
  month = "July",
  year = 2004,
  category = "Multithreaded_Programming"
}


@techreport{ hicks03safe,
  author = "Michael Hicks and Greg Morrisett and Dan Grossman and Trevor Jim",
  title = "Safe and Flexible Memory Management in {Cyclone}",
  number = "CS-TR-4514",
  institution = "University of Maryland Department of Computer Science",
  month = "July",
  year = "2003",
  url = "http://www.cs.umd.edu/~mwh/papers/CS-TR-4514.pdf",
  abstract = {
Cyclone is a type-safe programming language intended for applications
requiring control over memory management.  Our previous work on
Cyclone included support for stack allocation, lexical region
allocation, and a garbage-collected heap.  We achieved safety (i.e.,
prevented dangling pointers) through a region-based type-and-effects
system.  This paper describes some new memory-management mechanisms
that we have integrated into Cyclone: dynamic regions, unique
pointers, and reference-counted objects.  Our experience shows that
these new mechanisms are well suited for the timely recovery of
objects in situations where it is awkward to use lexical regions.
Crucially, programmers can write reusable functions without
unnecessarily restricting callers' choices among the variety of
memory-management options. To achieve this goal, Cyclone employs a
combination of polymorphism and scoped constructs that temporarily let
us treat objects as if they were allocated in a lexical region.  In
our experience, our new constructs can significantly improve
application performance, while adding a modest programming overhead.
  },
  http = {http://cyclone.thelanguage.org},
  category = "Memory_Management",
}

# Also published as University of Maryland Institute for Advanced Computer Studies (UMIACS) Technical report UMIACS-TR-2003-82

@article{ HicksNettles03,
  author = "Michael Hicks and Scott M. Nettles",
  title = "Dynamic Software Updating",
  journal = toplas,
  year = 2005,
  month = "November",
  volume = {27},
  number = {6},
  pages = {1049--1096},
  optnote = "Submitted November 2003.  Revised May 2004. Accepted September 2004",
  abstract = {
Many important applications must run continuously and without interruption,
yet must be changed to fix bugs or upgrade functionality.  No
prior general-purpose methodology for dynamic updating achieves a practical
balance between flexibility, robustness, low overhead, and ease of use.

We present an approach for C-like languages that provides type-safe dynamic
updating of native code in an extremely flexible manner (code, data, and
types may be updated, at programmer-determined times) and permits the use of
automated tools to aid the programmer in the updating process.  Our system
is based on dynamic patches that contain both the updated code and the code
needed to transition from the old version to the new.  A novel aspect of our
patches is that they consist of verifiable native code (e.g. Proof-Carrying
Code or Typed Assembly Language), which is native code accompanied by
annotations that allow on-line verification of the code's safety.  We
discuss how patches are generated mostly automatically, how they are applied
using dynamic-linking technology, and how code is compiled to make it
updateable.

To concretely illustrate our system, we have implemented a
dynamically-updateable web server, FlashEd.  We discuss our experience
building and maintaining FlashEd, and generalize to present observations
about updateable software development.  Performance experiments show that
for FlashEd, the overhead due to updating is low: typically less than 1
percent.
},
  url = {http://doi.acm.org/10.1145/1108970.1108971},
  optnote = "http://www.cs.umd.edu/~mwh/papers/dynupd-toplas.pdf",
  category = "Dynamic_Software_Updating",
}

@misc{ HicksKMGN03,
  author =       "Michael Hicks and Pankaj Kakkar and Jonathan T. Moore
  and Carl A. Gunter and Scott Nettles",
  title =        "{PLAN}: A Packet Language for Active Networks",
  note = "Under revision",
  omitfromweb = "yes",
  url = "http://www.cs.umd.edu/~mwh/papers/plan-journal.pdf",
  abstract = {
PLAN (Packet Language for Active Networks) is a new language for programs
that form the packets of a programmable network.  These programs replace the
packet headers (which can be viewed as very rudimentary programs) used in
current networks.  As such, PLAN programs need to be lightweight and of
restricted functionality.  These limitations are mitigated by allowing PLAN
code to call node-resident \textit{service routines} written in other, more
powerful languages.  This two-level architecture, in which PLAN serves as a
scripting or `glue' language for more general services, is the primary
contribution of this paper. We have successfully applied the PLAN
programming environment to implement an IP-free internetwork.

PLAN is based on the polymorphic lambda calculus and provides a restricted
set of primitives and datatypes.  PLAN defines a special construct called a
\emph{chunk} used to describe the remote execution of PLAN programs on
other nodes. Primitive operations on chunks are used to provide basic data
transport in the network and to support layering of protocols.  Remote
execution can make debugging difficult, so PLAN provides strong static
guarantees to the programmer, such as type safety.  A more novel property
aimed at protecting network availability is a guarantee that PLAN programs
use a bounded amount of network resources.
  },
  category = "Programmable_Networks",
}

@Article{HicksKS03,
  author =       "Michael Hicks and Angelos D. Keromytis and Jonathan M. Smith",
  title =        "A Secure {PLAN}",
  journal =      "{IEEE Transactions on Systems, Man, and Cybernetics, Part C}",
  month = "August",
  volume = 33,
  number = 3,
  pages = {413--426},
  year =         2003,
  note =         {Special Issue on Technologies Promoting Computational Intelligence, Openness and Programmability in Networks and {I}nternet Services, Part {I}},
  url = "http://www.cs.umd.edu/~mwh/papers/plansecurity.pdf",
  abstract = {
Active Networks, being programmable,
promise greater flexibility than current networks.
Programmability, however, may
introduce safety and security risks.
This paper describes the design and implementation of a security
architecture for the active network PLANet.
Security is obtained with a two-level architecture that combines a
functionally restricted packet language, PLAN, with
an environment of general-purpose service routines governed by trust
management.  In particular, a technique is used
which expands or contracts a packet's service environment based on its
level of privilege, termed {\em namespace-based security}.
The design and implementation of an active-network firewall and virtual
private network is used as an application of the security architecture.
Measurements of the system show that the addition of the firewall imposes an
approximately 34\% latency overhead and as little as a 6.7\% space overhead
to incoming packets.
  },
  category = "Security",
}

@InProceedings{HicksNvR03,
  author = {Michael Hicks and Adithya Nagarajan and Robbert van Renesse},
  title = "User-Specified Adaptive Scheduling in a Streaming Media Network",
  booktitle = inproc # openarch,
  year = 2003,
  month = apr,
  where = "San Francisco, CA",
  pages = "87--96",
  url = "http://www.cs.umd.edu/~mwh/papers/medianet.pdf",
  optnote = "Extended version published as University of Maryland Computer Science Technical Report CS-TR-4430, available at \url{http://www.cs.umd.edu/~mwh/papers/medianet-extended.pdf}",
  abstract = {
In disaster and combat situations, mobile cameras and other sensors
transmit real-time data, used by many operators or analysis tools.
Unfortunately, in the face of limited, unreliable resources, and varying
demands, not all users may be able to get the fidelity they require.  This
paper describes \emph{MediaNet}, a distributed stream processing system
designed with the above scenarios in mind.
Unlike past approaches, MediaNet's users can intuitively specify
how the system should adapt based on their
individual needs.
MediaNet uses both local and on-line global resource
scheduling to improve user performance and network utilization, and
adapts without requiring underlying support for
resource reservations.  Performance experiments show that our scheduling
algorithm is reasonably fast, and that user performance and network
utilization are both significantly improved.
  },
  optnote = "accept rate 12/50 or 24\%",
  category = "Programmable_Networks"
}

@techreport{ hicks03medianettr,
  author = "Michael Hicks and Adithya Nagarajan and Robbert van Renesse",
  title = "User-specified Adaptive Scheduling in a Streaming Media Network",
  number = "CS-TR-4430",
  institution = "University of Maryland Department of Computer Science",
  month = mar,
  year = "2003",
  abstract = {
In disaster and combat situations, mobile cameras
and other sensors transmit real-time data, used by
many operators and/or analysis tools. Unfortunately,
in the face of limited, unreliable resources, and varying demands, not all users may be able to get the
fidelity they require. This paper describes MediaNet, a distributed multi-media processing system designed with the above scenarios in mind. Unlike past
approaches, MediaNet's users can intuitively specify how the system should adapt based on their individual needs. MediaNet uses both local and on-line global resource scheduling to improve user performance and network utilization, and adapts without requiring underlying support for resource reservations. Performance experiments show that our
scheduling algorithm is reasonably fast, and that user
performance and network utilization are both significantly improved.
},
  url = "http://www.cs.umd.edu/~mwh/papers/medianet-extended.pdf",
  category = "Programmable_Networks"
}

@article{SewellSHBW07,
  author = "Peter Sewell and Gareth Stoyle and Michael Hicks and Gavin Bierman and Keith Wansbrough",
  title = "Dynamic Rebinding for Marshalling and Update, via Redex-time and Destruct-time Reduction",
  journal = "Journal of Functional Programming (JFP)",
  volume = 18,
  number = 4,
  month = jul,
  pages = {437--502},
  year = 2008,
  url = "http://www.cs.umd.edu/~mwh/papers/dynbind-journal.pdf",
  abstract = {
    Most programming languages adopt static binding, but for distributed
programming an exclusive reliance on static binding is too
restrictive: dynamic binding is required in various guises, for
example when a marshalled value is received from the network,
containing identifiers that must be rebound to local resources.
Typically it is provided only by ad-hoc mechanisms that lack clean
semantics.

    In this paper we adopt a foundational approach, developing core
dynamic rebinding mechanisms as extensions to the simply-typed
call-by-value lambda-calculus.  To do so we must first explore
refinements of the call-by-value reduction strategy that delay
instantiation, to ensure computations make use of the most recent
versions of rebound definitions.  We introduce redex-time and
destruct-time strategies.  The latter forms the basis for a
lambda-marsh calculus that supports dynamic rebinding of marshalled
values, while remaining as far as possible statically-typed.  We
sketch an extension of lambda-marsh with concurrency and
communication, giving examples showing how wrappers for encapsulating
untrusted code can be expressed.  Finally, we show that a high-level
semantics for dynamic updating can also be based on the destruct-time
strategy, defining a lambda-update calculus with simple primitives to
provide type-safe updating of running code.  We show how the ideas of
this simple calculus extend to more real-world, module-level dynamic
updating in the style of Erlang.  We thereby establish primitives and
a common semantic foundation for a variety of real-world dynamic
rebinding requirements.
  },
  category = "Dynamic_Software_Updating",
  note = "Appeared on-line October, 2007.  Supercedes ICFP 2003 and USE 2003 papers",
  optdoi = "doi: 10.1017/S0956796807006600"
}

@InProceedings{BiermanHSSW03,
  author = "Gavin Bierman and Michael Hicks and Peter Sewell and Gareth Stoyle and Keith Wansbrough",
  title = "Dynamic Rebinding for Marshalling and Update with Destruct-time $\lambda$",
  booktitle = inproc # icfp,
  month = "August",
  year = "2003",
  pages = "99--110",
  where = "Uppsala, Sweden",
  url = "http://www.cs.umd.edu/~mwh/papers/dynbind2-short.pdf",
  abstract = {
Most programming languages adopt static binding, but for distributed
programming an exclusive reliance on static binding is too
restrictive: dynamic binding is required in various guises.  Typically
it is provided only by ad-hoc mechanisms that lack clean semantics.
In this paper we adopt a more foundational approach, showing how core
dynamic rebinding mechanisms can be added to a CBV $\lambda$-calculus.
To do so we first develop two refinements of the CBV reduction
strategy with delayed instantiation, the \emph{redex-time} and
\emph{destruct-time} semantics.  Delayed instantiation ensures we
obtain the most recent version of a definition following a rebinding.
The destruct-time semantics gives the basis for a \lambda_{marsh} calculus
that supports dynamic rebinding, with primitives to package values and
\emph{marks} to control which identifiers are dynamically rebound when
they are unpackaged.  We extend \lambda_{marsh} with concurrency and
communication, giving examples showing how wrappers for encapsulating
untrusted code can be expressed, and discuss the extent to which it
can be statically typed.  Finally, we use the destruct-time semantics
also as a basis for a \lambda_{update} calculus with simple primitives to
provide type-safe, dynamic updating of code.  We thereby put a variety
of real-world mechanisms on a common semantic foundation.
  },
  optnote = "accept rate 24/95, or 25\%",
  category = "Distributed_Programming",
}

@InProceedings{BiermanHSS03,
  author = "Gavin Bierman and Michael Hicks and Peter Sewell and Gareth Stoyle",
  title = "Formalizing Dynamic Software Updating",
  booktitle = "On-line Proceedings of the Second International Workshop on Unanticipated Software Evolution (USE)",
  month = "April",
  year = "2003",
  note = "\url{http://www.informatik.uni-bonn.de/~gk/use/2003/Papers/papers.html}",
  url = "http://www.cs.umd.edu/~mwh/papers/formalUpdate.pdf",
  abstract = {
Dynamic software updating (DSU) enables running programs to be updated with
new code and data without interrupting their execution.  A number of DSU
systems have been designed, but there is still little rigorous understanding
of how to use DSU technology so that updates are safe.  As a first step in
this direction, we introduce a small \emph{update calculus} with a precise
mathematical semantics.  The calculus is formulated as an extension of a
typed lambda calculus, and supports updating technology similar to
that of the programming language Erlang.  Our goal
is to provide a simple yet expressive foundation for reasoning about
dynamically updateable software.  In this paper, we present the details of
the calculus, give some examples of its expressive power, and discuss how
it might be used or extended to guarantee safety properties.
  },
  category = "Dynamic_Software_Updating",
}

@InProceedings{SongSHN02,
  author =       "Seo-Kyu Song and Stephen Shannon and Michael Hicks and Scott Nettles",
  title =        "Evolution in Action: Using Active Networking to Evolve Network Support for Mobility",
  booktitle =	 "Proceedings of the Fourth International Working Conference on Active Networks (IWAN)",
  publisher =    "Springer-Verlag",
  editor =       "James Sterbenz and Osamu Takada and Christian Tschudin and Bernhard Plattner",
  series =       "Lecture Notes in Computer Science",
  volume =       2546,
  pages =        "146--161",
  year =         2002,
  month =        "December",
  url = "http://www.cs.umd.edu/~mwh/papers/evolution-action.pdf",
  abstract = {
A key early objective of Active Networking (AN) was to support
on-the-fly network evolution.  Although AN has been used
relatively extensively to build application-customized protocols
and even whole networking systems, demonstrations of evolution
have been limited.  This paper examines three AN mechanisms and how they enable
evolution: active packets and plug-in extensions, well-known to the AN
community, and update extensions, which are novel to AN.  We devote our
presentation to a series of demonstrations of how each type of evolution can
be applied to the problem of adding support for mobility to a network. This
represents the most large-scale demonstration of AN evolution to date. These
demonstrations show what previous AN research has not: that AN technology
can, in fact, support very significant changes to the network, even while
the network is operational.
  },
  category = "Programmable_Networks",
  optnote = {accept rate 20/53}
}
#  url = "http://www.springerlink.com/app/home/contribution.asp?wasp=3768dxxuvh2vymxvnnr7&referrer=parent&backto=searcharticlesresults,4,60;"

@techreport{GrossmanMJHWC02tr,
  author =       "Dan Grossman and Greg Morrisett and Trevor Jim and Michael Hicks and Yanling Wang and James Cheney",
  title =        "Formal Type Soundness for {Cyclone}'s Region System",
  number =       "CS 2001-1856",
  month = nov,
  year = 2001,
  institution = {Cornell University},
  url = {http://www.cs.umd.edu/~mwh/papers/cyclone_regions_tr.pdf},
  category = "Memory_Management",
}

@inproceedings{GrossmanMJHWC02,
  author =       "Dan Grossman and Greg Morrisett and Trevor Jim and Michael Hicks and Yanling Wang and James Cheney",
  title =        "Region-based Memory Management in {C}yclone",
  booktitle = inproc # pldi,
  month =        "June",
  where = "Berlin, Germany",
  pages = "282--293",
  publisher = "{ACM}",
  year =         2002,
  abstract = {
  Cyclone is a polymorphic, type-safe programming language derived
  from C\@.  The primary design goals of Cyclone are to let
  programmers control data representations and memory management
  without sacrificing type-safety.  In this paper, we focus on the
  region-based memory management of Cyclone and its static typing
  discipline.  The design incorporates several advancements, including
  support for region subtyping and a coherent integration with stack
  allocation and a garbage collector.  To support separate
  compilation, Cyclone requires programmers to write some explicit
  region annotations, but uses a combination of default annotations,
  local type inference, and a novel treatment of region effects to
  reduce this burden.  As a result, we integrate C idioms in a
  region-based framework.  In our experience, porting legacy C to
  Cyclone has required altering about 8\% of the code; of the
  changes, only 6\% (of the 8\%) were region annotations.
  },
  url = "http://www.cs.cornell.edu/projects/cyclone/papers/cyclone-regions.pdf",
  http = {http://cyclone.thelanguage.org},
  category = "Memory_Management"
}

@inproceedings{JimMGHCW02,
  author =       "Trevor Jim and Greg Morrisett and Dan Grossman and Michael Hicks and James Cheney and Yanling Wang",
  title =        "{C}yclone: A Safe Dialect of {C}",
  booktitle = "Proceedings of the {USENIX} Annual Technical Conference",
  month =        "June",
  where = "Monterey, CA",
  pages = "275--288",
  year =         2002,
  publisher = "{USENIX}",
  abstract = {
  Cyclone is a safe dialect of C\@.  It has been designed from the
  ground up to prevent the buffer overflows, format string attacks,
  and memory management errors that are common in C programs, while
  retaining C's syntax and semantics.  This paper examines safety
  violations enabled by C's design, and shows how Cyclone avoids them,
  without giving up C's hallmark control over low-level details such
  as data representation and memory management.
  },
  url = 	"http://www.cs.cornell.edu/projects/cyclone/papers/cyclone-safety.pdf",
  http = {http://cyclone.thelanguage.org},
  category = "Safe_Low-level_Programming"
}

@PHDTHESIS{Hicks01,
  AUTHOR = {Michael Hicks},
  TITLE = {Dynamic Software Updating},
  YEAR = 2001,
  MONTH = {August},
  SCHOOL = {Department of Computer and Information Science, University of Pennsylvania},
  URL = {http://www.cs.umd.edu/~mwh/papers/thesis.pdf},
  note = "Winner of the 2002 {ACM SIGPLAN Doctoral Dissertation} award",
  category = "Dynamic_Software_Updating"
}

@InProceedings{HicksMN01b,
  author =       "Michael Hicks and Jonathan T. Moore and Scott Nettles",
  title =        "Compiling {PLAN} to {SNAP}",
  booktitle =	 "Proceedings of the Third International Working Conference on Active Networks (IWAN)",
  publisher =    "Springer-Verlag",
  editor =       "Ian W. Marshall and Scott Nettles and Naoki Wakamiya",
  series =       "Lecture Notes in Computer Science",
  volume =       2207,
  pages =        "134--151",
  year =         2001,
  month =        "October",
  abstract = {
PLAN (Packet Language for Active Networks) is a highly flexible
and usable active packet language, whereas SNAP (Safe and Nimble
Active Packets)  offers significant resource usage safety and
achieves much higher performance compared to PLAN, but at the cost
of flexibility and usability.  Ideally, we would like to combine
the good properties of PLAN with those of SNAP. We have achieved
this end by developing a compiler that translates PLAN
into SNAP. The compiler allows us to achieve the
flexibility and usability of PLAN, but with the safety and
efficiency of SNAP. In this paper, we describe both languages,
highlighting the features that require special compilation
techniques. We then present the details of our compiler and
experimental results to evaluate our compiler with respect to code
size.
  },
  url = "http://www.cs.umd.edu/~mwh/papers/plansnap.ps",
  category = "Programmable_Networks",
  optnote = {accept rate 10/22}
}

#  url =          "http://www.springerlink.com/app/home/contribution.asp?wasp=gmuaykwgwm5wb2xydff7&referrer=parent&backto=searcharticlesresults,2,6;"

@Inproceedings{HicksMN01a,
  author =       "Michael Hicks and Jonathan T. Moore and Scott Nettles",
  booktitle = inproc # pldi,
  title =        "Dynamic Software Updating",
  month =        "June",
  year =         2001,
  pages = 	 "13--23",
  publisher =    "{ACM}",
  abstract = {
Many important applications must run continuously and without interruption,
yet must be changed to fix bugs or upgrade functionality.  No
prior general-purpose methodology for dynamic updating achieves a practical
balance between flexibility, robustness, low overhead, and ease of use.

We present a new approach for C-like languages that provides type-safe
dynamic updating of native code in an extremely flexible manner (code, data,
and types may be updated, at programmer-determined times) and permits the
use of automated tools to aid the programmer in the updating process.  Our
system is based on \emph{dynamic patches} that both contain the updated code
and the code needed to transition from the old version to the new.  A novel
aspect of our patches is that they consist of \emph{verifiable native code}
(\emph{e.g.} Proof-Carrying Code or Typed Assembly
Language, which is native code accompanied by
annotations that allow on-line verification of the code's safety.  We
discuss how patches are generated mostly automatically, how they are applied
using dynamic-linking technology, and how code is compiled to make it
updateable.

To concretely illustrate our system, we have implemented a
dynamically-updateable web server, FlashEd.  We discuss our experience
building and maintaining FlashEd.  Performance experiments show that for
FlashEd, the overhead due to updating is typically less than 1 percent.
},
  url =          "http://www.cs.umd.edu/~mwh/papers/dyn_update.pdf",
  category = "Dynamic_Software_Updating"
}

@InProceedings{MooreHN01,
  author =       "Jonathan T. Moore and Michael Hicks and Scott Nettles",
  title =        "Practical Programmable Packets",
  booktitle =    "Proceedings of the Twentieth {IEEE} Computer and
                  Communication Society {INFOCOM} Conference",
  month =        "April",
  year =         2001,
  pages =	 "41-50",
  publisher =    "{IEEE}",
  abstract = {
We present SNAP (Safe and Nimble Active Packets), a new scheme for
programmable (or {\em active}) packets centered around a new low-level
packet language. Unlike previous active packet approaches, SNAP is {\em
practical}: namely, adding significant {\em flexibility} over IP without
compromising {\em safety and security} or {\em efficiency}. In this work we
compare SNAP's flexibility to other active packet systems, give proof
sketches of its novel approach to resource control, and present experimental
data showing SNAP attains performance extremely close to that of a software
IP router.
  },
  url =          "http://www.cis.upenn.edu/~switchware/papers/snap.pdf",
  category = "Programmable_Networks",
}

@InProceedings{HicksN00,
  author =       "Michael Hicks and Scott Nettles",
  title =        "Active Networking means Evolution (or Enhanced Extensibility
                  Required)",
  abstract = {
The primary goal of active networking is to increase the pace of
network evolution.  The approach to achieving this goal, as well
as the goal of enhancing customizability, is to allow network
nodes to be extended by dynamically loaded code. Most active
network implementations employ {\em plug-in extensibility}, a
technique for loading code characterized by a concrete,
pre-defined abstraction of future change.  After giving examples
of plug-in extensibility, we argue that while it is flexible and
convenient, it is not sufficient to facilitate true evolution of
the network. To remedy this problem, we propose the use of {\em
dynamic software updating}.  Dynamic software updating reduces the
{\em a priori} assumptions of plug-in extensibility, improving
flexibility and eliminating the need to pre-plan extensions.
However, this additional flexibility results in additional
complexity and creates issues involving validity and security. We
discuss these issues, and describe the state-of-the-art in systems
that support dynamic software updating, thus framing the problem
for  researchers developing next-generation active networks.
  },
  booktitle =    "Proceedings of the Second International Working Conference on Active Networks (IWAN)",
  month =        "October",
  year =         2000,
  publisher =    "Springer-Verlag",
  editor =       "Hiroshi Yashuda",
  series =       "Lecture Notes in Computer Science",
  volume =       1942,
  pages =        "16--32",
  url = "http://www.cs.umd.edu/~mwh/papers/an_evolution.pdf",
  category = "Programmable_Networks",
}

#  url =          "http://www.springerlink.com/app/home/contribution.asp?wasp=gmuaykwgwm5wb2xydff7&referrer=parent&backto=searcharticlesresults,1,6;"

@InProceedings{AnagnostakisHIKS00,
  author =       "Kostas G. Anagnostakis and Michael W. Hicks and Sotiris Ioannidis and Angelos D. Keromytis and Jonathan M. Smith",
  title =        "Scalable Resource Control in Active Networks",
  abstract = {
The increased complexity of the service model relative to store-and-forward
routers, has made resource management one of the paramount concerns in
active networking research and engineering. Previous work investigated
methods for controlling access to resources by restricting namespaces
or providing limited functionality in a domain-specific language.
Combinations of these methods and scheduling technologies have also been used
to demonstrate a resource-managed node architecture. In this paper, we address
Two major challenges in scaling resource management to many-node active
networks.  The first is the use of market mechanisms and trading amongst nodes
and programs with varying degrees of competition and cooperation to provide a
scalable approach to managing active network resources. The second is the use
of a trust-management architecture to ensure that the participants in the
resource management marketplace have a policy-driven ``rule of law''
in which marketplace decisions can be made and relied upon. We have used
lottery scheduling and the Keynote trust-management system for our
implementation, for which we provide some initial performance indications.
  },
  booktitle =    "Proceedings of the Second International Working Conference on
Active Networks (IWAN)",
  month =        "October",
  year =         2000,
  publisher =    "Springer-Verlag",
  editor =       "Hiroshi Yashuda",
  series =       "Lecture Notes in Computer Science",
  volume =       1942,
  pages =	 "343--358",
  url = "http://www.cs.umd.edu/~mwh/papers/keynote-market.ps",
  category = "Programmable_Networks",
}

# url =          "http://www.springerlink.com/app/home/contribution.asp?wasp=gmuaykwgwm5wb2xydff7&referrer=parent&backto=searcharticlesresults,6,6;"

@TechReport{HicksW00type-loading-tr,
  author =       {Michael Hicks and Stephanie Weirich},
  title =        {A Calculus for Dynamic Loading},
  institution =  {University of Pennsylvania},
  year =         {2000},
  number =       {MS-CIS-00-07},
  month =        {April},
  url =          {http://www.cs.umd.edu/~mwh/papers/loadcalc.pdf},
  category = "Dynamic_Software_Updating",
}

@InProceedings{CraryHW00,
  author =       "Michael Hicks and Stephanie Weirich and Karl Crary",
  title =        "Safe and Flexible Dynamic Linking of Native Code",
  month =        "September",
  year =         2000,
  abstract = {
  We present the design and implementation of the first complete framework
  for flexible and safe dynamic linking of native code.  Our approach
  extends Typed Assembly Language with a primitive for loading and
  typechecking code, which is flexible enough to support a variety of
  linking strategies, but simple enough that it does not significantly
  expand the trusted computing base.  Using this primitive, along with the
  ability to compute with types, we show that we can {\em program} many
  existing dynamic linking approaches.  As a concrete demonstration, we have
  used our framework to implement dynamic linking for a type-safe dialect of
  C, closely modeled after the standard linking facility for Unix C
  programs.  Aside from the unavoidable cost of verification, our
  implementation performs comparably with the standard, untyped approach.
  },
  booktitle =    "Proceedings of the {ACM} {SIGPLAN} Workshop on Types in Compilation (TIC)",
  volume =	 "2071",
  publisher =    "Springer-Verlag",
  editor =       "Robert Harper",
  series =       "Lecture Notes in Computer Science",
  url = "http://www.cs.umd.edu/~mwh/papers/taldynlink.pdf",
  category = "Dynamic_Software_Updating",
}

# url =          "http://www.springerlink.com/app/home/contribution.asp?wasp=n97bk9fdwn4kyhdfqjft&referrer=parent&backto=searcharticlesresults,8,51;"

@unpublished{HicksKES00,
  author =       "Osman Ertugay and Michael Hicks and Jessica Kornblum and Jonathan Smith",
  title =        "Agents in Network Management",
  month =        "April",
  year =         2000,
  abstract = {
The ubiquity and complexity of modern networks requires automated
management and control. With increases in scale, automated solutions based
on simple data access models such as SNMP will give way to more distributed
and algorithmic techniques. This article outlines present and near-term
solutions based on the ideas of active networks and mobile agents,
which permit sophisticated programmable control and management of ultra
large scale networks.
  },
  url = 	"http://www.cis.upenn.edu/~mwh/papers/agentsNM.ps",
  note =	"Unpublished manuscript",
  omitfromweb = "yes"
}

@Inproceedings{HicksMNW02,
  author =       "Michael Hicks and Jonathan T. Moore and David Wetherall and Scott Nettles",
  title =        "Experiences with Capsule-based Active Networking",
  booktitle = "Proceedings of the {DARPA} Active Networks Conference and Exposition (DANCE)",
  month =        "May",
  where = "San Francisco, CA",
  year =         2002,
  pages = "16--24",
  publisher = "{IEEE}",
  abstract = {
Active Networking adds programmability to the elements
of the network, most aggressively by using programmable packets,
or {\em capsules}. ANTS and
PLANet are the most mature examples of
capsule-based systems, both having been publicly available for
several years. This paper presents our experience with these
systems and the lessons they hold for the future of capsule-based
Active Networking.

The paper focuses on four key issues: flexibility, performance,
security, and usability.  We consider how ANTS and PLANet address
these issues, noting that despite substantial surface differences,
both systems identify similar key problems and use closely related
solutions.  Based on our experience with these systems we conclude
that capsule-based systems can achieve useful levels of
flexibility, performance, and usability.  Many aspects of security
can also be adequately addressed, but some important problems
related to denial of service remain as open problems.
  },
  url =          "http://www.cs.umd.edu/~mwh/papers/planants.ps",
  category = "Programmable_Networks",
}

@InProceedings{KakkarHMG99,
  author =       "Pankaj Kakkar and Michael Hicks and Jonathan T. Moore and
                 Carl A. Gunter",
  title =        "Specifying the {PLAN} Network Programming Language",
  year =         1999,
  volume =       26,
  series =       "Electronic Notes in Theoretical Computer Science",
  booktitle =    "Higher Order Operational Techniques in Semantics (HOOTS)",
  pages = 	"87--104",
  publisher =    "Elsevier",
  month =        "September",
  url = "http://www.cis.upenn.edu/~switchware/PLAN/spec/spec-experience.ps",
  category = "Programmable_Networks"
}

@InProceedings{HicksK99,
  author =       "Michael Hicks and Angelos D. Keromytis",
  title =        "A Secure {PLAN}",
  booktitle =    "Proceedings of the First International Working Conference on
		  Active Networks (IWAN)",
  month =        "June",
  year =         1999,
  publisher =    "Springer-Verlag",
  editor =       "Stefan Covaci",
  series =       "Lecture Notes in Computer Science",
  volume =       1653,
  pages =        "307--314",
  abstract = {
Active Networks promise greater flexibility than current networks, but
threaten safety and security by virtue of their programmability. In this
paper, we describe the design and implementation of a security architecture
for the active network {\em PLANet}.  Security is obtained
with a two-level architecture that combines a functionally restricted packet
language, PLAN, with an environment of general-purpose
service routines governed by {\em trust management}.  In
particular, we employ a technique which expands or contracts a packet's
service environment based on its level of privilege, termed {\em
namespace-based security}.  As an application of our security architecture,
we present the design and implementation of an active-network firewall. We
find that the addition of the firewall imposes around a 30 percent latency
overhead, and as little as a 6.7 percent space overhead to incoming packets.
  },
  url = {http://www.cis.upenn.edu/~switchware/papers/iwan99.ps},
  note = "Reprinted with extensions in {DARPA} Active Networks Conference and Exposition (DANCE) and IEEE Transactions on Systems, Man, and Cybernetics, Part C",
  category = "Programmable_Networks"
}

@Inproceedings{MooreHN99,
  author =      "Jonathan T. Moore and Michael Hicks and Scott M. Nettles",
  title =        "Chunks in {PLAN}: Language Support for Programs as Packets",
  booktitle =    "Proceedings of the 37th Annual Allerton Conference on
                  Communication, Control, and Computing",
  month =       "September",
  year =         1999,
  abstract = {
{\em Chunks} are a programming construct in PLAN, the Packet Language for
Active Networks, comprised of a code segment and a suspended function call.
In PLAN, chunks provide support for encapsulation and other packet
programming techniques.  This paper begins by explaining the semantics and
implementation of chunks.  We proceed, using several PLAN source code
examples, to demonstrate the usefulness of chunks for micro-protocols,
asynchronous adaptation, and as units of authentication granularity.
  },
  url = {http://www.cis.upenn.edu/~switchware/papers/planchunks.pdf},
  category = "Programmable_Networks"
}

@InProceedings{HicksJKMU99,
  author =       "Michael Hicks and Suresh Jagannathan and Richard
		  Kelsey and Jonathan T. Moore and Cristian Ungureanu",
  title =        "Transparent Communication for Distributed Objects in {Java}",
  booktitle =    "Proceedings of the {ACM} {SIGPLAN} Java Grande Conference",
  month =        "June",
  year =         1999,
  publisher =    "ACM",
  pages = 	"160--170",
  abstract = {
We describe a native-code implementation of Java that supports distributed
objects. In order to foster the correctness of distributed programs, remote
access is syntactically and semantically indistinguishable from local
access. This transparency is provided by the runtime system through the
implicit generation of remote references to an object when it is passed as
an argument or returned from a remote method call. Consistency is achieved
through the use of a distributed (and thus scalable) global addressing
scheme.  Experiments show that application performance is a function of data
layout, access algorithm, and local workload. For distributed applications,
such as distributed databases, these factors may not be known statically,
suggesting the importance of runtime support.
  },
  url =		"http://www.cs.umd.edu/~mwh/papers/java99.ps",
  category = "Distributed_Programming"
}

@InProceedings{HicksKMGN98,
  author =       "Michael Hicks and Pankaj Kakkar and Jonathan T. Moore
  and Carl A. Gunter and Scott Nettles",
  title =        "{PLAN}: A Packet Language for Active Networks",
  booktitle =    "Proceedings of the Third {ACM} {SIGPLAN} International Conference on Functional Programming Languages (ICFP)",
  month =        "September",
  year =         1998,
  pages =        "86--93",
  publisher =    "ACM",
  abstract = {
PLAN (Packet Language for Active Networks) is a new language for
programs that form the packets of a programmable network.  These
programs replace the packet headers (which can be viewed as very
rudimentary programs) used in current networks.  As such, PLAN
programs are lightweight and of restricted functionality.  These
limitations are mitigated by allowing PLAN code to call node-resident
{\em service routines} written in other, more powerful languages.
This two-level architecture, in which PLAN serves as a scripting or
`glue' language for more general services, is the primary contribution
of this paper. We have successfully applied the PLAN programming
environment to implement an IP-free internetwork.

PLAN is based on the simply typed lambda calculus and provides a
restricted set of primitives and datatypes.  PLAN defines a special
construct called a {\em chunk} used to describe the remote execution
of PLAN programs on other nodes. Primitive operations on chunks are
used to provide basic data transport in the network and to support
layering of protocols.  Remote execution can make debugging difficult,
so PLAN provides strong static guarantees to the programmer, such as
type safety.  A more novel property aimed at protecting network
availability is a guarantee that PLAN programs use a bounded amount of
network resources.},
  url =          "http://www.cis.upenn.edu/~switchware/papers/plan.ps",
  category = "Programmable_Networks",
}

@InProceedings{HicksMAGN99,
  author =       "Michael Hicks and Jonathan T. Moore and D. Scott Alexander
  and Carl A. Gunter and Scott Nettles",
  title =        "{PLANet}: An Active Internetwork",
  booktitle =    "Proceedings of the Eighteenth {IEEE} Computer and
		  Communication Society {INFOCOM} Conference",
  month =        "March",
  year =         1999,
  publisher =    "{IEEE}",
  pages =        "1124--1133",
  abstract =     {
We present {\em PLANet}: an active network architecture and
implementation.  In addition to a standard suite of Internet-like
services, PLANet has two key programmability features:
\begin{enumerate}
\item all packets contain programs
\item router functionality may be extended dynamically
\end{enumerate}
Packet programs are written in our special purpose programming
language PLAN, the Packet Language for Active Networks, while dynamic
router extensions are written in OCaml, a dialect of ML.

Currently, PLANet routers run as byte-code-interpreted Linux
user-space applications, and support Ethernet and IP as link layers.
PLANet achieves respectable performance on standard networking
operations: on 300~MHz Pentium-II's attached to 100~Mbps Ethernet,
PLANet can route 48~Mbps and switch over 5000 packets per second.  We
demonstrate the utility of PLANet's activeness by showing
experimentally how it can non-trivially improve application and
aggregate network performance in congested conditions.},
  url =          "http://www.cis.upenn.edu/~switchware/papers/planet.ps",
  category = "Programmable_Networks",
}

@InProceedings{HicksKMGN98ipl,
  author =      "Michael Hicks and Pankaj Kakkar and Jonathan T. Moore
  and Carl A. Gunter and Scott Nettles",
  title =       "Network Programming Using {PLAN}",
  booktitle =   "Proceedings of the {IEEE} Workshop on Internet Programming Languages",
  year =        1998,
  month =       May,
  publisher =    "Springer-Verlag",
  editor =       "Luca Cardelli",
  series =       "Lecture Notes in Computer Science",
  volume =       1686,
  pages =        "127--143",
  abstract = {
We present here a methodology for programming active networks in the
environment defined by our new language PLAN (Packet Language for
Active Networks). This environment presumes a two-level architecture
consisting of:
\begin{enumerate}
\item {\em active packets} carrying PLAN code; and
\item downloadable, node-resident {\em services} written in more
general-purpose languages.
\end{enumerate}
We present several examples which illustrate how these two features
can be combined to implement various network functions.},
  url =		"http://www.cis.upenn.edu/~switchware/papers/progplan.ps",
  category = "Programmable_Networks",
}

#  url =		"http://www.springerlink.com/app/home/contribution.asp?wasp=gmuaykwgwm5wb2xydff7&referrer=parent&backto=searcharticlesresults,5,6;"

@InProceedings{HicksMN97,
  author =      "Michael W. Hicks and Jonathan T. Moore
                 and Scott M. Nettles",
  title =       "The Measured Cost of Copying Garbage Collection Mechanisms",
  booktitle =   "Proceedings of the {ACM} {SIGPLAN} Conference on
		 Functional Programming (ICFP)",
  year =        1997,
  publisher =   "{ACM}",
  pages =       "292--305",
  month =       "June",
  abstract =    "
We examine the costs and benefits of a variety of copying garbage
collection (GC) mechanisms across multiple architectures and
programming languages. Our study covers both low-level object
representation and copying issues as well as the mechanisms needed to
support more advanced techniques such as generational collection,
large object spaces, and type-segregated areas.

Our experiments are made possible by a novel performance analysis
tool, {\em Oscar.} Oscar allows us to capture snapshots of programming
language heaps that may then be used to replay garbage
collections. The replay program is self-contained and written in C,
which makes it easy to port to other architectures and to analyze with
standard performance analysis tools. Furthermore, it is possible to
study additional programming languages simply by instrumenting
existing implementations to capture heap snapshots.

In general, we found that careful implementation of GC mechanisms can
have a significant benefit. For a simple collector, we measured
improvements of as much as 95 percent. We then found that while the addition
of advanced features can have a sizeable overhead (up to 15 percent), the
net benefit is quite positive, resulting in additional gains of up to
42 percent. We also found that results varied depending upon the platform
and language. Machine characteristics such as cache arrangements,
instruction set (RISC/CISC), and register pool were important. For
different languages, average object size seemed to be most important.

The results of our experiments demonstrate the usefulness of a tool
like Oscar for studying GC performance. Without much overhead, we can
easily identify areas where programming language implementors could
collaborate with GC implementors to improve GC performance.",
  url =         "http://www.cis.upenn.edu/~oscar/icfp97.ps",
  category = "Memory_Management"
}

@InProceedings{HicksHMN98,
  author =      "Michael Hicks and Luke Hornof and Jonathan T. Moore
  and Scott Nettles",
  title =       "A Study of Large Object Spaces",
  booktitle =   inproc # ismm,
  pages = 	"138--145",
  year =        1998,
  publisher =   "{ACM}",
  month =       "October",
  abstract = {
This paper examines the design space for copying garbage collectors
(GCs) in which ``large objects'' are managed in a separate,
non-copy-collected space. We focus on two main issues:
\begin{enumerate}
\item how to set the policy for classifying objects as ``large''
\item how to manage the large object space
\end{enumerate}
We explore these issues experimentally using the Oscar GC testbed. In
particular, we vary the threshold size of large objects and also
whether the objects may contain pointers. Furthermore, we compare the
performance of treadmill collection to that of mark-and-sweep
collection for managing the large object space.

We find that for some heaps there is a minimum cutoff size below which
adding objects to the large object space does not result in a
performance improvement, while for others no such cutoff exists.  In
general, including pointer-containing objects in the large object
space seems beneficial.  Finally, the exact method used to collect the
large object space does not significantly influence overall
performance.
},
  url =		"http://www.cis.upenn.edu/~oscar/ismm98.ps",
  category = "Memory_Management"
}

@Techreport{Hicks98,
  author =      "Michael Hicks",
  title =       "{PLAN} System Security",
  institution = "Department of Computer and Information Science, University of Pennsylvania",
  type = "Technical Report",
  number = "MS-CIS-98-25",
  month =       "April",
  year =        "1998",
  url =	{http://www.cis.upenn.edu/~switchware/papers/plan_security.ps},
  category = "Security",
}

@Article{AlexanderAHKKMGNS98,
  author =       "D. Scott Alexander and William A. Arbaugh and Michael Hicks and Pankaj Kakkar and Angelos Keromytis and Jonathan T. Moore and Carl A. Gunter and Scott M. Nettles and Jonathan M. Smith",
  title =        "The {SwitchWare} Active Network Architecture",
  journal =      "{IEEE Network Magazine}",
  volume =       12,
  number =       3,
  year =         1998,
  pages =        "29-36",
  note =         "{Special issue on Active and Controllable Networks}",
  url = "http://www.cis.upenn.edu/~switchware/papers/switchware.ps",
  category = "Programmable_Networks",
}

@InProceedings{AlexanderHKKSMGJNS98,
  author =       "D. Scott Alexander and Michael W. Hicks and Pankaj
		  Kakkar and Angelos D. Keromytis and Marianne Shaw
		  and Jonathan T. Moore and Carl A. Gunter and Trevor
		  Jim and Scott M. Nettles and Jonathan M. Smith",
  title =        "{The SwitchWare Active Network Implementation}",
  booktitle =    "Notes of the {ACM} {SIGPLAN} Workshop on {ML}",
  month =        "September",
  year =         1998,
  pages =        "67--76",
  url =          "http://www.cis.upenn.edu/~switchware/papers/ml.ps",
  category = "Programmable_Networks",
}

@Unpublished{MooreHN98,
  author = 	 "Jonathan T. Moore and Michael Hicks and Scott Nettles",
  title = 	 "General-Purpose Persistence Using Flash Memory",
  year =	 1997,
  month =	 "April",
  abstract = {
Flash memory is a semiconductor memory technology that has interesting
price, performance, and semantic tradeoffs. We have developed Gordon,
a general-purpose persistence system for Standard ML that uses Flash
mapped into the virtual address space as its stable storage medium.

Flash supports a write-once/bulk-erase interface that makes it
difficult to support update-in-place semantics. In addition, Flash
chips are only guaranteed to survive a limited number of erase
cycles. Gordon has been designed to overcome these difficulties, and
our performance analysis demonstrates good performance and reasonable
lifetimes for appropriate application domains.},
  url = 	 "http://www.cs.umd.edu/~mwh/papers/flash.ps",
  note =	 "Unpublished manuscript",
  category = "Miscellaneous",
}

@Techreport{Hicks98A,
  author =      "Michael Hicks",
  title =       "{Types and Intermediate Representations}",
  institution = "Department of Computer and Information Science, University of Pennsylvania",
  type = "Technical Report",
  number = "MS-CIS-98-05",
  month =       "April",
  year =        "1998",
  abstract =
{The design objectives and the mechanisms for achieving those
objectives are considered for each of three systems, Java, Erlang, and
TIL. In particular, I examine the use of types and intermediate
representations in the system implementation. In addition, the systems
are compared to examine how one system's mechanisms may (or may not)
be applied to another.},
  url =	{http://www.cs.umd.edu/~mwh/papers/typedIR.ps},
  category = "Miscellaneous",
}


@inbook{anbook,
 author = "Michael Hicks and Scott M. Nettles",
 title = "Active Networks",
 publisher = "John Wiley and Sons, U.K.",
 year = 2004,
 chapter = "Execution Environments",
 note = "In progress.",
 omitfromweb = "yes",
}

@book{baader1999term,
  title={Term rewriting and all that},
  author={Baader, Franz and Nipkow, Tobias},
  year={1999},
  publisher={Cambridge university press}
}

@inproceedings{10.1145/3453483.3454074,
author = {Acay, Co\c{s}ku and Recto, Rolph and Gancher, Joshua and Myers, Andrew C. and Shi, Elaine},
title = {Viaduct: An Extensible, Optimizing Compiler for Secure Distributed Programs},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454074},
doi = {10.1145/3453483.3454074},
abstract = {Modern distributed systems involve interactions between principals with limited trust,
so cryptographic mechanisms are needed to protect confidentiality and integrity. At
the same time, most developers lack the training to securely employ cryptography.
We present Viaduct, a compiler that transforms high-level programs into secure, efficient
distributed realizations. Viaduct's source language allows developers to declaratively
specify security policies by annotating their programs with information flow labels.
The compiler uses these labels to synthesize distributed programs that use cryptography
efficiently while still defending the source-level security policy. The Viaduct approach
is general, and can be easily extended with new security mechanisms. Our implementation
of the Viaduct compiler comes with an extensible runtime system that includes plug-in
support for multiparty computation, commitments, and zero-knowledge proofs. We have
evaluated the system on a set of benchmarks, and the results indicate that our approach
is feasible and can use cryptography in efficient, nontrivial ways.},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {740–755},
numpages = {16},
keywords = {information flow, zero knowledge, multiparty computation},
location = {Virtual, Canada},
series = {PLDI 2021}
}

@inproceedings{10.1145/3319535.3339818,
author = {Ishaq, Muhammad and Milanova, Ana L. and Zikas, Vassilis},
title = {Efficient MPC via Program Analysis: A Framework for Efficient Optimal Mixing},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3339818},
doi = {10.1145/3319535.3339818},
abstract = {Multi-party computation (MPC) protocols have been extensively optimized in an effort
to bring this technology to practice, which has already started bearing fruits. The
choice of which MPC protocol to use depends on the computation we are trying to perform.
Protocol mixing is an effective black-box ---with respect to the MPC protocols---approach
to optimize performance. Despite, however, considerable progress in the recent years
existing works are heuristic and either give no guarantee or require an exponential
(brute-force) search to find the optimal assignment, a problem which was conjectured
to be NP hard.We provide a theoretically founded approach to optimal (MPC) protocol
assignment, i.e., optimal mixing, and prove that under mild and natural assumptions,
the problem is tractable both in theory and in practice for computing best two-out-of-three
combinations. Concretely, for the case of two protocols, we utilize program analysis
techniques---which we tailor to MPC---to define a new integer program, which we term
the Optimal Protocol Assignment (in short, OPA) problem whose solution is the optimal
(mixed) protocol assignment for these two protocols. Most importantly, we prove that
the solution to the linear program corresponding to the relaxation of OPA is integral,
and hence is also a solution to OPA. Since linear programming can be efficiently solved,
this yields the first efficient protocol mixer. We showcase the quality of our OPA
solver by applying it to standard benchmarks from the mixing literature. Our OPA solver
can be applied on any two-out-of-three protocol combinations to obtain a best two-out-of-three
protocol assignment.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1539–1556},
numpages = {18},
keywords = {linear programming, program analysis, cryptography, multiparty computation, protocol mixing},
location = {London, United Kingdom},
series = {CCS '19}
}

@inproceedings{10.1145/2810103.2813634,
author = {Wang, Xiao and Chan, Hubert and Shi, Elaine},
title = {Circuit ORAM: On Tightness of the Goldreich-Ostrovsky Lower Bound},
year = {2015},
isbn = {9781450338325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810103.2813634},
doi = {10.1145/2810103.2813634},
abstract = {We propose a new tree-based ORAM scheme called Circuit ORAM. Circuit ORAM makes both
theoretical and practical contributions. From a theoretical perspective, Circuit ORAM
shows that the well-known Goldreich-Ostrovsky logarithmic ORAM lower bound is tight
under certain parameter ranges, for several performance metrics. Therefore, we are
the first to give an answer to a theoretical challenge that remained open for the
past twenty-seven years. Second, Circuit ORAM earns its name because it achieves (almost)
optimal circuit size both in theory and in practice for realistic choices of block
sizes. We demonstrate compelling practical performance and show that Circuit ORAM
is an ideal candidate for secure multi-party computation applications.},
booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
pages = {850–861},
numpages = {12},
keywords = {oblivious RAM, secure computation},
location = {Denver, Colorado, USA},
series = {CCS '15}
}